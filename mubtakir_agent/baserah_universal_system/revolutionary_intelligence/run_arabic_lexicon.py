#!/usr/bin/env python3
# run_arabic_lexicon.py - ØªØ´ØºÙŠÙ„ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ

import sys
import os
from datetime import datetime

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…ÙƒØªØ¨Ø§Øª
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…Ø­Ø±Ùƒ ÙˆØ§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
from .arabic_lexicon_engine import (
    ArabicLexiconEngine,
    analyze_arabic_word,
    explore_arabic_letter,
    analyze_arabic_text,
    create_arabic_lexicon_engine
)

from .lexicon_data_loader import (
    LexiconDataLoader,
    quick_load_lexicon_data
)


def print_banner():
    """Ø·Ø¨Ø§Ø¹Ø© Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø­Ø±Ùƒ."""
    
    banner = """
ğŸ“šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ“š
ğŸ”¤                   Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ                      ğŸ”¤
ğŸ§¬              Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ ÙˆÙ†Ø¸Ø§Ù… Baserah Ø§Ù„Ù†Ù‚ÙŠ                ğŸ§¬
ğŸ“–              Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©              ğŸ“–
ğŸ“šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ğŸ“š
"""
    
    print(banner)
    print(f"ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”¥ Ø§Ù„Ù†Ø³Ø®Ø©: 1.0.0 - Arabic Lexicon Engine")
    print()


def print_menu():
    """Ø·Ø¨Ø§Ø¹Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª."""
    
    menu = """
ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:

1ï¸âƒ£  ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© Ø¹Ø±Ø¨ÙŠØ©
2ï¸âƒ£  Ø§Ø³ØªÙƒØ´Ø§Ù Ø¯Ù„Ø§Ù„Ø© Ø­Ø±Ù
3ï¸âƒ£  ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ø¹Ø±Ø¨ÙŠ
4ï¸âƒ£  ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ø¬Ù… Ø¥Ø¶Ø§ÙÙŠØ©
5ï¸âƒ£  Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ
6ï¸âƒ£  Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ø±Ùƒ
7ï¸âƒ£  Ø¹Ø±Ø¶ Ø¯Ù„Ø§Ù„Ø§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ø±ÙˆÙ
8ï¸âƒ£  Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¹Ø¬Ù…
0ï¸âƒ£  Ø®Ø±ÙˆØ¬

"""
    print(menu)


def analyze_word_interactive(engine):
    """ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© ØªÙØ§Ø¹Ù„ÙŠ."""
    
    print("ğŸ” ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© Ø¹Ø±Ø¨ÙŠØ©")
    print("=" * 50)
    
    word = input("ğŸ“ Ø£Ø¯Ø®Ù„ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: ").strip()
    
    if not word:
        print("âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø©!")
        return
    
    deep_analysis = input("ğŸ§¬ ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù…Ø¹ Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ØŸ (y/n): ").strip().lower() == 'y'
    
    print(f"\nğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø©: {word}")
    print("â³ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...")
    
    try:
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø©
        analysis = engine.analyze_word_revolutionary(word, deep_analysis=deep_analysis)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
        print("=" * 50)
        
        print(f"ğŸ”¤ Ø§Ù„ÙƒÙ„Ù…Ø©: {analysis.word}")
        print(f"ğŸŒ± Ø§Ù„Ø¬Ø°Ø±: {analysis.root}")
        print(f"ğŸ’­ Ø§Ù„Ù…Ø¹Ù†Ù‰: {analysis.meaning}")
        print(f"ğŸ“– Ø§Ù„ØªÙØ³ÙŠØ± Ø§Ù„Ù…ÙØµÙ„: {analysis.detailed_meaning}")
        print(f"âš–ï¸ Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {analysis.semantic_weight:.3f}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ
        print(f"\nğŸ”¤ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ:")
        for letter, meaning in analysis.letter_analysis.items():
            print(f"   {letter}: {meaning}")
        
        # ØªØ­Ù„ÙŠÙ„ Baserah
        print(f"\nğŸŒŸ ØªØ­Ù„ÙŠÙ„ Baserah:")
        baserah = analysis.baserah_analysis
        print(f"   Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {baserah.get('total_value', 0):.3f}")
        print(f"   Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©: {baserah.get('average_value', 0):.3f}")
        print(f"   Ù…Ø¤Ø´Ø± Ø§Ù„ØªÙ†Ø§ØºÙ…: {baserah.get('harmony_index', 0):.3f}")
        print(f"   Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ Ø§Ù„Ø«ÙˆØ±ÙŠ: {baserah.get('baserah_signature', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        
        # Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ (Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚Ø§Ù‹)
        if deep_analysis and analysis.basil_theories_application:
            print(f"\nğŸ§¬ Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø§Ù„Ø«ÙˆØ±ÙŠØ©:")
            
            # Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±
            if 'zero_duality' in analysis.basil_theories_application:
                zero_duality = analysis.basil_theories_application['zero_duality']
                print(f"   ğŸ”„ Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±:")
                print(f"      Ù…Ø¬Ù…ÙˆØ¹ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ: {zero_duality['positive_sum']:.3f}")
                print(f"      Ù…Ø¬Ù…ÙˆØ¹ Ø³Ø§Ù„Ø¨: {zero_duality['negative_sum']:.3f}")
                print(f"      Ø§Ù„ØªÙˆØ§Ø²Ù†: {zero_duality['balance']:.3f}")
                print(f"      Ù…ØªÙˆØ§Ø²Ù†: {'Ù†Ø¹Ù…' if zero_duality['is_balanced'] else 'Ù„Ø§'}")
            
            # ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯
            if 'perpendicular_opposites' in analysis.basil_theories_application:
                perp = analysis.basil_theories_application['perpendicular_opposites']
                print(f"   âŸ‚ ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯:")
                print(f"      Ø§Ù„Ù†ØµÙ Ø§Ù„Ø£ÙˆÙ„: {perp['first_half_value']:.3f}")
                print(f"      Ø§Ù„Ù†ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ: {perp['second_half_value']:.3f}")
                print(f"      Ø§Ù„Ø²Ø§ÙˆÙŠØ©: {perp['perpendicular_angle']:.1f}Â°")
            
            # Ø§Ù„ÙØªØ§Ø¦Ù„
            if 'filament_theory' in analysis.basil_theories_application:
                filament = analysis.basil_theories_application['filament_theory']
                print(f"   ğŸ§µ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„:")
                print(f"      Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙØªØ§Ø¦Ù„: {filament['total_filaments']}")
                print(f"      ÙØªØ§Ø¦Ù„ Ø£ÙˆÙ„ÙŠØ©: {filament['primary_filaments']}")
        
        # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
        if analysis.related_words:
            print(f"\nğŸ”— ÙƒÙ„Ù…Ø§Øª Ø°Ø§Øª ØµÙ„Ø©:")
            for related_word in analysis.related_words[:5]:
                print(f"   â€¢ {related_word}")
        
        # Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        if analysis.usage_examples:
            print(f"\nğŸ“ Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:")
            for example in analysis.usage_examples[:3]:
                print(f"   â€¢ {example}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø©: {e}")


def explore_letter_interactive(engine):
    """Ø§Ø³ØªÙƒØ´Ø§Ù Ø­Ø±Ù ØªÙØ§Ø¹Ù„ÙŠ."""
    
    print("ğŸ”¤ Ø§Ø³ØªÙƒØ´Ø§Ù Ø¯Ù„Ø§Ù„Ø© Ø­Ø±Ù")
    print("=" * 50)
    
    letter = input("ğŸ“ Ø£Ø¯Ø®Ù„ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠ: ").strip()
    
    if not letter or len(letter) != 1:
        print("âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø­Ø±Ù ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·!")
        return
    
    print(f"\nğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø­Ø±Ù: {letter}")
    
    try:
        # Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø­Ø±Ù
        analysis = engine.explore_letter_meanings(letter)
        
        if 'error' in analysis:
            print(f"âŒ {analysis['error']}")
            return
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù:")
        print("=" * 50)
        
        print(f"ğŸ”¤ Ø§Ù„Ø­Ø±Ù: {analysis['letter']}")
        print(f"ğŸ’­ Ø§Ù„Ù…Ø¹Ù†Ù‰: {analysis['meaning']}")
        print(f"ğŸŒŸ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø«ÙˆØ±ÙŠØ©: {analysis['baserah_value']:.3f}")
        print(f"âš›ï¸ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ÙƒÙ…ÙŠØ©: {analysis['quantum_value']:.3f}")
        print(f"ğŸ“Š ØªÙƒØ±Ø§Ø± ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {analysis['frequency_in_database']}")
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ
        if 'revolutionary_analysis' in analysis:
            rev_analysis = analysis['revolutionary_analysis']
            print(f"\nğŸ§¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ:")
            print(f"   Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©: {rev_analysis['semantic_power']:.3f}")
            print(f"   Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ Ø§Ù„ÙƒÙ…ÙŠ: {rev_analysis['quantum_signature']:.3f}")
            if rev_analysis['letter_position_in_alphabet'] > 0:
                print(f"   Ø§Ù„Ù…ÙˆØ¶Ø¹ ÙÙŠ Ø§Ù„Ø£Ø¨Ø¬Ø¯ÙŠØ©: {rev_analysis['letter_position_in_alphabet']}")
        
        # Ø£Ù…Ø«Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        if analysis['example_words']:
            print(f"\nğŸ“ Ø£Ù…Ø«Ù„Ø© ÙƒÙ„Ù…Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±Ù:")
            for word in analysis['example_words'][:10]:
                print(f"   â€¢ {word}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø­Ø±Ù: {e}")


def analyze_text_interactive(engine):
    """ØªØ­Ù„ÙŠÙ„ Ù†Øµ ØªÙØ§Ø¹Ù„ÙŠ."""
    
    print("ğŸ“ ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ø¹Ø±Ø¨ÙŠ")
    print("=" * 50)
    
    text = input("ğŸ“ Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ: ").strip()
    
    if not text:
        print("âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ!")
        return
    
    print(f"\nğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ...")
    print("â³ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...")
    
    try:
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
        analysis = engine.analyze_text_revolutionary(text)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
        print("=" * 50)
        
        print(f"ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: {analysis['original_text']}")
        
        # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        stats = analysis['text_statistics']
        print(f"\nğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {stats['total_words']}")
        print(f"   ÙƒÙ„Ù…Ø§Øª Ù…Ø­Ù„Ù„Ø©: {stats['analyzed_words']}")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø±ÙˆÙ: {stats['total_letters']}")
        print(f"   Ø­Ø±ÙˆÙ ÙØ±ÙŠØ¯Ø©: {stats['unique_letters']}")
        print(f"   Ø¬Ø°ÙˆØ± ÙØ±ÙŠØ¯Ø©: {stats['unique_roots']}")
        print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {stats['average_semantic_weight']:.3f}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        print(f"\nğŸ”¤ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª:")
        for word_analysis in analysis['word_analyses'][:5]:  # Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª
            print(f"   â€¢ {word_analysis['word']}: {word_analysis['meaning']} (ÙˆØ²Ù†: {word_analysis['semantic_weight']:.3f})")
        
        if len(analysis['word_analyses']) > 5:
            print(f"   ... Ùˆ {len(analysis['word_analyses']) - 5} ÙƒÙ„Ù…Ø© Ø£Ø®Ø±Ù‰")
        
        # Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹
        print(f"\nğŸ”¤ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹:")
        for letter_info in analysis['most_frequent_letters_meanings'][:5]:
            print(f"   â€¢ {letter_info['letter']}: {letter_info['frequency']} Ù…Ø±Ø© - {letter_info['meaning']}")
        
        # Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        if analysis['unique_roots']:
            print(f"\nğŸŒ± Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            for root in analysis['unique_roots'][:10]:
                print(f"   â€¢ {root}")
        
        # Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ
        if 'basil_theories_analysis' in analysis:
            basil = analysis['basil_theories_analysis']
            print(f"\nğŸ§¬ ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ:")
            
            if 'zero_duality_text' in basil:
                zero_text = basil['zero_duality_text']
                print(f"   ğŸ”„ Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±: ØªÙˆØ§Ø²Ù† {zero_text['balance_percentage']:.1f}%")
            
            if 'filament_theory_text' in basil:
                filament_text = basil['filament_theory_text']
                print(f"   ğŸ§µ Ø§Ù„ÙØªØ§Ø¦Ù„: {filament_text['total_filaments']} ÙØªÙŠÙ„Ø© ({filament_text['primary_filaments']} Ø£ÙˆÙ„ÙŠØ©)")
        
        # Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        if analysis['revolutionary_insights']:
            print(f"\nğŸ’¡ Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø«ÙˆØ±ÙŠØ©:")
            for insight in analysis['revolutionary_insights']:
                print(f"   â€¢ {insight}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ: {e}")


def load_lexicons_interactive(engine):
    """ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ø¬Ù… ØªÙØ§Ø¹Ù„ÙŠ."""
    
    print("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ø¬Ù… Ø¥Ø¶Ø§ÙÙŠØ©")
    print("=" * 50)
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        loader = LexiconDataLoader(engine)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©
        print("ğŸ”— Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©:")
        for source_name, source in loader.data_sources.items():
            status = "âœ… Ù†Ø´Ø·" if source.is_active else "âŒ ØºÙŠØ± Ù†Ø´Ø·"
            print(f"   {source_name}: {source.name} ({source.source_type}) - {status}")
        
        print("\nØ®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„:")
        print("1. ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±")
        print("2. ØªØ­Ù…ÙŠÙ„ Ù…ØµØ¯Ø± Ù…Ø­Ø¯Ø¯")
        print("3. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
        
        choice = input("\nØ§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø®ÙŠØ§Ø±: ").strip()
        
        if choice == '1':
            print("\nğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±...")
            results = loader.load_all_available_sources()
            
            print("\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù…ÙŠÙ„:")
            for source_name, result in results.items():
                if result['success']:
                    print(f"   âœ… {source_name}: {result['entries_loaded']} Ù…Ø¯Ø®Ù„")
                else:
                    print(f"   âŒ {source_name}: {result['error']}")
        
        elif choice == '2':
            source_name = input("Ø£Ø¯Ø®Ù„ Ø§Ø³Ù… Ø§Ù„Ù…ØµØ¯Ø±: ").strip()
            if source_name in loader.data_sources:
                source = loader.data_sources[source_name]
                
                if source.source_type == 'api':
                    words = input("Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø§Øª Ù„Ù„Ø¨Ø­Ø« (Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„): ").strip().split(',')
                    words = [w.strip() for w in words if w.strip()]
                    result = loader.load_from_api(source_name, words)
                elif source.source_type == 'xml':
                    result = loader.load_from_xml(source_name)
                elif source.source_type == 'json':
                    result = loader.load_from_json(source_name)
                else:
                    result = {'success': False, 'error': 'Ù†ÙˆØ¹ Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…'}
                
                if result['success']:
                    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {result['entries_loaded']} Ù…Ø¯Ø®Ù„ Ù…Ù† {source_name}")
                else:
                    print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {result['error']}")
            else:
                print("âŒ Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ!")
        
        elif choice == '3':
            print("\nğŸ”„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
            from .lexicon_data_loader import create_sample_lexicon_files
            results = create_sample_lexicon_files()
            
            for format_type, result in results.items():
                if result['success']:
                    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù {format_type.upper()}: {result['entries_loaded']} Ù…Ø¯Ø®Ù„")
                else:
                    print(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù {format_type.upper()}: {result['error']}")
        
        else:
            print("âŒ Ø®ÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­!")
    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ø¬Ù…: {e}")


def show_engine_statistics(engine):
    """Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ."""
    
    print("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ")
    print("=" * 50)
    
    try:
        status = engine.get_engine_status()
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ
        info = status['engine_info']
        print(f"ğŸ¤– Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ: {info['name']}")
        print(f"ğŸ“¦ Ø§Ù„Ø¥ØµØ¯Ø§Ø±: {info['version']}")
        print(f"ğŸ“… ÙˆÙ‚Øª Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: {info['creation_time']}")
        
        # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        stats = status['statistics']
        print(f"\nğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
        print(f"   ÙƒÙ„Ù…Ø§Øª Ù…Ø­Ù„Ù„Ø©: {stats['words_analyzed']}")
        print(f"   Ø­Ø±ÙˆÙ Ù…Ø­Ù„Ù„Ø©: {stats['letters_analyzed']}")
        print(f"   Ø¬Ø°ÙˆØ± Ù…ÙƒØªØ´ÙØ©: {stats['roots_discovered']}")
        print(f"   Ù…Ø¹Ø§Ù†ÙŠ Ù…Ø³ØªØ®Ø±Ø¬Ø©: {stats['meanings_extracted']}")
        print(f"   ØªØ­Ù„ÙŠÙ„Ø§Øª Baserah: {stats['baserah_analyses_performed']}")
        print(f"   ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„: {stats['basil_theories_applications']}")
        print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {stats['average_semantic_weight']:.3f}")
        print(f"   Ø±Ø¤Ù‰ Ø«ÙˆØ±ÙŠØ©: {stats['total_revolutionary_insights']}")
        
        # Ø§Ù„Ù‚Ø¯Ø±Ø§Øª
        capabilities = status['capabilities']
        print(f"\nğŸ› ï¸ Ø§Ù„Ù‚Ø¯Ø±Ø§Øª:")
        for capability, enabled in capabilities.items():
            status_icon = "âœ…" if enabled else "âŒ"
            print(f"   {status_icon} {capability}")
        
        # Ø§Ù„Ù…Ø¹Ø§Ø¬Ù… Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        lexicons = status['integrated_lexicons']
        print(f"\nğŸ“š Ø§Ù„Ù…Ø¹Ø§Ø¬Ù… Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©:")
        for lexicon, count in lexicons.items():
            print(f"   ğŸ“– {lexicon}: {count} Ù…Ø¯Ø®Ù„")
        
        # Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        revolutionary = status['revolutionary_features']
        print(f"\nğŸŒŸ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©:")
        for feature, enabled in revolutionary.items():
            if enabled:
                print(f"   ğŸ”¥ {feature}")
        
        print(f"\nğŸ“ Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {status['database_path']}")
        print(f"ğŸ”¤ Ø¹Ø¯Ø¯ Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ: {status['letter_meanings_count']}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")


def run_engine_tests():
    """ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ."""
    
    print("ğŸ§ª ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ")
    print("=" * 50)
    
    try:
        from .test_arabic_lexicon import run_all_tests
        run_all_tests()
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª: {e}")


def show_all_letters_meanings(engine):
    """Ø¹Ø±Ø¶ Ø¯Ù„Ø§Ù„Ø§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ø±ÙˆÙ."""
    
    print("ğŸ”¤ Ø¯Ù„Ø§Ù„Ø§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    print("=" * 50)
    
    try:
        arabic_letters = ['Ø§', 'Ø¨', 'Øª', 'Ø«', 'Ø¬', 'Ø­', 'Ø®', 'Ø¯', 'Ø°', 'Ø±', 'Ø²', 'Ø³', 'Ø´', 'Øµ', 'Ø¶', 'Ø·', 'Ø¸', 'Ø¹', 'Øº', 'Ù', 'Ù‚', 'Ùƒ', 'Ù„', 'Ù…', 'Ù†', 'Ù‡', 'Ùˆ', 'ÙŠ']
        
        for letter in arabic_letters:
            if letter in engine.letter_meanings:
                meaning = engine.letter_meanings[letter]
                print(f"   {letter}: {meaning}")
            else:
                print(f"   {letter}: ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
        
        print(f"\nØ¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø±ÙˆÙ: {len(arabic_letters)}")
        print(f"Ø­Ø±ÙˆÙ Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„Ù…Ø¹Ù†Ù‰: {len([l for l in arabic_letters if l in engine.letter_meanings])}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ: {e}")


def search_in_lexicon(engine):
    """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¹Ø¬Ù…."""
    
    print("ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¹Ø¬Ù…")
    print("=" * 50)
    
    search_term = input("ğŸ“ Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ø£Ùˆ Ø¬Ø²Ø¡ Ù…Ù† ÙƒÙ„Ù…Ø© Ù„Ù„Ø¨Ø­Ø«: ").strip()
    
    if not search_term:
        print("âŒ ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ù„Ù„Ø¨Ø­Ø«!")
        return
    
    try:
        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
        result = engine.search_word_meanings(search_term, include_related=True)
        
        print(f"\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {search_term}")
        print("=" * 50)
        
        print(f"ğŸ”¤ Ø§Ù„ÙƒÙ„Ù…Ø©: {result['word']}")
        print(f"ğŸŒ± Ø§Ù„Ø¬Ø°Ø±: {result['root']}")
        print(f"ğŸ’­ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: {result['main_meaning']}")
        print(f"ğŸ“– Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…ÙØµÙ„: {result['detailed_meaning']}")
        print(f"âš–ï¸ Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {result['semantic_weight']:.3f}")
        
        # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
        if result['related_words']:
            print(f"\nğŸ”— ÙƒÙ„Ù…Ø§Øª Ø°Ø§Øª ØµÙ„Ø©:")
            for related_word in result['related_words']:
                print(f"   â€¢ {related_word}")
        
        # Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        if result['usage_examples']:
            print(f"\nğŸ“ Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:")
            for example in result['usage_examples']:
                print(f"   â€¢ {example}")
        
        # Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        if result['revolutionary_insights']:
            print(f"\nğŸ’¡ Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø«ÙˆØ±ÙŠØ©:")
            for insight in result['revolutionary_insights'][:5]:
                print(f"   â€¢ {insight}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©."""
    
    print_banner()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ø±Ùƒ
    print("ğŸ”„ ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ...")
    try:
        engine = ArabicLexiconEngine("InteractiveLexiconEngine")
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ: {e}")
        return
    
    while True:
        print_menu()
        
        try:
            choice = input("ğŸ¯ Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©: ").strip()
            
            if choice == '1':
                analyze_word_interactive(engine)
            elif choice == '2':
                explore_letter_interactive(engine)
            elif choice == '3':
                analyze_text_interactive(engine)
            elif choice == '4':
                load_lexicons_interactive(engine)
            elif choice == '5':
                show_engine_statistics(engine)
            elif choice == '6':
                run_engine_tests()
            elif choice == '7':
                show_all_letters_meanings(engine)
            elif choice == '8':
                search_in_lexicon(engine)
            elif choice == '0':
                print("\nğŸ‘‹ Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ!")
                print("ğŸ“š Ù†Ø±Ø§ÙƒÙ… ÙÙŠ Ø±Ø­Ù„Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ!")
                break
            else:
                print("âŒ Ø®ÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­! ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø±Ù‚Ù… Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©.")
            
            input("\nâ¸ï¸ Ø§Ø¶ØºØ· Enter Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©...")
            print("\n" + "="*70 + "\n")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
            break
        except Exception as e:
            print(f"\nğŸ’¥ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
            input("â¸ï¸ Ø§Ø¶ØºØ· Enter Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©...")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ÙˆØ¯Ø§Ø¹Ø§Ù‹!")
    except Exception as e:
        print(f"ğŸ’¥ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬: {e}")

#!/usr/bin/env python3
# baserah_expert_core.py - Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø®Ø¨ÙŠØ±Ø© Baserah Ø§Ù„Ù†Ù‚ÙŠØ©

import math
import json
import uuid
from datetime import datetime
from typing import Dict, List, Tuple, Union, Optional, Any, Set
from dataclasses import dataclass, field
from enum import Enum

class KnowledgeType(str, Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙÙŠ Ù†Ø¸Ø§Ù… Baserah."""
    FACT = "fact"  # Ø­Ù‚ÙŠÙ‚Ø©
    RULE = "rule"  # Ù‚Ø§Ø¹Ø¯Ø©
    HEURISTIC = "heuristic"  # Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¥Ø±Ø´Ø§Ø¯ÙŠ
    CONSTRAINT = "constraint"  # Ù‚ÙŠØ¯
    GOAL = "goal"  # Ù‡Ø¯Ù
    CONCEPT = "concept"  # Ù…ÙÙ‡ÙˆÙ…
    RELATIONSHIP = "relationship"  # Ø¹Ù„Ø§Ù‚Ø©
    BASERAH_PATTERN = "baserah_pattern"  # Ù†Ù…Ø· Baserah

class InferenceMethod(str, Enum):
    """Ø·Ø±Ù‚ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Baserah."""
    FORWARD_CHAINING = "forward_chaining"  # ØªØ³Ù„Ø³Ù„ Ø£Ù…Ø§Ù…ÙŠ
    BACKWARD_CHAINING = "backward_chaining"  # ØªØ³Ù„Ø³Ù„ Ø®Ù„ÙÙŠ
    HYBRID_CHAINING = "hybrid_chaining"  # ØªØ³Ù„Ø³Ù„ Ù‡Ø¬ÙŠÙ†
    SIGMOID_REASONING = "sigmoid_reasoning"  # Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ÙŠ
    LINEAR_REASONING = "linear_reasoning"  # Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø®Ø·ÙŠ
    QUANTUM_REASONING = "quantum_reasoning"  # Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙƒÙ…ÙŠ

@dataclass
class BaserahKnowledgeItem:
    """Ø¹Ù†ØµØ± Ù…Ø¹Ø±ÙØ© Baserah Ø§Ù„Ù†Ù‚ÙŠ."""
    type: KnowledgeType
    content: Any  # Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¹Ø±ÙØ©
    id: str = field(default_factory=lambda: f"knowledge_{uuid.uuid4()}")
    activation_level: float = 1.0  # Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ†Ø´ÙŠØ·
    relevance_score: float = 1.0  # Ø¯Ø±Ø¬Ø© Ø§Ù„ØµÙ„Ø©
    baserah_weight: float = 1.0  # ÙˆØ²Ù† Baserah
    metadata: Dict[str, Any] = field(default_factory=dict)
    creation_date: str = field(default_factory=lambda: datetime.now().isoformat())

@dataclass
class BaserahInferenceContext:
    """Ø³ÙŠØ§Ù‚ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Baserah."""
    method: InferenceMethod = InferenceMethod.HYBRID_CHAINING
    current_facts: Set[str] = field(default_factory=set)
    goal: Optional[str] = None
    max_depth: int = 10
    confidence_threshold: float = 0.7
    sigmoid_params: Dict[str, float] = field(default_factory=lambda: {'n': 1, 'k': 1.0, 'x0': 0.0, 'alpha': 1.0})
    linear_params: Dict[str, float] = field(default_factory=lambda: {'beta': 1.0, 'gamma': 0.0})
    quantum_factor: int = 1
    custom_properties: Dict[str, Any] = field(default_factory=dict)

@dataclass
class BaserahInferenceResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Baserah."""
    derived_facts: Set[str] = field(default_factory=set)
    explanation_path: List[str] = field(default_factory=list)
    confidence: float = 1.0
    success: bool = False
    message: str = ""
    baserah_score: float = 0.0  # Ù†Ù‚Ø§Ø· Baserah
    reasoning_trace: List[Dict[str, Any]] = field(default_factory=list)

class BaserahAdaptiveMatrix:
    """
    Ù…ØµÙÙˆÙØ© ØªÙƒÙŠÙÙŠØ© Baserah Ø§Ù„Ù†Ù‚ÙŠØ©
    ØªØ³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ ÙˆØ§Ù„Ø®Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…
    """
    
    def __init__(self, input_dim: int, output_dim: int):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØµÙÙˆÙØ© Ø§Ù„ØªÙƒÙŠÙÙŠØ© Baserah."""
        self.input_dim = input_dim
        self.output_dim = output_dim
        
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ù„ÙƒÙ„ Ø¹Ù‚Ø¯Ø©
        self.sigmoid_params = []
        for i in range(output_dim):
            self.sigmoid_params.append({
                'n': 1,
                'k': 1.0,
                'x0': 0.0,
                'alpha': 1.0
            })
        
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø®Ø·ÙŠØ© Ù„ÙƒÙ„ Ø¹Ù‚Ø¯Ø©
        self.linear_params = []
        for i in range(output_dim):
            self.linear_params.append({
                'beta': 1.0,
                'gamma': 0.0
            })
        
        # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø¯Ù…Ø¬ (Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ vs Ø®Ø·ÙŠ)
        self.mixing_weights = [0.5] * output_dim
        
        # Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…
        self.learning_rate = 0.01
    
    def baserah_sigmoid(self, x: float, n: int, k: float, x0: float, alpha: float) -> float:
        """Ø¯Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Baserah Ø§Ù„Ù†Ù‚ÙŠØ©."""
        try:
            exponent = -k * ((x - x0) ** n)
            if exponent > 700:  # ØªØ¬Ù†Ø¨ overflow
                return 0.0
            elif exponent < -700:
                return alpha
            return alpha / (1 + math.exp(exponent))
        except (OverflowError, ZeroDivisionError):
            return alpha / 2
    
    def baserah_linear(self, x: float, beta: float, gamma: float) -> float:
        """Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ… Baserah Ø§Ù„Ù†Ù‚ÙŠØ©."""
        return beta * x + gamma
    
    def forward(self, x: List[float]) -> List[float]:
        """Ø§Ù„ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù…ÙŠ Baserah Ø§Ù„Ù†Ù‚ÙŠ."""
        if len(x) != self.input_dim:
            raise ValueError(f"Expected {self.input_dim} inputs, got {len(x)}")
        
        outputs = []
        
        for i in range(self.output_dim):
            # Ø­Ø³Ø§Ø¨ Ù…Ø¯Ø®Ù„ Ø§Ù„Ø¹Ù‚Ø¯Ø© (Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª)
            node_input = sum(x)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯
            sigmoid_output = self.baserah_sigmoid(
                node_input,
                self.sigmoid_params[i]['n'],
                self.sigmoid_params[i]['k'],
                self.sigmoid_params[i]['x0'],
                self.sigmoid_params[i]['alpha']
            )
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø·ÙŠ
            linear_output = self.baserah_linear(
                node_input,
                self.linear_params[i]['beta'],
                self.linear_params[i]['gamma']
            )
            
            # Ø¯Ù…Ø¬ Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ ÙˆØ§Ù„Ø®Ø·ÙŠ
            mixed_output = (self.mixing_weights[i] * sigmoid_output + 
                          (1 - self.mixing_weights[i]) * linear_output)
            
            outputs.append(mixed_output)
        
        return outputs
    
    def update_parameters(self, error: List[float]):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø·Ø£."""
        for i in range(self.output_dim):
            if i < len(error):
                # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯
                self.sigmoid_params[i]['k'] -= self.learning_rate * error[i] * 0.1
                self.sigmoid_params[i]['alpha'] -= self.learning_rate * error[i] * 0.1
                
                # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø®Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…
                self.linear_params[i]['beta'] -= self.learning_rate * error[i] * 0.1
                self.linear_params[i]['gamma'] -= self.learning_rate * error[i] * 0.1
                
                # ØªØ­Ø¯ÙŠØ« Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø¯Ù…Ø¬
                self.mixing_weights[i] -= self.learning_rate * error[i] * 0.05
                self.mixing_weights[i] = max(0.0, min(1.0, self.mixing_weights[i]))

class BaserahExpertCore:
    """
    Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø®Ø¨ÙŠØ±Ø© Baserah Ø§Ù„Ù†Ù‚ÙŠØ©
    Ù†Ø¸Ø§Ù… Ø®Ø¨ÙŠØ± ÙŠØ¹Ù…Ù„ Ø¨Ù…Ù†Ù‡Ø¬ Baserah ÙÙ‚Ø· (Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ + Ø®Ø·ÙŠ + ØªÙƒÙ…ÙŠÙ…)
    """
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø®Ø¨ÙŠØ±Ø© Baserah."""
        self.knowledge_base: Dict[str, BaserahKnowledgeItem] = {}
        self.learning_model: Optional[BaserahAdaptiveMatrix] = None
        self.learning_history: List[Dict[str, Any]] = []
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.inference_count = 0
        self.success_count = 0
        self.total_confidence = 0.0
        
        print("ğŸ§  ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø®Ø¨ÙŠØ±Ø© Baserah Ø§Ù„Ù†Ù‚ÙŠØ©")
    
    def add_knowledge(self, item: BaserahKnowledgeItem):
        """Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ØµØ± Ù…Ø¹Ø±ÙØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©."""
        if not isinstance(item, BaserahKnowledgeItem):
            raise TypeError("ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø¹Ù†ØµØ± Ù…Ù† Ù†ÙˆØ¹ BaserahKnowledgeItem")
        
        self.knowledge_base[item.id] = item
        print(f"âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø±ÙØ© ({item.type}): {item.id}")
    
    def get_knowledge(self, item_id: str) -> Optional[BaserahKnowledgeItem]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ù†ØµØ± Ù…Ø¹Ø±ÙØ©."""
        return self.knowledge_base.get(item_id)
    
    def remove_knowledge(self, item_id: str):
        """Ø¥Ø²Ø§Ù„Ø© Ø¹Ù†ØµØ± Ù…Ø¹Ø±ÙØ©."""
        if item_id in self.knowledge_base:
            del self.knowledge_base[item_id]
            print(f"ğŸ—‘ï¸ ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {item_id}")
        else:
            print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø±ÙØ©: {item_id}")
    
    def infer(self, context: BaserahInferenceContext) -> BaserahInferenceResult:
        """ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Baserah."""
        self.inference_count += 1
        
        print(f"ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Baserah #{self.inference_count} Ø¨Ø·Ø±ÙŠÙ‚Ø© {context.method}")
        
        if context.method == InferenceMethod.FORWARD_CHAINING:
            result = self._forward_chaining(context)
        elif context.method == InferenceMethod.BACKWARD_CHAINING:
            result = self._backward_chaining(context)
        elif context.method == InferenceMethod.HYBRID_CHAINING:
            result = self._hybrid_chaining(context)
        elif context.method == InferenceMethod.SIGMOID_REASONING:
            result = self._sigmoid_reasoning(context)
        elif context.method == InferenceMethod.LINEAR_REASONING:
            result = self._linear_reasoning(context)
        elif context.method == InferenceMethod.QUANTUM_REASONING:
            result = self._quantum_reasoning(context)
        else:
            result = BaserahInferenceResult(
                success=False,
                message=f"Ø·Ø±ÙŠÙ‚Ø© Ø§Ø³ØªØ¯Ù„Ø§Ù„ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©: {context.method}"
            )
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        if result.success:
            self.success_count += 1
            self.total_confidence += result.confidence
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        self.learning_history.append({
            'timestamp': datetime.now().isoformat(),
            'method': context.method,
            'success': result.success,
            'confidence': result.confidence,
            'derived_facts_count': len(result.derived_facts)
        })
        
        print(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„. Ø§Ù„Ù†Ø¬Ø§Ø­: {result.success}, Ø§Ù„Ø«Ù‚Ø©: {result.confidence:.3f}")
        return result
    
    def _forward_chaining(self, context: BaserahInferenceContext) -> BaserahInferenceResult:
        """Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¨Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø£Ù…Ø§Ù…ÙŠ Baserah."""
        derived_facts = set(context.current_facts)
        explanation_path = []
        newly_derived = True
        iterations = 0
        
        while newly_derived and iterations < context.max_depth:
            newly_derived = False
            iterations += 1
            
            for item_id, item in self.knowledge_base.items():
                if item.type == KnowledgeType.RULE and item_id not in explanation_path:
                    rule_content = item.content
                    if isinstance(rule_content, dict) and "if" in rule_content and "then" in rule_content:
                        conditions = rule_content["if"]
                        conclusions = rule_content["then"]
                        
                        # ØªØ·Ø¨ÙŠÙ‚ ÙˆØ²Ù† Baserah
                        baserah_weight = item.baserah_weight
                        
                        if all(cond_id in derived_facts for cond_id in conditions):
                            for conc_id in conclusions:
                                if conc_id not in derived_facts:
                                    derived_facts.add(conc_id)
                                    explanation_path.append(item_id)
                                    explanation_path.append(conc_id)
                                    newly_derived = True
        
        final_derived = derived_facts - context.current_facts
        success = bool(final_derived)
        confidence = min(1.0, len(final_derived) / max(1, len(context.current_facts)))
        
        return BaserahInferenceResult(
            derived_facts=final_derived,
            explanation_path=explanation_path,
            confidence=confidence,
            success=success,
            message=f"ØªØ³Ù„Ø³Ù„ Ø£Ù…Ø§Ù…ÙŠ: {len(final_derived)} Ø­Ù‚Ø§Ø¦Ù‚ Ø¬Ø¯ÙŠØ¯Ø©",
            baserah_score=confidence * len(final_derived)
        )

    def _backward_chaining(self, context: BaserahInferenceContext) -> BaserahInferenceResult:
        """Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¨Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø®Ù„ÙÙŠ Baserah."""
        if context.goal is None:
            return BaserahInferenceResult(
                success=False,
                message="ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ù‡Ø¯Ù Ù„Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø®Ù„ÙÙŠ"
            )

        memo = {}
        explanation_path = []

        def prove_goal(goal_id, depth):
            if goal_id in memo:
                return memo[goal_id]
            if depth > context.max_depth:
                return False

            if goal_id in context.current_facts:
                memo[goal_id] = True
                return True

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚ÙˆØ§Ø¹Ø¯ Baserah
            for item_id, item in self.knowledge_base.items():
                if item.type == KnowledgeType.RULE:
                    rule_content = item.content
                    if isinstance(rule_content, dict) and "then" in rule_content:
                        if goal_id in rule_content["then"]:
                            conditions = rule_content["if"]

                            all_conditions_proven = True
                            for cond_id in conditions:
                                if not prove_goal(cond_id, depth + 1):
                                    all_conditions_proven = False
                                    break

                            if all_conditions_proven:
                                explanation_path.append(item_id)
                                explanation_path.append(goal_id)
                                memo[goal_id] = True
                                return True

            memo[goal_id] = False
            return False

        goal_proven = prove_goal(context.goal, 0)

        return BaserahInferenceResult(
            derived_facts={context.goal} if goal_proven else set(),
            explanation_path=explanation_path,
            confidence=1.0 if goal_proven else 0.0,
            success=goal_proven,
            message=f"ØªØ³Ù„Ø³Ù„ Ø®Ù„ÙÙŠ: {'Ù†Ø¬Ø­' if goal_proven else 'ÙØ´Ù„'} ÙÙŠ Ø¥Ø«Ø¨Ø§Øª {context.goal}",
            baserah_score=1.0 if goal_proven else 0.0
        )

    def _hybrid_chaining(self, context: BaserahInferenceContext) -> BaserahInferenceResult:
        """Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ù‡Ø¬ÙŠÙ† Baserah."""
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø®Ù„ÙÙŠ Ø£ÙˆÙ„Ø§Ù‹ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù‡Ø¯Ù
        if context.goal:
            backward_result = self._backward_chaining(context)
            if backward_result.success:
                return backward_result

        # Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø£Ù…Ø§Ù…ÙŠ
        forward_result = self._forward_chaining(context)

        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        return BaserahInferenceResult(
            derived_facts=forward_result.derived_facts,
            explanation_path=forward_result.explanation_path,
            confidence=forward_result.confidence,
            success=forward_result.success,
            message=f"Ù‡Ø¬ÙŠÙ†: {forward_result.message}",
            baserah_score=forward_result.baserah_score
        )

    def _sigmoid_reasoning(self, context: BaserahInferenceContext) -> BaserahInferenceResult:
        """Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ÙŠ Baserah."""
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ù„Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø«Ù‚Ø©
        derived_facts = set()
        explanation_path = []

        sigmoid_params = context.sigmoid_params

        for item_id, item in self.knowledge_base.items():
            if item.type == KnowledgeType.FACT:
                # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯
                x = item.activation_level
                confidence = self._calculate_sigmoid_confidence(x, sigmoid_params)

                if confidence >= context.confidence_threshold:
                    derived_facts.add(item_id)
                    explanation_path.append(item_id)

        success = bool(derived_facts)
        avg_confidence = sum(self._calculate_sigmoid_confidence(
            self.knowledge_base[fact_id].activation_level, sigmoid_params
        ) for fact_id in derived_facts) / max(1, len(derived_facts))

        return BaserahInferenceResult(
            derived_facts=derived_facts,
            explanation_path=explanation_path,
            confidence=avg_confidence,
            success=success,
            message=f"Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ÙŠ: {len(derived_facts)} Ø­Ù‚Ø§Ø¦Ù‚",
            baserah_score=avg_confidence * len(derived_facts)
        )

    def _linear_reasoning(self, context: BaserahInferenceContext) -> BaserahInferenceResult:
        """Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ø®Ø·ÙŠ Baserah."""
        derived_facts = set()
        explanation_path = []

        linear_params = context.linear_params

        for item_id, item in self.knowledge_base.items():
            if item.type == KnowledgeType.FACT:
                # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…
                x = item.activation_level
                confidence = self._calculate_linear_confidence(x, linear_params)

                if confidence >= context.confidence_threshold:
                    derived_facts.add(item_id)
                    explanation_path.append(item_id)

        success = bool(derived_facts)
        avg_confidence = sum(self._calculate_linear_confidence(
            self.knowledge_base[fact_id].activation_level, linear_params
        ) for fact_id in derived_facts) / max(1, len(derived_facts))

        return BaserahInferenceResult(
            derived_facts=derived_facts,
            explanation_path=explanation_path,
            confidence=avg_confidence,
            success=success,
            message=f"Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø®Ø·ÙŠ: {len(derived_facts)} Ø­Ù‚Ø§Ø¦Ù‚",
            baserah_score=avg_confidence * len(derived_facts)
        )

    def _quantum_reasoning(self, context: BaserahInferenceContext) -> BaserahInferenceResult:
        """Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„ÙƒÙ…ÙŠ Baserah."""
        derived_facts = set()
        explanation_path = []

        quantum_factor = context.quantum_factor

        for item_id, item in self.knowledge_base.items():
            if item.type == KnowledgeType.FACT:
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙ…ÙŠÙ… Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ†Ø´ÙŠØ·
                x = item.activation_level
                quantized_activation = self._apply_quantum_factor(x, quantum_factor)

                if quantized_activation >= context.confidence_threshold:
                    derived_facts.add(item_id)
                    explanation_path.append(item_id)

        success = bool(derived_facts)
        avg_confidence = sum(self._apply_quantum_factor(
            self.knowledge_base[fact_id].activation_level, quantum_factor
        ) for fact_id in derived_facts) / max(1, len(derived_facts))

        return BaserahInferenceResult(
            derived_facts=derived_facts,
            explanation_path=explanation_path,
            confidence=avg_confidence,
            success=success,
            message=f"Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙƒÙ…ÙŠ (Q={quantum_factor}): {len(derived_facts)} Ø­Ù‚Ø§Ø¦Ù‚",
            baserah_score=avg_confidence * len(derived_facts)
        )

    def _calculate_sigmoid_confidence(self, x: float, params: Dict[str, float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯."""
        try:
            n = params.get('n', 1)
            k = params.get('k', 1.0)
            x0 = params.get('x0', 0.0)
            alpha = params.get('alpha', 1.0)

            exponent = -k * ((x - x0) ** n)
            if exponent > 700:
                return 0.0
            elif exponent < -700:
                return alpha
            return alpha / (1 + math.exp(exponent))
        except (OverflowError, ZeroDivisionError):
            return 0.5

    def _calculate_linear_confidence(self, x: float, params: Dict[str, float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…."""
        beta = params.get('beta', 1.0)
        gamma = params.get('gamma', 0.0)
        result = beta * x + gamma
        return max(0.0, min(1.0, result))  # ØªÙ‚ÙŠÙŠØ¯ Ø¨ÙŠÙ† 0 Ùˆ 1

    def _apply_quantum_factor(self, x: float, quantum_factor: int) -> float:
        """ØªØ·Ø¨ÙŠÙ‚ Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒÙ…ÙŠÙ…."""
        if quantum_factor <= 1:
            return x

        # ØªÙƒÙ…ÙŠÙ… Ø§Ù„Ù‚ÙŠÙ…Ø©
        step_size = 1.0 / quantum_factor
        quantized = round(x / step_size) * step_size
        return max(0.0, min(1.0, quantized))

    def initialize_learning_model(self, input_dim: int, output_dim: int):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Baserah."""
        self.learning_model = BaserahAdaptiveMatrix(input_dim, output_dim)
        print(f"ğŸ§  ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Baserah: {input_dim}â†’{output_dim}")

    def learn_from_inference(self, context: BaserahInferenceContext, result: BaserahInferenceResult):
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„."""
        if not result.success:
            return

        # ØªØ­Ø¯ÙŠØ« Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªÙ†Ø´ÙŠØ· Ù„Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        for item_id in result.explanation_path:
            if item_id in self.knowledge_base:
                item = self.knowledge_base[item_id]
                item.activation_level += 0.1 * result.confidence
                item.activation_level = min(item.activation_level, 2.0)
                item.baserah_weight += 0.05 * result.baserah_score

        print(f"ğŸ“š ØªÙ… Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„: {len(result.derived_facts)} Ø­Ù‚Ø§Ø¦Ù‚ Ø¬Ø¯ÙŠØ¯Ø©")

    def get_statistics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…."""
        success_rate = self.success_count / max(1, self.inference_count)
        avg_confidence = self.total_confidence / max(1, self.success_count)

        return {
            'total_inferences': self.inference_count,
            'successful_inferences': self.success_count,
            'success_rate': success_rate,
            'average_confidence': avg_confidence,
            'knowledge_base_size': len(self.knowledge_base),
            'learning_history_size': len(self.learning_history)
        }

    def save_knowledge_base(self, file_path: str):
        """Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©."""
        try:
            kb_data = {}
            for item_id, item in self.knowledge_base.items():
                kb_data[item_id] = {
                    'type': item.type.value,
                    'content': item.content,
                    'activation_level': item.activation_level,
                    'relevance_score': item.relevance_score,
                    'baserah_weight': item.baserah_weight,
                    'metadata': item.metadata,
                    'creation_date': item.creation_date
                }

            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(kb_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {file_path}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {e}")

    def load_knowledge_base(self, file_path: str):
        """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                kb_data = json.load(f)

            self.knowledge_base = {}
            for item_id, item_data in kb_data.items():
                item = BaserahKnowledgeItem(
                    id=item_id,
                    type=KnowledgeType(item_data['type']),
                    content=item_data['content'],
                    activation_level=item_data.get('activation_level', 1.0),
                    relevance_score=item_data.get('relevance_score', 1.0),
                    baserah_weight=item_data.get('baserah_weight', 1.0),
                    metadata=item_data.get('metadata', {}),
                    creation_date=item_data.get('creation_date', datetime.now().isoformat())
                )
                self.knowledge_base[item_id] = item

            print(f"ğŸ“‚ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {len(self.knowledge_base)} Ø¹Ù†ØµØ±")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {e}")

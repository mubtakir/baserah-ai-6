#!/usr/bin/env python3
# quranic_analysis_engine.py - Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ
#
# ğŸ‘¨â€ğŸ’» Ø§Ù„Ù…Ø·ÙˆØ±: Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
# ğŸ§  Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø±ÙŠØ©: Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙÙƒØ§Ø± ÙˆØ§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ù…Ù† Ø¥Ø¨Ø¯Ø§Ø¹ Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
# ğŸ¤– Ø§Ù„ØªØ·ÙˆÙŠØ±: Ø£ÙƒÙˆØ§Ø¯ Ø¨Ø¯Ø§Ø¦ÙŠØ© ØªÙ… ØªØ·ÙˆÙŠØ±Ù‡Ø§ Ø¨Ù…Ø³Ø§Ø¹Ø¯Ø© ÙˆÙƒÙŠÙ„ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
# ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: 2025
# ğŸ•Œ Ø§Ù„Ù…Ø­Ø±Ùƒ: Ø£ÙˆÙ„ Ù…Ø­Ø±Ùƒ ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù… Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… Ø¨Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø§Ù„Ø«ÙˆØ±ÙŠØ©
# ğŸŒŸ Ø§Ù„Ù†Ø¸Ø§Ù…: Baserah Pure System - sigmoid + linear ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† AI ØªÙ‚Ù„ÙŠØ¯ÙŠ
# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… Ø¨Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø§Ù„Ø«ÙˆØ±ÙŠØ© ÙˆÙ†Ø¸Ø§Ù… Baserah Ø§Ù„Ù†Ù‚ÙŠ

import os
import sys
import json
import sqlite3
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import math

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„ÙÙ†ÙŠØ©
from artistic_intelligence.baserah_core import (
    baserah_sigmoid, baserah_linear, baserah_quantum_sigmoid
)

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
from .ai_oop_foundation import BaserahExpertExplorerFoundation
from .revolutionary_mother_equation import ConcreteRevolutionaryMotherEquation
from .arabic_lexicon_engine import ArabicLexiconEngine


class QuranicTextType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©."""
    VERSE = "Ø¢ÙŠØ©"
    SURAH = "Ø³ÙˆØ±Ø©"
    JUZ = "Ø¬Ø²Ø¡"
    HIZB = "Ø­Ø²Ø¨"
    QUARTER = "Ø±Ø¨Ø¹"
    WORD = "ÙƒÙ„Ù…Ø©"
    LETTER = "Ø­Ø±Ù"


class SurahType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø³ÙˆØ±."""
    MECCAN = "Ù…ÙƒÙŠØ©"
    MEDINAN = "Ù…Ø¯Ù†ÙŠØ©"


@dataclass
class QuranicVerse:
    """Ø¢ÙŠØ© Ù‚Ø±Ø¢Ù†ÙŠØ© Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§ØªÙ‡Ø§."""
    surah_number: int
    verse_number: int
    arabic_text: str
    surah_name: str
    surah_type: SurahType
    revelation_order: int
    juz_number: int
    hizb_number: int
    quarter_number: int
    words_count: int
    letters_count: int
    metadata: Dict[str, Any]


@dataclass
class QuranicAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ø«ÙˆØ±ÙŠ Ù„Ù†Øµ Ù‚Ø±Ø¢Ù†ÙŠ."""
    text: str
    text_type: QuranicTextType
    baserah_analysis: Dict[str, float]
    basil_theories_application: Dict[str, Any]
    letter_frequency: Dict[str, int]
    word_analysis: List[Dict[str, Any]]
    numerical_miracle: Dict[str, Any]
    semantic_weight: float
    revolutionary_insights: List[str]
    divine_patterns: List[str]
    linguistic_features: Dict[str, Any]
    timestamp: str


@dataclass
class NumericalMiracle:
    """Ø¥Ø¹Ø¬Ø§Ø² Ø±Ù‚Ù…ÙŠ Ù‚Ø±Ø¢Ù†ÙŠ."""
    miracle_type: str
    description: str
    numbers_involved: List[int]
    baserah_calculation: float
    basil_theory_applied: str
    significance_level: float
    verification_method: str


class QuranicAnalysisEngine(BaserahExpertExplorerFoundation):
    """
    Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ.
    
    ÙŠØ¯Ù…Ø¬:
    1. Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ´ÙƒÙŠÙ„
    2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ§Øª Ø¨Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø§Ù„Ø«ÙˆØ±ÙŠØ©
    3. Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø¨Ù†Ø¸Ø§Ù… Baserah
    4. Ø¯Ø±Ø§Ø³Ø© Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø±ÙˆÙ ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ
    5. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ© ÙˆØ§Ù„Ù…Ø¹Ø¬Ø²Ø§Øª Ø§Ù„Ù„ØºÙˆÙŠØ©
    """
    
    def __init__(self, engine_name: str = "QuranicAnalysisEngine",
                 mother_inheritance: ConcreteRevolutionaryMotherEquation = None):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ."""
        
        # Ø§Ù„ÙˆØ±Ø§Ø«Ø© Ù…Ù† Ø§Ù„Ø£Ø³Ø³ Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        super().__init__(engine_name, mother_inheritance)
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ
        self.engine_name = engine_name
        self.creation_time = datetime.now()
        self.version = "1.0.0 - Quranic Analysis Engine"
        
        # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†
        self.quran_db_path = "data/quran_analysis.db"
        self.quran_text_path = "data/quran/quran_text.json"
        
        # Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ù…Ø¯Ù…Ø¬
        self.lexicon_engine = ArabicLexiconEngine("QuranicLexiconEngine")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ
        self.engine_stats = {
            'verses_analyzed': 0,
            'surahs_analyzed': 0,
            'words_analyzed': 0,
            'letters_analyzed': 0,
            'numerical_miracles_discovered': 0,
            'divine_patterns_found': 0,
            'baserah_analyses_performed': 0,
            'basil_theories_applications': 0,
            'total_revolutionary_insights': 0,
            'average_semantic_weight': 0.0
        }
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.quran_data = {
            'total_surahs': 114,
            'total_verses': 6236,  # Ø¹Ø¯Ø¯ Ø§Ù„Ø¢ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø¹Ø¯ Ø§Ù„ÙƒÙˆÙÙŠ
            'total_words': 77439,  # ØªÙ‚Ø±ÙŠØ¨ÙŠ
            'total_letters': 323015,  # ØªÙ‚Ø±ÙŠØ¨ÙŠ
            'meccan_surahs': 86,
            'medinan_surahs': 28
        }
        
        # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø³ÙˆØ±
        self.surah_names = self._load_surah_names()
        
        # ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._initialize_quran_database()
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ
        self._load_quran_text()
        
        print(f"ğŸ•Œ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ: {engine_name}")
        print(f"ğŸ“– Ø³ÙˆØ± Ø§Ù„Ù‚Ø±Ø¢Ù†: {self.quran_data['total_surahs']}")
        print(f"ğŸ“ Ø¢ÙŠØ§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†: {self.quran_data['total_verses']}")
        print(f"ğŸ§¬ Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø§Ù„Ø«ÙˆØ±ÙŠØ©")
        print(f"ğŸŒŸ Ù…Ø¯Ù…Ø¬ Ù…Ø¹ Ù†Ø¸Ø§Ù… Baserah Ø§Ù„Ù†Ù‚ÙŠ")
    
    def _load_surah_names(self) -> Dict[int, Dict[str, str]]:
        """ØªØ­Ù…ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø³ÙˆØ±."""
        
        surah_names = {
            1: {"arabic": "Ø§Ù„ÙØ§ØªØ­Ø©", "english": "Al-Fatiha", "type": "meccan"},
            2: {"arabic": "Ø§Ù„Ø¨Ù‚Ø±Ø©", "english": "Al-Baqarah", "type": "medinan"},
            3: {"arabic": "Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù†", "english": "Aal-E-Imran", "type": "medinan"},
            4: {"arabic": "Ø§Ù„Ù†Ø³Ø§Ø¡", "english": "An-Nisa", "type": "medinan"},
            5: {"arabic": "Ø§Ù„Ù…Ø§Ø¦Ø¯Ø©", "english": "Al-Maidah", "type": "medinan"},
            6: {"arabic": "Ø§Ù„Ø£Ù†Ø¹Ø§Ù…", "english": "Al-An'am", "type": "meccan"},
            7: {"arabic": "Ø§Ù„Ø£Ø¹Ø±Ø§Ù", "english": "Al-A'raf", "type": "meccan"},
            8: {"arabic": "Ø§Ù„Ø£Ù†ÙØ§Ù„", "english": "Al-Anfal", "type": "medinan"},
            9: {"arabic": "Ø§Ù„ØªÙˆØ¨Ø©", "english": "At-Tawbah", "type": "medinan"},
            10: {"arabic": "ÙŠÙˆÙ†Ø³", "english": "Yunus", "type": "meccan"},
            11: {"arabic": "Ù‡ÙˆØ¯", "english": "Hud", "type": "meccan"},
            12: {"arabic": "ÙŠÙˆØ³Ù", "english": "Yusuf", "type": "meccan"},
            13: {"arabic": "Ø§Ù„Ø±Ø¹Ø¯", "english": "Ar-Ra'd", "type": "medinan"},
            14: {"arabic": "Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ…", "english": "Ibrahim", "type": "meccan"},
            15: {"arabic": "Ø§Ù„Ø­Ø¬Ø±", "english": "Al-Hijr", "type": "meccan"},
            16: {"arabic": "Ø§Ù„Ù†Ø­Ù„", "english": "An-Nahl", "type": "meccan"},
            17: {"arabic": "Ø§Ù„Ø¥Ø³Ø±Ø§Ø¡", "english": "Al-Isra", "type": "meccan"},
            18: {"arabic": "Ø§Ù„ÙƒÙ‡Ù", "english": "Al-Kahf", "type": "meccan"},
            19: {"arabic": "Ù…Ø±ÙŠÙ…", "english": "Maryam", "type": "meccan"},
            20: {"arabic": "Ø·Ù‡", "english": "Taha", "type": "meccan"},
            # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø³ÙˆØ±...
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³ÙˆØ± Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø³Ø·
        remaining_surahs = {
            21: {"arabic": "Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡", "english": "Al-Anbiya", "type": "meccan"},
            22: {"arabic": "Ø§Ù„Ø­Ø¬", "english": "Al-Hajj", "type": "medinan"},
            23: {"arabic": "Ø§Ù„Ù…Ø¤Ù…Ù†ÙˆÙ†", "english": "Al-Mu'minun", "type": "meccan"},
            24: {"arabic": "Ø§Ù„Ù†ÙˆØ±", "english": "An-Nur", "type": "medinan"},
            25: {"arabic": "Ø§Ù„ÙØ±Ù‚Ø§Ù†", "english": "Al-Furqan", "type": "meccan"},
            # ... ÙŠÙ…ÙƒÙ† Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
            112: {"arabic": "Ø§Ù„Ø¥Ø®Ù„Ø§Øµ", "english": "Al-Ikhlas", "type": "meccan"},
            113: {"arabic": "Ø§Ù„ÙÙ„Ù‚", "english": "Al-Falaq", "type": "meccan"},
            114: {"arabic": "Ø§Ù„Ù†Ø§Ø³", "english": "An-Nas", "type": "meccan"}
        }
        
        surah_names.update(remaining_surahs)
        return surah_names
    
    def _initialize_quran_database(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†."""
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        os.makedirs(os.path.dirname(self.quran_db_path), exist_ok=True)
        
        try:
            conn = sqlite3.connect(self.quran_db_path)
            cursor = conn.cursor()
            
            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø³ÙˆØ±
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS surahs (
                    id INTEGER PRIMARY KEY,
                    number INTEGER UNIQUE NOT NULL,
                    arabic_name TEXT NOT NULL,
                    english_name TEXT,
                    type TEXT,
                    verses_count INTEGER,
                    revelation_order INTEGER,
                    baserah_analysis TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¢ÙŠØ§Øª
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS verses (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    surah_number INTEGER NOT NULL,
                    verse_number INTEGER NOT NULL,
                    arabic_text TEXT NOT NULL,
                    words_count INTEGER,
                    letters_count INTEGER,
                    juz_number INTEGER,
                    hizb_number INTEGER,
                    quarter_number INTEGER,
                    baserah_analysis TEXT,
                    basil_theories TEXT,
                    semantic_weight REAL,
                    numerical_miracles TEXT,
                    revolutionary_insights TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(surah_number, verse_number)
                )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS quranic_words (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    word TEXT NOT NULL,
                    root TEXT,
                    surah_number INTEGER,
                    verse_number INTEGER,
                    word_position INTEGER,
                    frequency_in_quran INTEGER,
                    baserah_value REAL,
                    semantic_weight REAL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS numerical_miracles (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    miracle_type TEXT NOT NULL,
                    description TEXT,
                    numbers_involved TEXT,
                    baserah_calculation REAL,
                    basil_theory TEXT,
                    significance_level REAL,
                    verification_method TEXT,
                    discovered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS divine_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pattern_type TEXT NOT NULL,
                    description TEXT,
                    occurrences TEXT,
                    baserah_analysis TEXT,
                    revolutionary_significance TEXT,
                    discovered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ÙÙ‡Ø§Ø±Ø³ Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_verse_surah ON verses(surah_number)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_word_text ON quranic_words(word)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_miracle_type ON numerical_miracles(miracle_type)')
            
            conn.commit()
            conn.close()
            
            print(f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†: {self.quran_db_path}")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
    
    def _load_quran_text(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ."""
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©
        os.makedirs(os.path.dirname(self.quran_text_path), exist_ok=True)
        
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ØŒ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø£Ø³Ø§Ø³ÙŠ
        if not os.path.exists(self.quran_text_path):
            self._create_sample_quran_data()
        
        try:
            with open(self.quran_text_path, 'r', encoding='utf-8') as f:
                self.quran_text_data = json.load(f)
            
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ Ù…Ù†: {self.quran_text_path}")
            
        except Exception as e:
            print(f"âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ: {e}")
            self.quran_text_data = {}
    
    def _create_sample_quran_data(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø±Ø¢Ù†ÙŠØ© ØªØ¬Ø±ÙŠØ¨ÙŠØ©."""
        
        # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø¢ÙŠØ§Øª Ø§Ù„Ù…Ø´Ù‡ÙˆØ±Ø©
        sample_quran_data = {
            "metadata": {
                "source": "Quranic Analysis Engine",
                "version": "1.0.0",
                "created": datetime.now().isoformat(),
                "description": "Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø±Ø¢Ù†ÙŠØ© ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ"
            },
            "surahs": {
                "1": {
                    "name": "Ø§Ù„ÙØ§ØªØ­Ø©",
                    "english_name": "Al-Fatiha",
                    "type": "meccan",
                    "verses_count": 7,
                    "verses": {
                        "1": "Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù",
                        "2": "Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯Ù Ù„ÙÙ„ÙÙ‘Ù‡Ù Ø±ÙØ¨ÙÙ‘ Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù",
                        "3": "Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù",
                        "4": "Ù…ÙØ§Ù„ÙÙƒÙ ÙŠÙÙˆÙ’Ù…Ù Ø§Ù„Ø¯ÙÙ‘ÙŠÙ†Ù",
                        "5": "Ø¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ¹Ù’Ø¨ÙØ¯Ù ÙˆÙØ¥ÙÙŠÙÙ‘Ø§ÙƒÙ Ù†ÙØ³Ù’ØªÙØ¹ÙÙŠÙ†Ù",
                        "6": "Ø§Ù‡Ù’Ø¯ÙÙ†ÙØ§ Ø§Ù„ØµÙÙ‘Ø±ÙØ§Ø·Ù Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙÙ‚ÙÙŠÙ…Ù",
                        "7": "ØµÙØ±ÙØ§Ø·Ù Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù Ø£ÙÙ†Ù’Ø¹ÙÙ…Ù’ØªÙ Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ØºÙÙŠÙ’Ø±Ù Ø§Ù„Ù’Ù…ÙØºÙ’Ø¶ÙÙˆØ¨Ù Ø¹ÙÙ„ÙÙŠÙ’Ù‡ÙÙ…Ù’ ÙˆÙÙ„ÙØ§ Ø§Ù„Ø¶ÙÙ‘Ø§Ù„ÙÙ‘ÙŠÙ†Ù"
                    }
                },
                "112": {
                    "name": "Ø§Ù„Ø¥Ø®Ù„Ø§Øµ",
                    "english_name": "Al-Ikhlas",
                    "type": "meccan",
                    "verses_count": 4,
                    "verses": {
                        "1": "Ù‚ÙÙ„Ù’ Ù‡ÙÙˆÙ Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø£ÙØ­ÙØ¯ÙŒ",
                        "2": "Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„ØµÙÙ‘Ù…ÙØ¯Ù",
                        "3": "Ù„ÙÙ…Ù’ ÙŠÙÙ„ÙØ¯Ù’ ÙˆÙÙ„ÙÙ…Ù’ ÙŠÙÙˆÙ„ÙØ¯Ù’",
                        "4": "ÙˆÙÙ„ÙÙ…Ù’ ÙŠÙÙƒÙÙ† Ù„ÙÙ‘Ù‡Ù ÙƒÙÙÙÙˆÙ‹Ø§ Ø£ÙØ­ÙØ¯ÙŒ"
                    }
                },
                "113": {
                    "name": "Ø§Ù„ÙÙ„Ù‚",
                    "english_name": "Al-Falaq",
                    "type": "meccan",
                    "verses_count": 5,
                    "verses": {
                        "1": "Ù‚ÙÙ„Ù’ Ø£ÙØ¹ÙÙˆØ°Ù Ø¨ÙØ±ÙØ¨ÙÙ‘ Ø§Ù„Ù’ÙÙÙ„ÙÙ‚Ù",
                        "2": "Ù…ÙÙ† Ø´ÙØ±ÙÙ‘ Ù…ÙØ§ Ø®ÙÙ„ÙÙ‚Ù",
                        "3": "ÙˆÙÙ…ÙÙ† Ø´ÙØ±ÙÙ‘ ØºÙØ§Ø³ÙÙ‚Ù Ø¥ÙØ°ÙØ§ ÙˆÙÙ‚ÙØ¨Ù",
                        "4": "ÙˆÙÙ…ÙÙ† Ø´ÙØ±ÙÙ‘ Ø§Ù„Ù†ÙÙ‘ÙÙÙ‘Ø§Ø«ÙØ§ØªÙ ÙÙÙŠ Ø§Ù„Ù’Ø¹ÙÙ‚ÙØ¯Ù",
                        "5": "ÙˆÙÙ…ÙÙ† Ø´ÙØ±ÙÙ‘ Ø­ÙØ§Ø³ÙØ¯Ù Ø¥ÙØ°ÙØ§ Ø­ÙØ³ÙØ¯Ù"
                    }
                },
                "114": {
                    "name": "Ø§Ù„Ù†Ø§Ø³",
                    "english_name": "An-Nas",
                    "type": "meccan",
                    "verses_count": 6,
                    "verses": {
                        "1": "Ù‚ÙÙ„Ù’ Ø£ÙØ¹ÙÙˆØ°Ù Ø¨ÙØ±ÙØ¨ÙÙ‘ Ø§Ù„Ù†ÙÙ‘Ø§Ø³Ù",
                        "2": "Ù…ÙÙ„ÙÙƒÙ Ø§Ù„Ù†ÙÙ‘Ø§Ø³Ù",
                        "3": "Ø¥ÙÙ„ÙÙ°Ù‡Ù Ø§Ù„Ù†ÙÙ‘Ø§Ø³Ù",
                        "4": "Ù…ÙÙ† Ø´ÙØ±ÙÙ‘ Ø§Ù„Ù’ÙˆÙØ³Ù’ÙˆÙØ§Ø³Ù Ø§Ù„Ù’Ø®ÙÙ†ÙÙ‘Ø§Ø³Ù",
                        "5": "Ø§Ù„ÙÙ‘Ø°ÙÙŠ ÙŠÙÙˆÙØ³Ù’ÙˆÙØ³Ù ÙÙÙŠ ØµÙØ¯ÙÙˆØ±Ù Ø§Ù„Ù†ÙÙ‘Ø§Ø³Ù",
                        "6": "Ù…ÙÙ†Ù Ø§Ù„Ù’Ø¬ÙÙ†ÙÙ‘Ø©Ù ÙˆÙØ§Ù„Ù†ÙÙ‘Ø§Ø³Ù"
                    }
                }
            }
        }
        
        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        with open(self.quran_text_path, 'w', encoding='utf-8') as f:
            json.dump(sample_quran_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø±Ø¢Ù†ÙŠØ© ØªØ¬Ø±ÙŠØ¨ÙŠØ©: {self.quran_text_path}")
    
    def analyze_verse_revolutionary(self, surah_number: int, verse_number: int, 
                                  deep_analysis: bool = True) -> QuranicAnalysis:
        """
        ØªØ­Ù„ÙŠÙ„ Ø«ÙˆØ±ÙŠ Ø´Ø§Ù…Ù„ Ù„Ø¢ÙŠØ© Ù‚Ø±Ø¢Ù†ÙŠØ©.
        
        Args:
            surah_number: Ø±Ù‚Ù… Ø§Ù„Ø³ÙˆØ±Ø©
            verse_number: Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©
            deep_analysis: ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù…Ø¹ Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„
            
        Returns:
            QuranicAnalysis: ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¢ÙŠØ©
        """
        
        print(f"ğŸ•Œ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ù„Ù„Ø¢ÙŠØ©: {surah_number}:{verse_number}")
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©
        verse_text = self._get_verse_text(surah_number, verse_number)
        
        if not verse_text:
            raise ValueError(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ© {surah_number}:{verse_number}")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ù„Ù„ØªØ­Ù„ÙŠÙ„
        clean_text = self._remove_diacritics(verse_text)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        words = clean_text.split()
        word_analyses = []
        
        for word in words:
            try:
                word_analysis = self.lexicon_engine.analyze_word_revolutionary(word, deep_analysis=False)
                word_analyses.append({
                    'word': word,
                    'root': word_analysis.root,
                    'meaning': word_analysis.meaning,
                    'semantic_weight': word_analysis.semantic_weight,
                    'baserah_analysis': word_analysis.baserah_analysis
                })
            except Exception as e:
                print(f"âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø© '{word}': {e}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ
        letter_frequency = self._analyze_letter_frequency(clean_text)
        
        # ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ Baserah
        baserah_analysis = self._apply_baserah_to_verse(verse_text, word_analyses)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„
        basil_theories = self._apply_basil_theories_to_verse(verse_text, word_analyses) if deep_analysis else {}
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ
        numerical_miracle = self._discover_numerical_miracles(surah_number, verse_number, verse_text)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
        semantic_weight = self._calculate_verse_semantic_weight(word_analyses, baserah_analysis)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        revolutionary_insights = self._generate_verse_insights(surah_number, verse_number, verse_text, word_analyses)
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©
        divine_patterns = self._discover_divine_patterns(verse_text, baserah_analysis)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºÙˆÙŠØ©
        linguistic_features = self._analyze_linguistic_features(verse_text)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
        analysis = QuranicAnalysis(
            text=verse_text,
            text_type=QuranicTextType.VERSE,
            baserah_analysis=baserah_analysis,
            basil_theories_application=basil_theories,
            letter_frequency=letter_frequency,
            word_analysis=word_analyses,
            numerical_miracle=numerical_miracle,
            semantic_weight=semantic_weight,
            revolutionary_insights=revolutionary_insights,
            divine_patterns=divine_patterns,
            linguistic_features=linguistic_features,
            timestamp=datetime.now().isoformat()
        )
        
        # Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._save_verse_analysis(surah_number, verse_number, analysis)
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self._update_engine_statistics(analysis)
        
        print(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ù„Ù„Ø¢ÙŠØ©: {surah_number}:{verse_number}")
        
        return analysis

    def _get_verse_text(self, surah_number: int, verse_number: int) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©."""

        try:
            if hasattr(self, 'quran_text_data') and 'surahs' in self.quran_text_data:
                surah_data = self.quran_text_data['surahs'].get(str(surah_number))
                if surah_data and 'verses' in surah_data:
                    return surah_data['verses'].get(str(verse_number), '')

            return ""

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©: {e}")
            return ""

    def _remove_diacritics(self, text: str) -> str:
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ù…Ù† Ø§Ù„Ù†Øµ."""

        # Ø±Ù…ÙˆØ² Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        diacritics = [
            '\u064B', '\u064C', '\u064D', '\u064E', '\u064F', '\u0650',  # ØªÙ†ÙˆÙŠÙ† ÙˆØ­Ø±ÙƒØ§Øª
            '\u0651', '\u0652', '\u0653', '\u0654', '\u0655', '\u0656',  # Ø´Ø¯Ø© ÙˆØ³ÙƒÙˆÙ†
            '\u0657', '\u0658', '\u0659', '\u065A', '\u065B', '\u065C',  # Ø¹Ù„Ø§Ù…Ø§Øª Ø£Ø®Ø±Ù‰
            '\u065D', '\u065E', '\u065F', '\u0670'  # Ø¹Ù„Ø§Ù…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        ]

        clean_text = text
        for diacritic in diacritics:
            clean_text = clean_text.replace(diacritic, '')

        return clean_text

    def _analyze_letter_frequency(self, text: str) -> Dict[str, int]:
        """ØªØ­Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø­Ø±ÙˆÙ."""

        frequency = {}

        for char in text:
            if char.isalpha() and 'Ø§' <= char <= 'ÙŠ':  # Ø­Ø±ÙˆÙ Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·
                frequency[char] = frequency.get(char, 0) + 1

        return frequency

    def _apply_baserah_to_verse(self, verse_text: str, word_analyses: List[Dict[str, Any]]) -> Dict[str, float]:
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ Baserah Ø¹Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ©."""

        # Ø¬Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        semantic_weights = [w['semantic_weight'] for w in word_analyses if 'semantic_weight' in w]

        if not semantic_weights:
            return {'total_value': 0.0, 'average_value': 0.0, 'harmony_index': 0.0}

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        total_value = sum(semantic_weights)
        average_value = total_value / len(semantic_weights)

        # Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„ØªÙ†Ø§ØºÙ… Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ
        variance = sum((v - average_value) ** 2 for v in semantic_weights) / len(semantic_weights)
        harmony_index = baserah_sigmoid(1.0 - variance, n=1, k=3.0, x0=0.5, alpha=1.0)

        # ØªØ·Ø¨ÙŠÙ‚ Ø¯ÙˆØ§Ù„ Baserah Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        quantum_value = baserah_quantum_sigmoid(average_value, n=1000, k=2.0, x0=0.5, alpha=1.2)
        linear_trend = baserah_linear(average_value, slope=1.5, intercept=0.1)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¥Ù„Ù‡ÙŠØ© (Divine Value)
        divine_multiplier = len(verse_text) / 100.0  # Ø¹Ø§Ù…Ù„ Ø§Ù„Ø·ÙˆÙ„
        divine_value = baserah_sigmoid(average_value * divine_multiplier, n=1, k=1.0, x0=0.7, alpha=1.5)

        return {
            'total_value': total_value,
            'average_value': average_value,
            'harmony_index': harmony_index,
            'quantum_value': quantum_value,
            'linear_trend': linear_trend,
            'divine_value': divine_value,
            'verse_length_factor': divine_multiplier,
            'baserah_signature': f"Q_{total_value:.3f}_{harmony_index:.3f}_{divine_value:.3f}"
        }

    def _apply_basil_theories_to_verse(self, verse_text: str, word_analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ©."""

        basil_theories = {}

        if not word_analyses:
            return basil_theories

        semantic_weights = [w['semantic_weight'] for w in word_analyses if 'semantic_weight' in w]

        # Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©
        positive_words = [w for i, w in enumerate(word_analyses) if i % 2 == 0]
        negative_words = [w for i, w in enumerate(word_analyses) if i % 2 == 1]

        positive_sum = sum(w['semantic_weight'] for w in positive_words if 'semantic_weight' in w)
        negative_sum = sum(w['semantic_weight'] for w in negative_words if 'semantic_weight' in w)
        divine_balance = abs(positive_sum - negative_sum)

        basil_theories['zero_duality_quranic'] = {
            'positive_sum': positive_sum,
            'negative_sum': negative_sum,
            'divine_balance': divine_balance,
            'is_divinely_balanced': divine_balance < 0.05,  # ØªÙˆØ§Ø²Ù† Ø¥Ù„Ù‡ÙŠ Ø£Ø¯Ù‚
            'balance_percentage': (1 - divine_balance) * 100,
            'theory': 'Zero Duality Theory - Quranic Application'
        }

        # Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©
        if len(word_analyses) >= 2:
            first_half = word_analyses[:len(word_analyses)//2]
            second_half = word_analyses[len(word_analyses)//2:]

            first_half_avg = sum(w['semantic_weight'] for w in first_half if 'semantic_weight' in w) / len(first_half) if first_half else 0
            second_half_avg = sum(w['semantic_weight'] for w in second_half if 'semantic_weight' in w) / len(second_half) if second_half else 0

            divine_angle = abs(first_half_avg - second_half_avg) * 90

            basil_theories['perpendicular_opposites_quranic'] = {
                'first_half_value': first_half_avg,
                'second_half_value': second_half_avg,
                'divine_angle': divine_angle,
                'is_divinely_perpendicular': abs(divine_angle - 90) < 5,  # Ø¯Ù‚Ø© Ø¥Ù„Ù‡ÙŠØ©
                'theory': 'Perpendicular Opposites Theory - Quranic Application'
            }

        # Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©
        quranic_filaments = []
        for i, word_analysis in enumerate(word_analyses):
            filament = {
                'filament_id': i,
                'word': word_analysis['word'],
                'semantic_weight': word_analysis.get('semantic_weight', 0),
                'meaning': word_analysis.get('meaning', ''),
                'is_divine_primary': word_analysis.get('semantic_weight', 0) > 0.7,  # ÙØªÙŠÙ„Ø© Ø¥Ù„Ù‡ÙŠØ© Ø£ÙˆÙ„ÙŠØ©
                'divine_significance': word_analysis.get('semantic_weight', 0) * len(word_analysis['word'])
            }
            quranic_filaments.append(filament)

        basil_theories['filament_theory_quranic'] = {
            'quranic_filaments': quranic_filaments,
            'total_filaments': len(quranic_filaments),
            'divine_primary_filaments': len([f for f in quranic_filaments if f['is_divine_primary']]),
            'divine_reconstruction_possible': len(quranic_filaments) > 0,
            'strongest_divine_filament': max(quranic_filaments, key=lambda x: x['divine_significance']) if quranic_filaments else None,
            'theory': 'Filament Theory - Quranic Application'
        }

        return basil_theories

    def _discover_numerical_miracles(self, surah_number: int, verse_number: int, verse_text: str) -> Dict[str, Any]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ."""

        miracles = {}

        # Ø¥Ø¹Ø¬Ø§Ø² Ø±Ù‚Ù… Ø§Ù„Ø³ÙˆØ±Ø© ÙˆØ§Ù„Ø¢ÙŠØ©
        surah_verse_sum = surah_number + verse_number
        surah_verse_product = surah_number * verse_number

        # ØªØ·Ø¨ÙŠÙ‚ Ø¯ÙˆØ§Ù„ Baserah Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        sum_baserah = baserah_sigmoid(surah_verse_sum / 100.0, n=1, k=1.0, x0=0.5, alpha=1.0)
        product_baserah = baserah_sigmoid(surah_verse_product / 1000.0, n=1, k=1.5, x0=0.5, alpha=1.0)

        miracles['surah_verse_numerology'] = {
            'surah_number': surah_number,
            'verse_number': verse_number,
            'sum': surah_verse_sum,
            'product': surah_verse_product,
            'sum_baserah_value': sum_baserah,
            'product_baserah_value': product_baserah,
            'is_miraculous': sum_baserah > 0.7 or product_baserah > 0.7
        }

        # Ø¥Ø¹Ø¬Ø§Ø² Ø·ÙˆÙ„ Ø§Ù„Ø¢ÙŠØ©
        verse_length = len(verse_text)
        words_count = len(verse_text.split())
        letters_count = len([c for c in verse_text if c.isalpha()])

        # Ù†Ø³Ø¨Ø© Ø°Ù‡Ø¨ÙŠØ© Ù‚Ø±Ø¢Ù†ÙŠØ©
        if words_count > 0:
            golden_ratio_quranic = letters_count / words_count
            golden_baserah = baserah_sigmoid(golden_ratio_quranic / 10.0, n=1, k=2.0, x0=0.5, alpha=1.0)

            miracles['golden_ratio_quranic'] = {
                'letters_count': letters_count,
                'words_count': words_count,
                'ratio': golden_ratio_quranic,
                'baserah_value': golden_baserah,
                'is_golden_miraculous': abs(golden_ratio_quranic - 1.618) < 0.5  # Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©
            }

        # Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù… 19 (Ø¥Ø¹Ø¬Ø§Ø² Ù…Ø´Ù‡ÙˆØ± ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù†)
        if verse_length % 19 == 0 or letters_count % 19 == 0 or words_count % 19 == 0:
            miracles['nineteen_miracle'] = {
                'verse_length_divisible': verse_length % 19 == 0,
                'letters_divisible': letters_count % 19 == 0,
                'words_divisible': words_count % 19 == 0,
                'significance': 'Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù… 19 ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…'
            }

        # Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„ØªÙ…Ø§Ø«Ù„
        clean_text = self._remove_diacritics(verse_text).replace(' ', '')
        is_palindromic = clean_text == clean_text[::-1]

        if is_palindromic:
            miracles['palindromic_miracle'] = {
                'is_palindromic': True,
                'significance': 'Ø¢ÙŠØ© Ù…ØªÙ…Ø§Ø«Ù„Ø© (ØªÙ‚Ø±Ø£ Ù†ÙØ³Ù‡Ø§ Ù…Ù† Ø§Ù„Ø£Ù…Ø§Ù… ÙˆØ§Ù„Ø®Ù„Ù)',
                'divine_symmetry': True
            }

        return miracles

    def _calculate_verse_semantic_weight(self, word_analyses: List[Dict[str, Any]],
                                       baserah_analysis: Dict[str, float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ù„Ù„Ø¢ÙŠØ©."""

        if not word_analyses:
            return 0.0

        # Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ
        words_weight = sum(w.get('semantic_weight', 0) for w in word_analyses) / len(word_analyses)
        harmony_weight = baserah_analysis.get('harmony_index', 0.5)
        divine_weight = baserah_analysis.get('divine_value', 0.5)

        # Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù…Ø¹ Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©
        semantic_weight = (words_weight * 0.4 + harmony_weight * 0.3 + divine_weight * 0.3)

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ
        return baserah_sigmoid(semantic_weight * 2.0, n=1, k=2.0, x0=0.6, alpha=1.2)

    def _generate_verse_insights(self, surah_number: int, verse_number: int,
                               verse_text: str, word_analyses: List[Dict[str, Any]]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¤Ù‰ Ø«ÙˆØ±ÙŠØ© Ù„Ù„Ø¢ÙŠØ©."""

        insights = []

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¢ÙŠØ©
        surah_name = self.surah_names.get(surah_number, {}).get('arabic', f'Ø§Ù„Ø³ÙˆØ±Ø© {surah_number}')
        insights.append(f"Ù‡Ø°Ù‡ Ø§Ù„Ø¢ÙŠØ© Ù…Ù† Ø³ÙˆØ±Ø© {surah_name} Ø§Ù„Ù…Ø¨Ø§Ø±ÙƒØ©")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„ØªØ±ÙƒÙŠØ¨ Ø§Ù„Ù„ØºÙˆÙŠ
        words_count = len(word_analyses)
        if words_count <= 3:
            insights.append("Ø¢ÙŠØ© Ù…Ø®ØªØµØ±Ø© ÙˆÙ…Ø±ÙƒØ²Ø©ØŒ ÙƒÙ„ ÙƒÙ„Ù…Ø© ÙÙŠÙ‡Ø§ Ù„Ù‡Ø§ ÙˆØ²Ù† Ø¹Ø¸ÙŠÙ…")
        elif words_count <= 7:
            insights.append("Ø¢ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© Ø§Ù„Ø·ÙˆÙ„ØŒ ØªØ­Ù…Ù„ Ù…Ø¹Ø§Ù†ÙŠ Ù…ØªÙˆØ§Ø²Ù†Ø©")
        else:
            insights.append("Ø¢ÙŠØ© Ø·ÙˆÙŠÙ„Ø© ØºÙ†ÙŠØ© Ø¨Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ ÙˆØ§Ù„Ø¯Ù„Ø§Ù„Ø§Øª")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
        high_weight_words = [w for w in word_analyses if w.get('semantic_weight', 0) > 0.7]
        if high_weight_words:
            key_words = [w['word'] for w in high_weight_words[:3]]
            insights.append(f"Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø­ÙˆØ±ÙŠØ© ÙÙŠ Ø§Ù„Ø¢ÙŠØ©: {', '.join(key_words)}")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ø¬Ø°ÙˆØ±
        roots = list(set(w['root'] for w in word_analyses if w.get('root')))
        if len(roots) > len(word_analyses) * 0.7:
            insights.append("ØªÙ†ÙˆØ¹ Ù„ØºÙˆÙŠ Ø¹Ø§Ù„ÙŠ ÙÙŠ Ø§Ù„Ø¬Ø°ÙˆØ±ØŒ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø«Ø±Ø§Ø¡ Ø§Ù„Ù…Ø¹Ù†Ù‰")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¥Ù„Ù‡ÙŠ
        if len(word_analyses) % 2 == 0:
            insights.append("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø²ÙˆØ¬ÙŠØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¥Ù„Ù‡ÙŠ")
        else:
            insights.append("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙØ±Ø¯ÙŠØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ­Ø¯Ø§Ù†ÙŠØ© Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ù‚Ø·Ø¹Ø© (Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª)
        if any(len(word) == 1 and word in ['Ø§Ù„Ù…', 'Ø§Ù„Ø±', 'Ø­Ù…', 'Ø·Ù‡', 'ÙŠØ³'] for word in [w['word'] for w in word_analyses]):
            insights.append("ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­Ø±ÙˆÙ Ù…Ù‚Ø·Ø¹Ø©ØŒ Ù…Ù† Ø£Ø³Ø±Ø§Ø± Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„Ø¹Ø¸ÙŠÙ…Ø©")

        return insights

    def _discover_divine_patterns(self, verse_text: str, baserah_analysis: Dict[str, float]) -> List[str]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©."""

        patterns = []

        # Ù†Ù…Ø· Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¥Ù„Ù‡ÙŠ
        harmony_index = baserah_analysis.get('harmony_index', 0)
        if harmony_index > 0.8:
            patterns.append("Ù†Ù…Ø· Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¥Ù„Ù‡ÙŠ: ØªÙ†Ø§ØºÙ… Ø¹Ø§Ù„ÙŠ Ø¨ÙŠÙ† Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¢ÙŠØ©")

        # Ù†Ù…Ø· Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©
        divine_value = baserah_analysis.get('divine_value', 0)
        if divine_value > 0.7:
            patterns.append("Ù†Ù…Ø· Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©: Ù…Ø³ØªÙˆÙ‰ Ø±ÙˆØ­Ø§Ù†ÙŠ Ø¹Ø§Ù„ÙŠ ÙÙŠ Ø§Ù„Ø¢ÙŠØ©")

        # Ù†Ù…Ø· Ø§Ù„ØªÙƒØ±Ø§Ø±
        words = verse_text.split()
        word_counts = {}
        for word in words:
            clean_word = self._remove_diacritics(word)
            word_counts[clean_word] = word_counts.get(clean_word, 0) + 1

        repeated_words = [word for word, count in word_counts.items() if count > 1]
        if repeated_words:
            patterns.append(f"Ù†Ù…Ø· Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¥Ù„Ù‡ÙŠ: ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª {', '.join(repeated_words)} Ù„Ù„ØªØ£ÙƒÙŠØ¯")

        # Ù†Ù…Ø· Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø¥Ù„Ù‡ÙŠ
        verse_length = len(verse_text)
        if verse_length in [19, 38, 57, 76, 95, 114]:  # Ù…Ø¶Ø§Ø¹ÙØ§Øª 19
            patterns.append("Ù†Ù…Ø· Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø¥Ù„Ù‡ÙŠ: Ø·ÙˆÙ„ Ø§Ù„Ø¢ÙŠØ© ÙŠØªØ¨Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ù…Ø¹Ø¬Ø²")

        return patterns

    def _analyze_linguistic_features(self, verse_text: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºÙˆÙŠØ©."""

        features = {}

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·ÙˆÙ„
        features['length_analysis'] = {
            'total_characters': len(verse_text),
            'letters_only': len([c for c in verse_text if c.isalpha()]),
            'words_count': len(verse_text.split()),
            'average_word_length': len([c for c in verse_text if c.isalpha()]) / len(verse_text.split()) if verse_text.split() else 0
        }

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ
        letter_analysis = self._analyze_letter_frequency(self._remove_diacritics(verse_text))
        features['letter_analysis'] = {
            'unique_letters': len(letter_analysis),
            'most_frequent_letter': max(letter_analysis.items(), key=lambda x: x[1]) if letter_analysis else ('', 0),
            'letter_diversity': len(letter_analysis) / len([c for c in verse_text if c.isalpha()]) if verse_text else 0
        }

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        features['pattern_analysis'] = {
            'has_repetition': len(set(verse_text.split())) < len(verse_text.split()),
            'starts_with_praise': verse_text.strip().startswith(('Ø§Ù„Ø­Ù…Ø¯', 'Ø³Ø¨Ø­', 'ØªØ¨Ø§Ø±Ùƒ')),
            'ends_with_divine_name': verse_text.strip().endswith(('Ø§Ù„Ù„Ù‡', 'Ø§Ù„Ø¹Ù„ÙŠÙ…', 'Ø§Ù„Ø­ÙƒÙŠÙ…', 'Ø§Ù„Ø±Ø­ÙŠÙ…')),
            'contains_divine_names': any(name in verse_text for name in ['Ø§Ù„Ù„Ù‡', 'Ø§Ù„Ø±Ø­Ù…Ù†', 'Ø§Ù„Ø±Ø­ÙŠÙ…', 'Ø±Ø¨'])
        }

        return features

    def _save_verse_analysis(self, surah_number: int, verse_number: int, analysis: QuranicAnalysis):
        """Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""

        try:
            conn = sqlite3.connect(self.quran_db_path)
            cursor = conn.cursor()

            # Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ©
            cursor.execute('''
                INSERT OR REPLACE INTO verses
                (surah_number, verse_number, arabic_text, words_count, letters_count,
                 baserah_analysis, basil_theories, semantic_weight, numerical_miracles, revolutionary_insights)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                surah_number,
                verse_number,
                analysis.text,
                len(analysis.word_analysis),
                analysis.linguistic_features.get('length_analysis', {}).get('letters_only', 0),
                json.dumps(analysis.baserah_analysis, ensure_ascii=False),
                json.dumps(analysis.basil_theories_application, ensure_ascii=False),
                analysis.semantic_weight,
                json.dumps(analysis.numerical_miracle, ensure_ascii=False),
                json.dumps(analysis.revolutionary_insights, ensure_ascii=False)
            ))

            # Ø­ÙØ¸ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠØ©
            for i, word_analysis in enumerate(analysis.word_analysis):
                cursor.execute('''
                    INSERT OR REPLACE INTO quranic_words
                    (word, root, surah_number, verse_number, word_position, semantic_weight)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    word_analysis['word'],
                    word_analysis.get('root', ''),
                    surah_number,
                    verse_number,
                    i + 1,
                    word_analysis.get('semantic_weight', 0)
                ))

            # Ø­ÙØ¸ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ
            for miracle_type, miracle_data in analysis.numerical_miracle.items():
                if isinstance(miracle_data, dict):
                    cursor.execute('''
                        INSERT INTO numerical_miracles
                        (miracle_type, description, numbers_involved, significance_level)
                        VALUES (?, ?, ?, ?)
                    ''', (
                        miracle_type,
                        json.dumps(miracle_data, ensure_ascii=False),
                        json.dumps([surah_number, verse_number], ensure_ascii=False),
                        miracle_data.get('baserah_value', 0) if 'baserah_value' in miracle_data else 0.5
                    ))

            # Ø­ÙØ¸ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©
            for pattern in analysis.divine_patterns:
                cursor.execute('''
                    INSERT INTO divine_patterns
                    (pattern_type, description, occurrences)
                    VALUES (?, ?, ?)
                ''', (
                    'verse_pattern',
                    pattern,
                    json.dumps([f"{surah_number}:{verse_number}"], ensure_ascii=False)
                ))

            conn.commit()
            conn.close()

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ©: {e}")

    def _update_engine_statistics(self, analysis: QuranicAnalysis):
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ."""

        self.engine_stats['verses_analyzed'] += 1
        self.engine_stats['words_analyzed'] += len(analysis.word_analysis)
        self.engine_stats['letters_analyzed'] += analysis.linguistic_features.get('length_analysis', {}).get('letters_only', 0)
        self.engine_stats['baserah_analyses_performed'] += 1

        if analysis.basil_theories_application:
            self.engine_stats['basil_theories_applications'] += len(analysis.basil_theories_application)

        if analysis.numerical_miracle:
            self.engine_stats['numerical_miracles_discovered'] += len(analysis.numerical_miracle)

        if analysis.divine_patterns:
            self.engine_stats['divine_patterns_found'] += len(analysis.divine_patterns)

        self.engine_stats['total_revolutionary_insights'] += len(analysis.revolutionary_insights)

        # ØªØ­Ø¯ÙŠØ« Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
        current_avg = self.engine_stats['average_semantic_weight']
        verses_count = self.engine_stats['verses_analyzed']
        new_avg = ((current_avg * (verses_count - 1)) + analysis.semantic_weight) / verses_count
        self.engine_stats['average_semantic_weight'] = new_avg

    def analyze_surah_revolutionary(self, surah_number: int, deep_analysis: bool = True) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø«ÙˆØ±ÙŠ Ø´Ø§Ù…Ù„ Ù„Ø³ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©."""

        print(f"ğŸ•Œ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ù„Ù„Ø³ÙˆØ±Ø©: {surah_number}")

        if surah_number not in self.surah_names:
            raise ValueError(f"Ø±Ù‚Ù… Ø§Ù„Ø³ÙˆØ±Ø© ØºÙŠØ± ØµØ­ÙŠØ­: {surah_number}")

        surah_info = self.surah_names[surah_number]
        surah_name = surah_info['arabic']

        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢ÙŠØ§Øª Ø§Ù„Ø³ÙˆØ±Ø©
        surah_data = self.quran_text_data.get('surahs', {}).get(str(surah_number), {})
        verses = surah_data.get('verses', {})

        if not verses:
            raise ValueError(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¢ÙŠØ§Øª Ø§Ù„Ø³ÙˆØ±Ø© {surah_number}")

        # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ø¢ÙŠØ©
        verse_analyses = []
        total_semantic_weight = 0.0
        all_words = []
        all_letters_freq = {}
        all_numerical_miracles = {}
        all_divine_patterns = []

        for verse_num in sorted(verses.keys(), key=int):
            try:
                verse_analysis = self.analyze_verse_revolutionary(surah_number, int(verse_num), deep_analysis)
                verse_analyses.append(verse_analysis)

                total_semantic_weight += verse_analysis.semantic_weight
                all_words.extend(verse_analysis.word_analysis)

                # Ø¬Ù…Ø¹ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø­Ø±ÙˆÙ
                for letter, freq in verse_analysis.letter_frequency.items():
                    all_letters_freq[letter] = all_letters_freq.get(letter, 0) + freq

                # Ø¬Ù…Ø¹ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ
                for miracle_type, miracle_data in verse_analysis.numerical_miracle.items():
                    if miracle_type not in all_numerical_miracles:
                        all_numerical_miracles[miracle_type] = []
                    all_numerical_miracles[miracle_type].append(miracle_data)

                # Ø¬Ù…Ø¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©
                all_divine_patterns.extend(verse_analysis.divine_patterns)

            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ© {verse_num}: {e}")

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆØ±Ø© ÙƒÙƒÙ„
        surah_baserah_analysis = self._analyze_surah_baserah(verse_analyses)
        surah_basil_theories = self._apply_basil_theories_to_surah(verse_analyses) if deep_analysis else {}
        surah_numerical_miracles = self._discover_surah_numerical_miracles(surah_number, verse_analyses)
        surah_linguistic_features = self._analyze_surah_linguistic_features(verse_analyses)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        surah_statistics = {
            'surah_number': surah_number,
            'surah_name': surah_name,
            'surah_type': surah_info['type'],
            'total_verses': len(verse_analyses),
            'total_words': len(all_words),
            'total_letters': sum(all_letters_freq.values()),
            'average_semantic_weight': total_semantic_weight / len(verse_analyses) if verse_analyses else 0,
            'unique_letters': len(all_letters_freq),
            'numerical_miracles_count': len(all_numerical_miracles),
            'divine_patterns_count': len(set(all_divine_patterns))
        }

        # Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ù„Ù„Ø³ÙˆØ±Ø©
        surah_insights = self._generate_surah_insights(surah_number, surah_statistics, verse_analyses)

        surah_analysis = {
            'surah_info': surah_info,
            'surah_statistics': surah_statistics,
            'verse_analyses': verse_analyses,
            'surah_baserah_analysis': surah_baserah_analysis,
            'surah_basil_theories': surah_basil_theories,
            'surah_numerical_miracles': surah_numerical_miracles,
            'surah_linguistic_features': surah_linguistic_features,
            'letter_frequency_surah': all_letters_freq,
            'divine_patterns_surah': list(set(all_divine_patterns)),
            'revolutionary_insights_surah': surah_insights,
            'analysis_timestamp': datetime.now().isoformat()
        }

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.engine_stats['surahs_analyzed'] += 1

        print(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ù„Ù„Ø³ÙˆØ±Ø©: {surah_name}")

        return surah_analysis

    def _analyze_surah_baserah(self, verse_analyses: List[QuranicAnalysis]) -> Dict[str, float]:
        """ØªØ­Ù„ÙŠÙ„ Baserah Ù„Ù„Ø³ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©."""

        if not verse_analyses:
            return {}

        # Ø¬Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¢ÙŠØ§Øª
        verse_weights = [analysis.semantic_weight for analysis in verse_analyses]
        verse_harmonies = [analysis.baserah_analysis.get('harmony_index', 0) for analysis in verse_analyses]
        verse_divine_values = [analysis.baserah_analysis.get('divine_value', 0) for analysis in verse_analyses]

        # Ø­Ø³Ø§Ø¨ Ù‚ÙŠÙ… Ø§Ù„Ø³ÙˆØ±Ø©
        surah_total_weight = sum(verse_weights)
        surah_average_weight = surah_total_weight / len(verse_weights)
        surah_harmony = sum(verse_harmonies) / len(verse_harmonies)
        surah_divine_value = sum(verse_divine_values) / len(verse_divine_values)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ†Ø§ØºÙ… Ø¨ÙŠÙ† Ø§Ù„Ø¢ÙŠØ§Øª
        weight_variance = sum((w - surah_average_weight) ** 2 for w in verse_weights) / len(verse_weights)
        inter_verse_harmony = baserah_sigmoid(1.0 - weight_variance, n=1, k=2.0, x0=0.5, alpha=1.0)

        # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¥Ù„Ù‡ÙŠØ© Ù„Ù„Ø³ÙˆØ±Ø©
        surah_length_factor = len(verse_analyses) / 100.0
        surah_divine_signature = baserah_sigmoid(surah_divine_value * surah_length_factor, n=1, k=1.5, x0=0.6, alpha=1.3)

        return {
            'surah_total_weight': surah_total_weight,
            'surah_average_weight': surah_average_weight,
            'surah_harmony': surah_harmony,
            'surah_divine_value': surah_divine_value,
            'inter_verse_harmony': inter_verse_harmony,
            'surah_divine_signature': surah_divine_signature,
            'surah_length_factor': surah_length_factor,
            'verses_count': len(verse_analyses)
        }

    def _apply_basil_theories_to_surah(self, verse_analyses: List[QuranicAnalysis]) -> Dict[str, Any]:
        """ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙˆØ±Ø©."""

        if not verse_analyses:
            return {}

        basil_theories = {}

        # Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³ÙˆØ±Ø©
        positive_verses = [v for i, v in enumerate(verse_analyses) if i % 2 == 0]
        negative_verses = [v for i, v in enumerate(verse_analyses) if i % 2 == 1]

        positive_sum = sum(v.semantic_weight for v in positive_verses)
        negative_sum = sum(v.semantic_weight for v in negative_verses)
        surah_balance = abs(positive_sum - negative_sum)

        basil_theories['zero_duality_surah'] = {
            'positive_verses_sum': positive_sum,
            'negative_verses_sum': negative_sum,
            'surah_balance': surah_balance,
            'is_surah_balanced': surah_balance < 0.1,
            'balance_percentage': (1 - surah_balance) * 100,
            'total_verses': len(verse_analyses)
        }

        # Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³ÙˆØ±Ø©
        if len(verse_analyses) >= 2:
            first_half = verse_analyses[:len(verse_analyses)//2]
            second_half = verse_analyses[len(verse_analyses)//2:]

            first_half_avg = sum(v.semantic_weight for v in first_half) / len(first_half)
            second_half_avg = sum(v.semantic_weight for v in second_half) / len(second_half)

            surah_perpendicular_angle = abs(first_half_avg - second_half_avg) * 90

            basil_theories['perpendicular_opposites_surah'] = {
                'first_half_avg': first_half_avg,
                'second_half_avg': second_half_avg,
                'surah_angle': surah_perpendicular_angle,
                'is_surah_perpendicular': abs(surah_perpendicular_angle - 90) < 10
            }

        # Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³ÙˆØ±Ø©
        surah_filaments = []
        for i, verse_analysis in enumerate(verse_analyses):
            filament = {
                'verse_number': i + 1,
                'semantic_weight': verse_analysis.semantic_weight,
                'words_count': len(verse_analysis.word_analysis),
                'is_primary_verse': verse_analysis.semantic_weight > 0.7,
                'divine_significance': verse_analysis.semantic_weight * len(verse_analysis.word_analysis)
            }
            surah_filaments.append(filament)

        basil_theories['filament_theory_surah'] = {
            'surah_filaments': surah_filaments,
            'total_verse_filaments': len(surah_filaments),
            'primary_verse_filaments': len([f for f in surah_filaments if f['is_primary_verse']]),
            'strongest_verse_filament': max(surah_filaments, key=lambda x: x['divine_significance']) if surah_filaments else None
        }

        return basil_theories

    def _discover_surah_numerical_miracles(self, surah_number: int, verse_analyses: List[QuranicAnalysis]) -> Dict[str, Any]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ Ù„Ù„Ø³ÙˆØ±Ø©."""

        miracles = {}

        # Ø¥Ø¹Ø¬Ø§Ø² Ø±Ù‚Ù… Ø§Ù„Ø³ÙˆØ±Ø©
        surah_baserah = baserah_sigmoid(surah_number / 114.0, n=1, k=1.0, x0=0.5, alpha=1.0)

        miracles['surah_number_miracle'] = {
            'surah_number': surah_number,
            'position_in_quran': surah_number / 114.0,
            'baserah_value': surah_baserah,
            'is_miraculous_position': surah_baserah > 0.7
        }

        # Ø¥Ø¹Ø¬Ø§Ø² Ø¹Ø¯Ø¯ Ø§Ù„Ø¢ÙŠØ§Øª
        verses_count = len(verse_analyses)
        verses_baserah = baserah_sigmoid(verses_count / 100.0, n=1, k=1.5, x0=0.5, alpha=1.0)

        miracles['verses_count_miracle'] = {
            'verses_count': verses_count,
            'baserah_value': verses_baserah,
            'is_miraculous_count': verses_baserah > 0.6
        }

        # Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„ØªÙˆØ§Ø²Ù† ÙÙŠ Ø§Ù„Ø³ÙˆØ±Ø©
        total_words = sum(len(v.word_analysis) for v in verse_analyses)
        total_letters = sum(v.linguistic_features.get('length_analysis', {}).get('letters_only', 0) for v in verse_analyses)

        if total_words > 0:
            letters_words_ratio = total_letters / total_words
            ratio_baserah = baserah_sigmoid(letters_words_ratio / 10.0, n=1, k=2.0, x0=0.5, alpha=1.0)

            miracles['surah_balance_miracle'] = {
                'total_words': total_words,
                'total_letters': total_letters,
                'ratio': letters_words_ratio,
                'baserah_value': ratio_baserah,
                'is_balanced_miracle': ratio_baserah > 0.5
            }

        # Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù… 19 Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³ÙˆØ±Ø©
        if (verses_count % 19 == 0 or total_words % 19 == 0 or
            total_letters % 19 == 0 or surah_number % 19 == 0):

            miracles['nineteen_miracle_surah'] = {
                'verses_divisible': verses_count % 19 == 0,
                'words_divisible': total_words % 19 == 0,
                'letters_divisible': total_letters % 19 == 0,
                'surah_number_divisible': surah_number % 19 == 0,
                'significance': 'Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù… 19 Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³ÙˆØ±Ø©'
            }

        return miracles

    def _analyze_surah_linguistic_features(self, verse_analyses: List[QuranicAnalysis]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºÙˆÙŠØ© Ù„Ù„Ø³ÙˆØ±Ø©."""

        features = {}

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        total_verses = len(verse_analyses)
        total_words = sum(len(v.word_analysis) for v in verse_analyses)
        total_letters = sum(v.linguistic_features.get('length_analysis', {}).get('letters_only', 0) for v in verse_analyses)

        features['general_statistics'] = {
            'total_verses': total_verses,
            'total_words': total_words,
            'total_letters': total_letters,
            'average_words_per_verse': total_words / total_verses if total_verses > 0 else 0,
            'average_letters_per_verse': total_letters / total_verses if total_verses > 0 else 0,
            'average_letters_per_word': total_letters / total_words if total_words > 0 else 0
        }

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†ÙˆØ¹
        all_words = []
        for verse_analysis in verse_analyses:
            all_words.extend([w['word'] for w in verse_analysis.word_analysis])

        unique_words = len(set(all_words))
        word_diversity = unique_words / total_words if total_words > 0 else 0

        features['diversity_analysis'] = {
            'unique_words': unique_words,
            'total_words': total_words,
            'word_diversity_ratio': word_diversity,
            'repetition_level': 1 - word_diversity
        }

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        verse_lengths = [len(v.word_analysis) for v in verse_analyses]
        features['pattern_analysis'] = {
            'shortest_verse_length': min(verse_lengths) if verse_lengths else 0,
            'longest_verse_length': max(verse_lengths) if verse_lengths else 0,
            'verse_length_variance': sum((l - sum(verse_lengths)/len(verse_lengths))**2 for l in verse_lengths) / len(verse_lengths) if verse_lengths else 0,
            'has_consistent_pattern': max(verse_lengths) - min(verse_lengths) <= 3 if verse_lengths else False
        }

        return features

    def _generate_surah_insights(self, surah_number: int, surah_statistics: Dict[str, Any],
                               verse_analyses: List[QuranicAnalysis]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¤Ù‰ Ø«ÙˆØ±ÙŠØ© Ù„Ù„Ø³ÙˆØ±Ø©."""

        insights = []

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ø³ÙˆØ±Ø©
        surah_name = surah_statistics['surah_name']
        surah_type = surah_statistics['surah_type']
        insights.append(f"Ø³ÙˆØ±Ø© {surah_name} Ù…Ù† Ø§Ù„Ø³ÙˆØ± Ø§Ù„{surah_type}Ø© Ø§Ù„Ù…Ø¨Ø§Ø±ÙƒØ©")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ø·ÙˆÙ„
        verses_count = surah_statistics['total_verses']
        if verses_count <= 10:
            insights.append("Ø³ÙˆØ±Ø© Ù‚ØµÙŠØ±Ø© Ù…Ø±ÙƒØ²Ø©ØŒ ÙƒÙ„ Ø¢ÙŠØ© ÙÙŠÙ‡Ø§ Ù„Ù‡Ø§ ÙˆÙ‚Ø¹ Ø®Ø§Øµ")
        elif verses_count <= 50:
            insights.append("Ø³ÙˆØ±Ø© Ù…ØªÙˆØ³Ø·Ø© Ø§Ù„Ø·ÙˆÙ„ØŒ ØªØ­Ù…Ù„ Ù…Ø¹Ø§Ù†ÙŠ Ù…ØªÙˆØ§Ø²Ù†Ø© ÙˆÙ…ØªØ¯Ø±Ø¬Ø©")
        else:
            insights.append("Ø³ÙˆØ±Ø© Ø·ÙˆÙŠÙ„Ø© ØºÙ†ÙŠØ© Ø¨Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„Ù‚ØµØµ")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„ØªÙˆØ§Ø²Ù†
        avg_semantic_weight = surah_statistics['average_semantic_weight']
        if avg_semantic_weight > 0.7:
            insights.append("Ø³ÙˆØ±Ø© Ø°Ø§Øª ÙˆØ²Ù† Ø¯Ù„Ø§Ù„ÙŠ Ø¹Ø§Ù„ÙŠØŒ ØªØ­Ù…Ù„ Ù…Ø¹Ø§Ù†ÙŠ Ø¹Ù…ÙŠÙ‚Ø© ÙˆÙ‚ÙˆÙŠØ©")
        elif avg_semantic_weight > 0.5:
            insights.append("Ø³ÙˆØ±Ø© Ù…ØªÙˆØ§Ø²Ù†Ø© Ø¯Ù„Ø§Ù„ÙŠØ§Ù‹ØŒ ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©")
        else:
            insights.append("Ø³ÙˆØ±Ø© Ø®ÙÙŠÙØ© Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØŒ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„ØªØ£Ù…Ù„ ÙˆØ§Ù„ØªØ¯Ø¨Ø±")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ
        miracles_count = surah_statistics['numerical_miracles_count']
        if miracles_count > 3:
            insights.append("Ø³ÙˆØ±Ø© ØºÙ†ÙŠØ© Ø¨Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠØŒ ØªØ­Ù…Ù„ Ø£Ø³Ø±Ø§Ø±Ø§Ù‹ Ø¹Ø¯Ø¯ÙŠØ© Ø¹Ø¸ÙŠÙ…Ø©")
        elif miracles_count > 0:
            insights.append("Ø³ÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¥Ø¹Ø¬Ø§Ø² Ø±Ù‚Ù…ÙŠØŒ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ù„Ù‡ÙŠ Ø§Ù„Ù…Ø­ÙƒÙ…")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©
        patterns_count = surah_statistics['divine_patterns_count']
        if patterns_count > 5:
            insights.append("Ø³ÙˆØ±Ø© ØºÙ†ÙŠØ© Ø¨Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©ØŒ ØªØ¸Ù‡Ø± Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ Ø§Ù„Ø±Ø¨Ø§Ù†ÙŠ")

        # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø³ÙˆØ±Ø©
        if surah_number == 1:
            insights.append("ÙØ§ØªØ­Ø© Ø§Ù„ÙƒØªØ§Ø¨ØŒ Ø£Ù… Ø§Ù„Ù‚Ø±Ø¢Ù†ØŒ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬ÙˆÙ‡Ø± Ø§Ù„Ø¯ÙŠÙ†")
        elif surah_number <= 10:
            insights.append("Ù…Ù† Ø§Ù„Ø³ÙˆØ± Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙŠ Ø§Ù„Ù…ØµØ­ÙØŒ Ù„Ù‡Ø§ Ù…ÙƒØ§Ù†Ø© Ø®Ø§ØµØ©")
        elif surah_number >= 110:
            insights.append("Ù…Ù† Ø§Ù„Ø³ÙˆØ± Ø§Ù„Ø£Ø®ÙŠØ±Ø© ÙÙŠ Ø§Ù„Ù…ØµØ­ÙØŒ ØºØ§Ù„Ø¨Ø§Ù‹ Ù…Ø§ ØªÙƒÙˆÙ† Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ø¤Ø«Ø±Ø©")

        return insights

    def search_quranic_text(self, search_term: str, search_type: str = 'word') -> Dict[str, Any]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ."""

        print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø¹Ù†: {search_term}")

        results = {
            'search_term': search_term,
            'search_type': search_type,
            'matches': [],
            'total_matches': 0,
            'surahs_found': set(),
            'search_statistics': {}
        }

        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³ÙˆØ±
        for surah_num, surah_data in self.quran_text_data.get('surahs', {}).items():
            surah_number = int(surah_num)
            surah_name = surah_data.get('name', f'Ø§Ù„Ø³ÙˆØ±Ø© {surah_number}')
            verses = surah_data.get('verses', {})

            for verse_num, verse_text in verses.items():
                verse_number = int(verse_num)

                # Ø§Ù„Ø¨Ø­Ø« Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
                if search_type == 'word':
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙ„Ù…Ø©
                    clean_verse = self._remove_diacritics(verse_text)
                    clean_search = self._remove_diacritics(search_term)

                    if clean_search in clean_verse.split():
                        match = {
                            'surah_number': surah_number,
                            'surah_name': surah_name,
                            'verse_number': verse_number,
                            'verse_text': verse_text,
                            'match_type': 'exact_word'
                        }
                        results['matches'].append(match)
                        results['surahs_found'].add(surah_number)

                elif search_type == 'partial':
                    # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¬Ø²Ø¦ÙŠ
                    clean_verse = self._remove_diacritics(verse_text)
                    clean_search = self._remove_diacritics(search_term)

                    if clean_search in clean_verse:
                        match = {
                            'surah_number': surah_number,
                            'surah_name': surah_name,
                            'verse_number': verse_number,
                            'verse_text': verse_text,
                            'match_type': 'partial_match'
                        }
                        results['matches'].append(match)
                        results['surahs_found'].add(surah_number)

                elif search_type == 'root':
                    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¬Ø°ÙˆØ±
                    words = self._remove_diacritics(verse_text).split()
                    for word in words:
                        try:
                            word_analysis = self.lexicon_engine.analyze_word_revolutionary(word, deep_analysis=False)
                            if word_analysis.root == search_term:
                                match = {
                                    'surah_number': surah_number,
                                    'surah_name': surah_name,
                                    'verse_number': verse_number,
                                    'verse_text': verse_text,
                                    'matched_word': word,
                                    'root': word_analysis.root,
                                    'match_type': 'root_match'
                                }
                                results['matches'].append(match)
                                results['surahs_found'].add(surah_number)
                                break
                        except:
                            continue

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¨Ø­Ø«
        results['total_matches'] = len(results['matches'])
        results['surahs_found'] = list(results['surahs_found'])
        results['search_statistics'] = {
            'total_verses_found': len(results['matches']),
            'total_surahs_found': len(results['surahs_found']),
            'search_coverage': len(results['surahs_found']) / 114 * 100,  # Ù†Ø³Ø¨Ø© Ø§Ù„Ø³ÙˆØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
            'most_frequent_surah': max(results['surahs_found'], key=lambda s: len([m for m in results['matches'] if m['surah_number'] == s])) if results['surahs_found'] else None
        }

        print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {results['total_matches']} Ù†ØªÙŠØ¬Ø© ÙÙŠ {len(results['surahs_found'])} Ø³ÙˆØ±Ø©")

        return results

    def get_engine_status(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ."""

        return {
            'engine_info': {
                'name': self.engine_name,
                'version': self.version,
                'creation_time': self.creation_time.isoformat(),
                'type': 'quranic_analysis_engine'
            },
            'quran_data': self.quran_data,
            'statistics': self.engine_stats,
            'capabilities': {
                'verse_analysis': True,
                'surah_analysis': True,
                'numerical_miracles_discovery': True,
                'divine_patterns_recognition': True,
                'baserah_integration': True,
                'basil_theories_application': True,
                'quranic_search': True,
                'linguistic_analysis': True,
                'revolutionary_insights': True
            },
            'database_info': {
                'quran_db_path': self.quran_db_path,
                'quran_text_path': self.quran_text_path,
                'database_exists': os.path.exists(self.quran_db_path),
                'text_data_loaded': hasattr(self, 'quran_text_data')
            },
            'lexicon_engine_status': self.lexicon_engine.get_engine_status() if hasattr(self.lexicon_engine, 'get_engine_status') else {},
            'revolutionary_features': {
                'baserah_pure_approach': True,
                'basil_theories_integration': True,
                'divine_patterns_discovery': True,
                'numerical_miracles_analysis': True,
                'quranic_linguistic_analysis': True,
                'revolutionary_insights_generation': True,
                'no_traditional_ai': True
            }
        }

    def export_analysis_results(self, output_file: str, format_type: str = 'json') -> bool:
        """ØªØµØ¯ÙŠØ± Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ."""

        try:
            # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµØ¯ÙŠØ±
            export_data = {
                'engine_info': {
                    'name': self.engine_name,
                    'version': self.version,
                    'export_time': datetime.now().isoformat(),
                    'export_type': 'quranic_analysis_results'
                },
                'quran_metadata': self.quran_data,
                'engine_statistics': self.engine_stats,
                'analysis_results': {
                    'verses': [],
                    'numerical_miracles': [],
                    'divine_patterns': []
                }
            }

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            conn = sqlite3.connect(self.quran_db_path)
            cursor = conn.cursor()

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ§Øª
            cursor.execute('SELECT * FROM verses ORDER BY surah_number, verse_number LIMIT 100')
            verses_results = cursor.fetchall()

            for verse_result in verses_results:
                verse_data = {
                    'surah_number': verse_result[1],
                    'verse_number': verse_result[2],
                    'arabic_text': verse_result[3],
                    'semantic_weight': verse_result[7],
                    'analysis_date': verse_result[10]
                }
                export_data['analysis_results']['verses'].append(verse_data)

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² Ø§Ù„Ø±Ù‚Ù…ÙŠ
            cursor.execute('SELECT * FROM numerical_miracles ORDER BY discovered_at DESC LIMIT 50')
            miracles_results = cursor.fetchall()

            for miracle_result in miracles_results:
                miracle_data = {
                    'miracle_type': miracle_result[1],
                    'description': miracle_result[2],
                    'significance_level': miracle_result[5],
                    'discovered_at': miracle_result[7]
                }
                export_data['analysis_results']['numerical_miracles'].append(miracle_data)

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©
            cursor.execute('SELECT * FROM divine_patterns ORDER BY discovered_at DESC LIMIT 50')
            patterns_results = cursor.fetchall()

            for pattern_result in patterns_results:
                pattern_data = {
                    'pattern_type': pattern_result[1],
                    'description': pattern_result[2],
                    'discovered_at': pattern_result[6]
                }
                export_data['analysis_results']['divine_patterns'].append(pattern_data)

            conn.close()

            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if format_type.lower() == 'json':
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
            else:
                return False

            print(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ Ø¥Ù„Ù‰: {output_file}")
            return True

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØµØ¯ÙŠØ±: {e}")
            return False

    def get_verse_by_reference(self, surah_number: int, verse_number: int) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢ÙŠØ© Ø¨Ø§Ù„Ù…Ø±Ø¬Ø¹ Ù…Ø¹ ØªØ­Ù„ÙŠÙ„Ù‡Ø§."""

        try:
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø¢ÙŠØ©
            verse_text = self._get_verse_text(surah_number, verse_number)

            if not verse_text:
                return {
                    'error': f'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ© {surah_number}:{verse_number}',
                    'success': False
                }

            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙˆØ±Ø©
            surah_info = self.surah_names.get(surah_number, {})

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ø­Ù„Ù„Ø© Ù…Ù† Ù‚Ø¨Ù„
            try:
                analysis = self.analyze_verse_revolutionary(surah_number, verse_number, deep_analysis=True)

                return {
                    'success': True,
                    'surah_number': surah_number,
                    'verse_number': verse_number,
                    'surah_name': surah_info.get('arabic', f'Ø§Ù„Ø³ÙˆØ±Ø© {surah_number}'),
                    'surah_type': surah_info.get('type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
                    'verse_text': verse_text,
                    'analysis': {
                        'semantic_weight': analysis.semantic_weight,
                        'word_count': len(analysis.word_analysis),
                        'letter_frequency': analysis.letter_frequency,
                        'baserah_analysis': analysis.baserah_analysis,
                        'numerical_miracles': analysis.numerical_miracle,
                        'divine_patterns': analysis.divine_patterns,
                        'revolutionary_insights': analysis.revolutionary_insights,
                        'linguistic_features': analysis.linguistic_features
                    },
                    'reference': f"{surah_number}:{verse_number}",
                    'analysis_timestamp': analysis.timestamp
                }

            except Exception as e:
                return {
                    'success': True,
                    'surah_number': surah_number,
                    'verse_number': verse_number,
                    'surah_name': surah_info.get('arabic', f'Ø§Ù„Ø³ÙˆØ±Ø© {surah_number}'),
                    'verse_text': verse_text,
                    'analysis_error': str(e),
                    'reference': f"{surah_number}:{verse_number}"
                }

        except Exception as e:
            return {
                'error': f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ©: {e}',
                'success': False
            }


# === Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹ ===

def create_quranic_analysis_engine(engine_name: str = "QuickQuranicEngine") -> QuranicAnalysisEngine:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ ØªØ­Ù„ÙŠÙ„ Ù‚Ø±Ø¢Ù†ÙŠ Ø³Ø±ÙŠØ¹."""

    engine = QuranicAnalysisEngine(engine_name)
    print(f"ğŸ•Œ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ: {engine_name}")
    return engine


def analyze_quranic_verse(surah_number: int, verse_number: int,
                         engine_name: str = "QuickVerseAnalyzer") -> Dict[str, Any]:
    """ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ Ù„Ø¢ÙŠØ© Ù‚Ø±Ø¢Ù†ÙŠØ©."""

    engine = QuranicAnalysisEngine(engine_name)
    try:
        analysis = engine.analyze_verse_revolutionary(surah_number, verse_number, deep_analysis=True)
        return {
            'success': True,
            'verse_reference': f"{surah_number}:{verse_number}",
            'verse_text': analysis.text,
            'semantic_weight': analysis.semantic_weight,
            'revolutionary_insights': analysis.revolutionary_insights,
            'numerical_miracles': analysis.numerical_miracle,
            'divine_patterns': analysis.divine_patterns
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'verse_reference': f"{surah_number}:{verse_number}"
        }


def search_in_quran(search_term: str, search_type: str = 'word',
                   engine_name: str = "QuickQuranicSearch") -> Dict[str, Any]:
    """Ø¨Ø­Ø« Ø³Ø±ÙŠØ¹ ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…."""

    engine = QuranicAnalysisEngine(engine_name)
    result = engine.search_quranic_text(search_term, search_type)
    return result


def get_quranic_verse(surah_number: int, verse_number: int,
                     engine_name: str = "QuickVerseGetter") -> Dict[str, Any]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¹Ù„Ù‰ Ø¢ÙŠØ© Ù‚Ø±Ø¢Ù†ÙŠØ©."""

    engine = QuranicAnalysisEngine(engine_name)
    result = engine.get_verse_by_reference(surah_number, verse_number)
    return result


# === Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ===

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ."""

    print("ğŸ•Œâœ¨ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ!")
    print("ğŸ“– ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ… Ø¨Ù†Ø¸Ø±ÙŠØ§Øª Ø¨Ø§Ø³Ù„ ÙˆÙ†Ø¸Ø§Ù… Baserah Ø§Ù„Ù†Ù‚ÙŠ")
    print()

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ø±Ùƒ
    engine = QuranicAnalysisEngine("MainQuranicAnalysisEngine")

    # Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    print("ğŸ” Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ:")

    # ØªØ­Ù„ÙŠÙ„ Ø¢ÙŠØ© Ø§Ù„ÙƒØ±Ø³ÙŠ (Ù…Ø«Ø§Ù„)
    try:
        verse_analysis = engine.get_verse_by_reference(1, 1)  # Ø§Ù„ÙØ§ØªØ­Ø© Ø§Ù„Ø¢ÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰
        if verse_analysis['success']:
            print(f"\nğŸ“ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ©: {verse_analysis['reference']}")
            print(f"   Ø§Ù„Ù†Øµ: {verse_analysis['verse_text']}")
            print(f"   Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {verse_analysis['analysis']['semantic_weight']:.3f}")
            print(f"   Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {verse_analysis['analysis']['word_count']}")
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø«Ø§Ù„: {e}")

    # Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù†
    search_result = engine.search_quranic_text("Ø§Ù„Ù„Ù‡", "word")
    print(f"\nğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø© 'Ø§Ù„Ù„Ù‡':")
    print(f"   Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¹Ø«ÙˆØ±: {search_result['total_matches']}")
    print(f"   Ø³ÙˆØ± Ù…Ø·Ø§Ø¨Ù‚Ø©: {len(search_result['surahs_found'])}")

    # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ
    status = engine.get_engine_status()
    print(f"\nğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ:")
    print(f"   Ø¢ÙŠØ§Øª Ù…Ø­Ù„Ù„Ø©: {status['statistics']['verses_analyzed']}")
    print(f"   ÙƒÙ„Ù…Ø§Øª Ù…Ø­Ù„Ù„Ø©: {status['statistics']['words_analyzed']}")
    print(f"   Ø¥Ø¹Ø¬Ø§Ø² Ø±Ù‚Ù…ÙŠ Ù…ÙƒØªØ´Ù: {status['statistics']['numerical_miracles_discovered']}")
    print(f"   Ø£Ù†Ù…Ø§Ø· Ø¥Ù„Ù‡ÙŠØ©: {status['statistics']['divine_patterns_found']}")


if __name__ == "__main__":
    main()

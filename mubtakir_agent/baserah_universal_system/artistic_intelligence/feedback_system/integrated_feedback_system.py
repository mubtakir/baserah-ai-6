#!/usr/bin/env python3
# integrated_feedback_system.py - Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©

import sys
import os
import numpy as np
from typing import Dict, List, Tuple, Any, Optional
from datetime import datetime
import uuid

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class BaserahIntegratedFeedbackSystem:
    """
    Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Baserah Ø§Ù„Ù†Ù‚ÙŠ
    ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø¹ÙŠÙ† Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø© ÙˆØ§Ù„Ø±Ø§Ø³Ù… ÙˆØ§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø¨ÙŠØ± ÙÙŠ Ø¯ÙˆØ±Ø© ØªØ­Ø³ÙŠÙ† Ù…Ø³ØªÙ…Ø±Ø©
    """
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„."""
        
        # Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.enhanced_inference_engine = None
        self.feedback_mediator = None
        self.quality_assessor = None
        self.expert_system = None
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.max_feedback_cycles = 5
        self.target_quality = 0.95
        self.min_improvement = 0.02
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.total_sessions = 0
        self.successful_sessions = 0
        self.average_improvement = 0.0
        self.session_history = []
        
        print("ðŸ”— ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Baserah Ø§Ù„Ù†Ù‚ÙŠ")
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        self._initialize_components()
    
    def _initialize_components(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª."""
        
        try:
            # Ø§Ù„Ø¹ÙŠÙ† Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
            from .enhanced_inference_engine import EnhancedBaserahInferenceEngine
            self.enhanced_inference_engine = EnhancedBaserahInferenceEngine()
            print("   âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹ÙŠÙ† Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©")
            
            # Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙˆØ³ÙŠØ·
            from .feedback_mediator_system import BaserahFeedbackMediatorSystem
            self.feedback_mediator = BaserahFeedbackMediatorSystem()
            print("   âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙˆØ³ÙŠØ·")
            
            # Ù…Ø­Ø±Ùƒ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©
            from .quality_assessment_engine import BaserahQualityAssessmentEngine
            self.quality_assessor = BaserahQualityAssessmentEngine()
            print("   âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©")
            
            # Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø¨ÙŠØ± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            try:
                from revolutionary_intelligence.expert_explorer_system.expert_explorer.integrated_expert_explorer import BaserahIntegratedExpertExplorer
                self.expert_system = BaserahIntegratedExpertExplorer()
                print("   âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù")
            except ImportError:
                print("   âš ï¸ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø¨ÙŠØ± ØºÙŠØ± Ù…ØªØ§Ø­ - Ø³ÙŠØ¹Ù…Ù„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø¯ÙˆÙ†Ù‡")
            
        except Exception as e:
            print(f"   âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª: {e}")
    
    def run_intelligent_inference(self, input_data: List[Tuple[float, float]], 
                                 session_name: str = None) -> Dict[str, Any]:
        """
        ØªØ´ØºÙŠÙ„ Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø°ÙƒÙŠ Ù…Ø¹ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø©.
        
        Args:
            input_data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø© [(x, y), ...]
            session_name: Ø§Ø³Ù… Ø§Ù„Ø¬Ù„Ø³Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø°ÙƒÙŠ
        """
        
        session_id = f"intelligent_session_{uuid.uuid4()}"
        if session_name:
            session_id = f"{session_name}_{session_id}"
        
        self.total_sessions += 1
        
        print(f"\nðŸ§  Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø°ÙƒÙŠ: {session_id}")
        print(f"ðŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø©: {len(input_data)} Ù†Ù‚Ø·Ø©")
        print("=" * 60)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        x_data = [p[0] for p in input_data]
        y_data = [p[1] for p in input_data]
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø£ÙˆÙ„ÙŠ
        print("ðŸ” Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø£ÙˆÙ„ÙŠ")
        initial_result = self.enhanced_inference_engine.infer_from_data_points(x_data, y_data)
        initial_confidence = initial_result.get('confidence', 0.5)
        
        print(f"   ðŸ“ˆ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: {initial_confidence:.3f}")
        print(f"   ðŸ“ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…ÙƒØªØ´Ù: {initial_result.get('type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¯ÙˆØ±Ø© Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
        print("\nðŸ”„ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¯ÙˆØ±Ø© Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©")
        feedback_result = self.feedback_mediator.run_feedback_cycle(
            input_data, initial_confidence
        )
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        print("\nðŸŽ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø­Ø³Ù† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙØ¶Ù„ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø©
        best_feedback = feedback_result.get('feedback_summary', {})
        
        final_result = self.enhanced_inference_engine.infer_with_feedback(
            x_data, y_data, best_feedback
        )
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        print("\nðŸ“Š Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
        final_quality = self._assess_final_quality(input_data, final_result)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø§Ù„Ø¬Ù„Ø³Ø©
        session_summary = self._create_session_summary(
            session_id, input_data, initial_result, feedback_result, 
            final_result, final_quality
        )
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®
        self.session_history.append(session_summary)
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self._update_performance_stats(session_summary)
        
        print(f"\nâœ… Ø§Ù†ØªÙ‡Øª Ø¬Ù„Ø³Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø°ÙƒÙŠ")
        print(f"ðŸ“ˆ Ø§Ù„ØªØ­Ø³Ù† Ø§Ù„Ù…Ø­Ù‚Ù‚: +{session_summary['improvement_achieved']:.3f}")
        print(f"ðŸŽ¯ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {final_quality:.3f}")
        
        return session_summary
    
    def _assess_final_quality(self, original_data: List[Tuple[float, float]], 
                            inference_result: Dict[str, Any]) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©."""
        
        try:
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©
            x_data = [p[0] for p in original_data]
            generated_data = self._generate_data_from_result(inference_result, x_data)
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©
            if self.quality_assessor:
                quality_metrics = self.quality_assessor.assess_quality(original_data, generated_data)
                return quality_metrics.overall_score
            else:
                # ØªÙ‚ÙŠÙŠÙ… Ø¨Ø³ÙŠØ·
                return inference_result.get('confidence', 0.5)
                
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©: {e}")
            return inference_result.get('confidence', 0.5)
    
    def _generate_data_from_result(self, result: Dict[str, Any], 
                                 x_data: List[float]) -> List[Tuple[float, float]]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·."""
        
        generated_points = []
        
        try:
            result_type = result.get('type', 'linear')
            components = result.get('components', [])
            
            for x in x_data:
                y = 0.0
                
                for component in components:
                    comp_type = component.get('type', 'linear')
                    params = component.get('parameters', {})
                    
                    if comp_type == 'linear':
                        from .baserah_core import baserah_linear
                        beta = params.get('beta', 1.0)
                        gamma = params.get('gamma', 0.0)
                        y += baserah_linear(x, beta=beta, gamma=gamma)
                    
                    elif comp_type == 'sigmoid':
                        from .baserah_core import baserah_sigmoid
                        n = params.get('n', 1)
                        k = params.get('k', 1.0)
                        x0 = params.get('x0', 0.0)
                        alpha = params.get('alpha', 1.0)
                        y += baserah_sigmoid(x, n=n, k=k, x0=x0, alpha=alpha)
                
                generated_points.append((x, y))
            
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {e}")
            # ØªÙˆÙ„ÙŠØ¯ Ø§ÙØªØ±Ø§Ø¶ÙŠ
            generated_points = [(x, x) for x in x_data]
        
        return generated_points
    
    def _create_session_summary(self, session_id: str, input_data: List[Tuple[float, float]],
                              initial_result: Dict[str, Any], feedback_result: Dict[str, Any],
                              final_result: Dict[str, Any], final_quality: float) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø§Ù„Ø¬Ù„Ø³Ø©."""
        
        initial_confidence = initial_result.get('confidence', 0.5)
        final_confidence = final_result.get('confidence', 0.5)
        improvement = final_confidence - initial_confidence
        
        summary = {
            'session_id': session_id,
            'timestamp': datetime.now(),
            'input_data_points': len(input_data),
            
            # Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
            'initial_confidence': initial_confidence,
            'initial_type': initial_result.get('type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
            
            # Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
            'feedback_cycles': feedback_result.get('total_iterations', 0),
            'feedback_converged': feedback_result.get('converged', False),
            'feedback_quality': feedback_result.get('best_quality', 0.0),
            
            # Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            'final_confidence': final_confidence,
            'final_quality': final_quality,
            'final_type': final_result.get('type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
            
            # Ø§Ù„ØªØ­Ø³Ù† Ø§Ù„Ù…Ø­Ù‚Ù‚
            'improvement_achieved': improvement,
            'quality_improvement': final_quality - initial_confidence,
            
            # ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©
            'enhancement_applied': final_result.get('enhancement_applied', False),
            'feedback_incorporated': final_result.get('feedback_incorporated', False),
            'expert_system_used': self.expert_system is not None,
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ø¬Ø§Ø­
            'success': final_quality >= self.target_quality or improvement >= self.min_improvement,
            'target_achieved': final_quality >= self.target_quality
        }
        
        return summary
    
    def _update_performance_stats(self, session_summary: Dict[str, Any]):
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡."""
        
        if session_summary['success']:
            self.successful_sessions += 1
        
        # ØªØ­Ø¯ÙŠØ« Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ­Ø³Ù†
        all_improvements = [s['improvement_achieved'] for s in self.session_history]
        self.average_improvement = sum(all_improvements) / len(all_improvements)
    
    def run_batch_inference(self, batch_data: List[List[Tuple[float, float]]], 
                          batch_name: str = None) -> Dict[str, Any]:
        """ØªØ´ØºÙŠÙ„ Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ù…Ø¬Ù…ÙˆØ¹ÙŠ Ù…Ø¹ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø©."""
        
        batch_id = f"batch_{uuid.uuid4()}"
        if batch_name:
            batch_id = f"{batch_name}_{batch_id}"
        
        print(f"\nðŸ“¦ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ÙŠ: {batch_id}")
        print(f"ðŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {len(batch_data)}")
        
        batch_results = []
        total_improvement = 0.0
        successful_count = 0
        
        for i, data_set in enumerate(batch_data):
            print(f"\n--- Ù…Ø¬Ù…ÙˆØ¹Ø© {i+1}/{len(batch_data)} ---")
            
            session_result = self.run_intelligent_inference(
                data_set, f"{batch_id}_set_{i+1}"
            )
            
            batch_results.append(session_result)
            total_improvement += session_result['improvement_achieved']
            
            if session_result['success']:
                successful_count += 1
        
        # Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©
        batch_summary = {
            'batch_id': batch_id,
            'timestamp': datetime.now(),
            'total_sets': len(batch_data),
            'successful_sets': successful_count,
            'success_rate': successful_count / len(batch_data),
            'average_improvement': total_improvement / len(batch_data),
            'total_improvement': total_improvement,
            'individual_results': batch_results
        }
        
        print(f"\nðŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ÙŠ:")
        print(f"   Ù†Ø¬Ø­: {successful_count}/{len(batch_data)} ({batch_summary['success_rate']:.1%})")
        print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ­Ø³Ù†: {batch_summary['average_improvement']:.3f}")
        
        return batch_summary
    
    def get_system_performance(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„."""
        
        performance = {
            'total_sessions': self.total_sessions,
            'successful_sessions': self.successful_sessions,
            'success_rate': self.successful_sessions / self.total_sessions if self.total_sessions > 0 else 0,
            'average_improvement': self.average_improvement,
            'target_quality': self.target_quality,
            'min_improvement': self.min_improvement
        }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        if self.enhanced_inference_engine:
            performance['inference_engine_stats'] = self.enhanced_inference_engine.get_learning_summary()
        
        if self.feedback_mediator:
            performance['mediator_stats'] = self.feedback_mediator.get_performance_summary()
        
        if self.quality_assessor:
            performance['quality_assessor_stats'] = self.quality_assessor.get_assessment_summary()
        
        # Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£Ø¯Ø§Ø¡
        if len(self.session_history) >= 5:
            recent_success = sum(1 for s in self.session_history[-5:] if s['success'])
            performance['recent_success_rate'] = recent_success / 5
            
            recent_improvements = [s['improvement_achieved'] for s in self.session_history[-5:]]
            performance['recent_average_improvement'] = sum(recent_improvements) / len(recent_improvements)
        
        return performance
    
    def demonstrate_system(self) -> Dict[str, Any]:
        """Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù„Ù†Ø¸Ø§Ù…."""
        
        print("\nðŸŽ­ Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©")
        print("=" * 60)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±
        test_datasets = [
            # Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø·ÙŠØ©
            [(i, 2*i + 1) for i in range(-3, 4)],
            # Ø¨ÙŠØ§Ù†Ø§Øª Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
            [(i, 1/(1 + np.exp(-i))) for i in range(-3, 4)],
            # Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø¶ÙˆØ¶Ø§Ø¡
            [(i, 2*i + 1 + 0.1*np.random.randn()) for i in range(-3, 4)]
        ]
        
        demo_results = self.run_batch_inference(test_datasets, "demo")
        
        print(f"\nðŸŽ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ:")
        print(f"   Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {demo_results['success_rate']:.1%}")
        print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ­Ø³Ù†: {demo_results['average_improvement']:.3f}")
        
        return demo_results

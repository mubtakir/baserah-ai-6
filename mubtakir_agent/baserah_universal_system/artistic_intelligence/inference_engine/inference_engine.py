#!/usr/bin/env python3
# inference_engine.py - Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Baserah (Ø¹ÙŠÙ† Ø§Ù„Ù†Ø¸Ø§Ù…) - Ù†Ø³Ø®Ø© Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©

import math
from typing import List, Tuple, Dict, Optional, Union
from .baserah_core import (
    baserah_sigmoid, baserah_linear, baserah_quantum_sigmoid, baserah_equation
)

class BaserahInferenceEngine:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Baserah - Ø¹ÙŠÙ† Ø§Ù„Ù†Ø¸Ø§Ù…
    ÙŠØ³ØªÙ†ØªØ¬ Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù†Ù‡Ø¬ Baserah Ø§Ù„Ù†Ù‚ÙŠ ÙÙ‚Ø·
    """
    
    def __init__(self):
        self.tolerance = 1e-6
        self.max_iterations = 1000
        self.learning_rate = 0.01
        
    def infer_from_data_points(self, x_data: List[float], y_data: List[float]) -> Dict:
        """
        Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        if len(x_data) != len(y_data) or len(x_data) < 3:
            return {'error': 'Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©'}
        
        print(f"ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ù…Ù† {len(x_data)} Ù†Ù‚Ø·Ø© Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data_analysis = self._analyze_data_pattern(x_data, y_data)
        print(f"   Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…ÙƒØªØ´Ù: {data_analysis['pattern_type']}")
        
        # Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†Ù…Ø·
        if data_analysis['pattern_type'] == 'linear':
            return self._infer_linear_parameters(x_data, y_data)
        elif data_analysis['pattern_type'] == 'sigmoid':
            return self._infer_sigmoid_parameters(x_data, y_data)
        elif data_analysis['pattern_type'] == 'step':
            return self._infer_quantum_parameters(x_data, y_data)
        elif data_analysis['pattern_type'] == 'mixed':
            return self._infer_mixed_parameters(x_data, y_data)
        else:
            return self._infer_general_parameters(x_data, y_data)
    
    def _analyze_data_pattern(self, x_data: List[float], y_data: List[float]) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ù†Ù…Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©"""
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª
        y_range = max(y_data) - min(y_data)
        y_mean = sum(y_data) / len(y_data)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø±Ø¬
        gradients = []
        for i in range(1, len(x_data)):
            if x_data[i] != x_data[i-1]:
                grad = (y_data[i] - y_data[i-1]) / (x_data[i] - x_data[i-1])
                gradients.append(grad)
        
        if not gradients:
            return {'pattern_type': 'constant', 'confidence': 1.0}
        
        grad_variance = self._calculate_variance(gradients)
        grad_mean = sum(gradients) / len(gradients)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù…Ø·
        if grad_variance < 0.01:  # ØªØ¯Ø±Ø¬ Ø«Ø§Ø¨Øª ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹
            return {'pattern_type': 'linear', 'confidence': 0.9}
        elif self._is_step_function(y_data):
            return {'pattern_type': 'step', 'confidence': 0.8}
        elif self._is_sigmoid_like(x_data, y_data):
            return {'pattern_type': 'sigmoid', 'confidence': 0.7}
        else:
            return {'pattern_type': 'mixed', 'confidence': 0.5}
    
    def _is_step_function(self, y_data: List[float]) -> bool:
        """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ´Ø¨Ù‡ Ø¯Ø§Ù„Ø© Ù…ØªÙ‚Ø·Ø¹Ø©"""
        unique_values = list(set(y_data))
        return len(unique_values) <= 5 and len(unique_values) < len(y_data) / 3
    
    def _is_sigmoid_like(self, x_data: List[float], y_data: List[float]) -> bool:
        """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ´Ø¨Ù‡ Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯"""
        y_min, y_max = min(y_data), max(y_data)
        y_range = y_max - y_min
        
        if y_range < 0.1:
            return False
        
        # ÙØ­Øµ Ø§Ù„Ø´ÙƒÙ„ S
        sorted_pairs = sorted(zip(x_data, y_data))
        y_sorted = [pair[1] for pair in sorted_pairs]
        
        # ÙØ­Øµ Ø§Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠØ©
        increasing_count = 0
        for i in range(1, len(y_sorted)):
            if y_sorted[i] >= y_sorted[i-1]:
                increasing_count += 1
        
        return increasing_count / len(y_sorted) > 0.7
    
    def _calculate_variance(self, data: List[float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¨Ø§ÙŠÙ†"""
        if len(data) < 2:
            return 0.0
        
        mean = sum(data) / len(data)
        variance = sum((x - mean) ** 2 for x in data) / len(data)
        return variance
    
    def _infer_linear_parameters(self, x_data: List[float], y_data: List[float]) -> Dict:
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø®Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…"""
        print("   Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø®Ø·ÙŠØ©...")
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠÙ„ ÙˆØ§Ù„ØªÙ‚Ø§Ø·Ø¹ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„ØµØºØ±Ù‰
        n = len(x_data)
        sum_x = sum(x_data)
        sum_y = sum(y_data)
        sum_xy = sum(x_data[i] * y_data[i] for i in range(n))
        sum_x2 = sum(x * x for x in x_data)
        
        denominator = n * sum_x2 - sum_x * sum_x
        if abs(denominator) < self.tolerance:
            beta = 0.0
            gamma = sum_y / n
        else:
            beta = (n * sum_xy - sum_x * sum_y) / denominator
            gamma = (sum_y - beta * sum_x) / n
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø·Ø£
        error = self._calculate_error(x_data, y_data, 
                                    lambda x: baserah_linear(x, beta, gamma))
        
        return {
            'type': 'linear',
            'components': [
                {
                    'type': 'linear',
                    'params': {'beta': beta, 'gamma': gamma}
                }
            ],
            'error': error,
            'confidence': 0.9 if error < 0.1 else 0.5
        }
    
    def _infer_sigmoid_parameters(self, x_data: List[float], y_data: List[float]) -> Dict:
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯"""
        print("   Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯...")
        
        # ØªÙ‚Ø¯ÙŠØ± Ø£ÙˆÙ„ÙŠ Ù„Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        y_min, y_max = min(y_data), max(y_data)
        alpha = y_max - y_min
        x_mid = (max(x_data) + min(x_data)) / 2
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        best_params = {'n': 1, 'k': 1.0, 'x0': x_mid, 'alpha': alpha}
        best_error = float('inf')
        
        # ØªØ¬Ø±Ø¨Ø© Ù‚ÙŠÙ… Ù…Ø®ØªÙ„ÙØ©
        for n in [1, 2, 3]:
            for k in [0.5, 1.0, 2.0, 5.0]:
                for x0_offset in [-1.0, 0.0, 1.0]:
                    x0 = x_mid + x0_offset
                    
                    # ØªØ­Ø³ÙŠÙ† alpha
                    alpha_opt = self._optimize_alpha(x_data, y_data, n, k, x0)
                    
                    error = self._calculate_error(x_data, y_data,
                                                lambda x: baserah_sigmoid(x, n, k, x0, alpha_opt))
                    
                    if error < best_error:
                        best_error = error
                        best_params = {'n': n, 'k': k, 'x0': x0, 'alpha': alpha_opt}
        
        return {
            'type': 'sigmoid',
            'components': [
                {
                    'type': 'sigmoid',
                    'params': best_params
                }
            ],
            'error': best_error,
            'confidence': 0.8 if best_error < 0.2 else 0.4
        }
    
    def _infer_quantum_parameters(self, x_data: List[float], y_data: List[float]) -> Dict:
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ø§Ù„Ù…ÙƒÙ…Ù…"""
        print("   Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªÙƒÙ…ÙŠÙ…...")
        
        # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù†ÙØµÙ„Ø©
        unique_values = sorted(list(set(y_data)))
        quantum_factor = len(unique_values)
        
        # ØªÙ‚Ø¯ÙŠØ± Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        sigmoid_result = self._infer_sigmoid_parameters(x_data, y_data)
        
        if sigmoid_result['type'] == 'sigmoid':
            base_params = sigmoid_result['components'][0]['params']
            
            # Ø¥Ø¶Ø§ÙØ© Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒÙ…ÙŠÙ…
            quantum_params = base_params.copy()
            quantum_params['quantum_factor'] = quantum_factor
            
            error = self._calculate_error(x_data, y_data,
                                        lambda x: baserah_quantum_sigmoid(x, **quantum_params))
            
            return {
                'type': 'quantum_sigmoid',
                'components': [
                    {
                        'type': 'quantum_sigmoid',
                        'params': quantum_params
                    }
                ],
                'error': error,
                'confidence': 0.7 if error < 0.3 else 0.3
            }
        
        return sigmoid_result
    
    def _infer_mixed_parameters(self, x_data: List[float], y_data: List[float]) -> Dict:
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø®ØªÙ„Ø·Ø© (Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ + Ø®Ø·ÙŠ)"""
        print("   Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø®ØªÙ„Ø·Ø©...")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ±ÙƒÙŠØ¨ Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ + Ø®Ø·ÙŠ
        sigmoid_result = self._infer_sigmoid_parameters(x_data, y_data)
        
        if sigmoid_result['error'] > 0.5:
            # Ø¥Ø¶Ø§ÙØ© Ù…ÙƒÙˆÙ† Ø®Ø·ÙŠ
            sigmoid_params = sigmoid_result['components'][0]['params']
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¨Ù‚Ø§ÙŠØ§
            residuals = []
            for i, x in enumerate(x_data):
                predicted = baserah_sigmoid(x, **sigmoid_params)
                residual = y_data[i] - predicted
                residuals.append(residual)
            
            # ØªØ±ÙƒÙŠØ¨ Ø®Ø· Ù…Ø³ØªÙ‚ÙŠÙ… Ù„Ù„Ø¨Ù‚Ø§ÙŠØ§
            linear_result = self._infer_linear_parameters(x_data, residuals)
            linear_params = linear_result['components'][0]['params']
            
            # Ø¯Ù…Ø¬ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
            components = [
                {'type': 'sigmoid', 'params': sigmoid_params},
                {'type': 'linear', 'params': linear_params}
            ]
            
            error = self._calculate_error(x_data, y_data,
                                        lambda x: baserah_equation(x, components))
            
            return {
                'type': 'mixed',
                'components': components,
                'error': error,
                'confidence': 0.6 if error < 0.4 else 0.2
            }
        
        return sigmoid_result
    
    def _infer_general_parameters(self, x_data: List[float], y_data: List[float]) -> Dict:
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¹Ø§Ù… - Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹"""
        print("   Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø¹Ø§Ù…...")
        
        results = []
        
        # ØªØ¬Ø±Ø¨Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹
        linear_result = self._infer_linear_parameters(x_data, y_data)
        results.append(linear_result)
        
        sigmoid_result = self._infer_sigmoid_parameters(x_data, y_data)
        results.append(sigmoid_result)
        
        quantum_result = self._infer_quantum_parameters(x_data, y_data)
        results.append(quantum_result)
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
        best_result = min(results, key=lambda r: r['error'])
        
        return best_result
    
    def _optimize_alpha(self, x_data: List[float], y_data: List[float], 
                       n: int, k: float, x0: float) -> float:
        """ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù…Ù„ alpha"""
        
        # Ø­Ø³Ø§Ø¨ alpha Ø§Ù„Ù…Ø«Ù„Ù‰ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„ØµØºØ±Ù‰
        numerator = 0.0
        denominator = 0.0
        
        for i, x in enumerate(x_data):
            sigmoid_val = baserah_sigmoid(x, n, k, x0, 1.0)  # alpha = 1
            numerator += y_data[i] * sigmoid_val
            denominator += sigmoid_val * sigmoid_val
        
        if abs(denominator) < self.tolerance:
            return 1.0
        
        return numerator / denominator
    
    def _calculate_error(self, x_data: List[float], y_data: List[float], 
                        func) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø®Ø·Ø£"""
        total_error = 0.0
        
        for i, x in enumerate(x_data):
            predicted = func(x)
            error = (y_data[i] - predicted) ** 2
            total_error += error
        
        return total_error / len(x_data)
    
    def generate_equation_string(self, inference_result: Dict) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ø¹Ø§Ø¯Ù„Ø© Ù†ØµÙŠØ© Ù…Ù† Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·"""
        
        if 'error' in inference_result:
            return f"Ø®Ø·Ø£: {inference_result['error']}"
        
        components = inference_result.get('components', [])
        if not components:
            return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙƒÙˆÙ†Ø§Øª"
        
        equation_parts = []
        
        for comp in components:
            comp_type = comp['type']
            params = comp['params']
            
            if comp_type == 'linear':
                beta = params.get('beta', 0)
                gamma = params.get('gamma', 0)
                equation_parts.append(f"linear({beta:.3f}*x + {gamma:.3f})")
                
            elif comp_type == 'sigmoid':
                n = params.get('n', 1)
                k = params.get('k', 1)
                x0 = params.get('x0', 0)
                alpha = params.get('alpha', 1)
                equation_parts.append(f"sigmoid(n={n}, k={k:.3f}, x0={x0:.3f}, Î±={alpha:.3f})")
                
            elif comp_type == 'quantum_sigmoid':
                n = params.get('n', 1)
                k = params.get('k', 1)
                x0 = params.get('x0', 0)
                alpha = params.get('alpha', 1)
                qf = params.get('quantum_factor', 1)
                equation_parts.append(f"quantum_sigmoid(n={n}, k={k:.3f}, x0={x0:.3f}, Î±={alpha:.3f}, Q={qf})")
        
        equation = " + ".join(equation_parts)
        error = inference_result.get('error', 0)
        confidence = inference_result.get('confidence', 0)
        
        return f"f(x) = {equation} [Ø®Ø·Ø£: {error:.6f}, Ø«Ù‚Ø©: {confidence:.2f}]"

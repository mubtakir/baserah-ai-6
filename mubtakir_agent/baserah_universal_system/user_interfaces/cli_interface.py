#!/usr/bin/env python3
# cli_interface.py - ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Baserah

import argparse
import sys
import os
import json
from datetime import datetime
import numpy as np

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from revolutionary_intelligence.revolutionary_mother_system.revolutionary_mother_system import BaserahRevolutionaryMotherSystem, InheritanceType
from revolutionary_intelligence.adaptive_equations_system.self_evolving_system import BaserahSelfEvolvingSystem, EvolutionDirection
from advanced_cognitive_objects import BaserahAdvancedCognitiveObject, AdvancedCognitiveType
from knowledge_systems.semantic_meaning.semantic_meaning_system import BaserahSemanticMeaningSystem
from artistic_unit.integrated_system import BaserahIntegratedSystem
from revolutionary_intelligence.quranic_analysis_engine import QuranicAnalysisEngine
from revolutionary_intelligence.arabic_lexicon_engine import ArabicLexiconEngine
from revolutionary_intelligent_agent.intelligent_agent import BaserahIntelligentAgent

class BaserahCLI:
    """
    ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Baserah

    ØªÙˆÙØ± ÙˆØµÙˆÙ„ ÙƒØ§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ø¨Ø± Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±:
    - Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ
    - Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
    - Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
    - Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ©
    - Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
    """

    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±."""

        self.system_ready = False
        self.initialize_revolutionary_system()

        print("ğŸ’» ØªÙ… ØªÙ‡ÙŠØ¦Ø© ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ")

    def initialize_revolutionary_system(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„."""

        try:
            print("ğŸ”„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ...")

            # Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…
            self.mother_system = BaserahRevolutionaryMotherSystem()
            print("   âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù… Ø¬Ø§Ù‡Ø²")

            # Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
            self.self_evolving = BaserahSelfEvolvingSystem(self.mother_system)
            print("   âœ… Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¬Ø§Ù‡Ø²")

            # Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ©
            self.semantic_system = BaserahSemanticMeaningSystem(self.mother_system)
            print("   âœ… Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ© Ø¬Ø§Ù‡Ø²")

            # Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
            self.artistic_unit = BaserahIntegratedSystem()
            print("   âœ… Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ© Ø¬Ø§Ù‡Ø²Ø©")

            # ÙˆØ±Ø§Ø«Ø© Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ© Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…
            self.mother_system.inherit_to_unit(InheritanceType.ARTISTIC_UNIT, self.artistic_unit)
            print("   âœ… ÙˆØ±Ø§Ø«Ø© Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ© Ù…ÙƒØªÙ…Ù„Ø©")

            # ÙƒØ§Ø¦Ù† Ù…Ø¹Ø±ÙÙŠ Ù…ØªÙ‚Ø¯Ù…
            self.consciousness = BaserahAdvancedCognitiveObject("Ø§Ù„ÙˆØ¹ÙŠ CLI",
                                                              AdvancedCognitiveType.CONSCIOUSNESS_SIMULATOR)

            # Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ
            self.quranic_engine = QuranicAnalysisEngine("CLIQuranicEngine")

            # Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            self.lexicon_engine = ArabicLexiconEngine("CLILexiconEngine")

            # Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ
            self.intelligent_agent = BaserahIntelligentAgent("CLIIntelligentAgent")
            print("   âœ… Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ Ø¬Ø§Ù‡Ø²")

            self.system_ready = True
            print("ğŸ‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!")

        except Exception as e:
            self.system_ready = False
            print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ: {e}")

    def create_parser(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ù„Ù„ Ø§Ù„Ø£ÙˆØ§Ù…Ø±."""

        parser = argparse.ArgumentParser(
            description='ğŸŒŸ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Baserah - ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±',
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
  python cli_interface.py status                           # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
  python cli_interface.py evolution --analyze              # ØªØ­Ù„ÙŠÙ„ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
  python cli_interface.py evolution --execute              # ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
  python cli_interface.py semantic --interpret "Ø§Ù†Ø³Ø§Ù† ÙŠÙ…Ø´ÙŠ"  # ØªÙØ³ÙŠØ± Ø¬Ù…Ù„Ø© Ø¯Ù„Ø§Ù„ÙŠØ©
  python cli_interface.py semantic --execute "Ù…Ø±Ø¨Ø¹ ÙŠØªØ­ÙˆÙ„"    # ØªÙ†ÙÙŠØ° Ø£Ù…Ø± Ø¯Ù„Ø§Ù„ÙŠ
  python cli_interface.py cognitive --reflect              # ØªØ£Ù…Ù„ Ø°Ø§ØªÙŠ
  python cli_interface.py cognitive --create               # ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ
  python cli_interface.py export --output results.json    # ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            """
        )

        subparsers = parser.add_subparsers(dest='command', help='Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©')

        # Ø£Ù…Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        status_parser = subparsers.add_parser('status', help='Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…')
        status_parser.add_argument('--detailed', action='store_true', help='Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ·ÙˆÙŠØ±
        evolution_parser = subparsers.add_parser('evolution', help='Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ')
        evolution_group = evolution_parser.add_mutually_exclusive_group(required=True)
        evolution_group.add_argument('--analyze', action='store_true', help='ØªØ­Ù„ÙŠÙ„ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…')
        evolution_group.add_argument('--execute', action='store_true', help='ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ')
        evolution_group.add_argument('--continuous', type=int, metavar='CYCLES', help='ØªØ·ÙˆÙŠØ± Ù…Ø³ØªÙ…Ø± Ù„Ø¹Ø¯Ø¯ Ù…Ø¹ÙŠÙ† Ù…Ù† Ø§Ù„Ø¯ÙˆØ±Ø§Øª')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ©
        semantic_parser = subparsers.add_parser('semantic', help='Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ©')
        semantic_group = semantic_parser.add_mutually_exclusive_group(required=True)
        semantic_group.add_argument('--interpret', type=str, metavar='SENTENCE', help='ØªÙØ³ÙŠØ± Ø¬Ù…Ù„Ø© Ø¯Ù„Ø§Ù„ÙŠØ©')
        semantic_group.add_argument('--execute', type=str, metavar='COMMAND', help='ØªÙ†ÙÙŠØ° Ø£Ù…Ø± Ø¯Ù„Ø§Ù„ÙŠ')
        semantic_group.add_argument('--transform', nargs=2, metavar=('FROM', 'TO'), help='ØªØ­ÙˆÙŠÙ„ Ø¯Ù„Ø§Ù„ÙŠ')
        semantic_group.add_argument('--database', action='store_true', help='Ø¹Ø±Ø¶ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©
        cognitive_parser = subparsers.add_parser('cognitive', help='Ø£ÙˆØ§Ù…Ø± Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©')
        cognitive_group = cognitive_parser.add_mutually_exclusive_group(required=True)
        cognitive_group.add_argument('--reflect', action='store_true', help='ØªØ£Ù…Ù„ Ø°Ø§ØªÙŠ')
        cognitive_group.add_argument('--learn', type=str, metavar='DATA', help='ØªØ¹Ù„Ù… Ù…Ø³ØªÙ‚Ù„')
        cognitive_group.add_argument('--create', action='store_true', help='ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ')
        cognitive_group.add_argument('--consciousness', action='store_true', help='ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆØ¹ÙŠ')
        cognitive_group.add_argument('--summary', action='store_true', help='Ù…Ù„Ø®Øµ Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
        artistic_parser = subparsers.add_parser('artistic', help='Ø£ÙˆØ§Ù…Ø± Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©')
        artistic_group = artistic_parser.add_mutually_exclusive_group(required=True)
        artistic_group.add_argument('--plot', nargs='+', metavar='PARAMS', help='Ø±Ø³Ù… Ù…Ø¹Ø§Ø¯Ù„Ø© (Ù†ÙˆØ¹ n k alpha)')
        artistic_group.add_argument('--adapt', nargs=2, metavar=('FROM', 'TO'), help='ØªÙƒÙŠÙ Ø¨ØµØ±ÙŠ')
        artistic_group.add_argument('--animate', type=str, metavar='SHAPE', help='Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³ÙˆÙ… Ù…ØªØ­Ø±ÙƒØ©')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ
        quran_parser = subparsers.add_parser('quran', help='Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ')
        quran_group = quran_parser.add_mutually_exclusive_group(required=True)
        quran_group.add_argument('--analyze', nargs=2, type=int, metavar=('SURAH', 'VERSE'), help='ØªØ­Ù„ÙŠÙ„ Ø¢ÙŠØ© (Ø±Ù‚Ù… Ø§Ù„Ø³ÙˆØ±Ø© Ø±Ù‚Ù… Ø§Ù„Ø¢ÙŠØ©)')
        quran_group.add_argument('--search', type=str, metavar='TERM', help='Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù†')
        quran_group.add_argument('--surah', type=int, metavar='NUMBER', help='ØªØ­Ù„ÙŠÙ„ Ø³ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©')
        quran_group.add_argument('--status', action='store_true', help='Ø­Ø§Ù„Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ
        lexicon_parser = subparsers.add_parser('lexicon', help='Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ')
        lexicon_group = lexicon_parser.add_mutually_exclusive_group(required=True)
        lexicon_group.add_argument('--analyze', type=str, metavar='WORD', help='ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© Ø¹Ø±Ø¨ÙŠØ©')
        lexicon_group.add_argument('--root', type=str, metavar='ROOT', help='Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø¬Ø°Ø±')
        lexicon_group.add_argument('--morphology', type=str, metavar='WORD', help='Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ')
        lexicon_group.add_argument('--status', action='store_true', help='Ø­Ø§Ù„Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ
        agent_parser = subparsers.add_parser('agent', help='Ø£ÙˆØ§Ù…Ø± Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ')
        agent_group = agent_parser.add_mutually_exclusive_group(required=True)
        agent_group.add_argument('--task', type=str, metavar='DESCRIPTION', help='ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ø°ÙƒÙŠØ©')
        agent_group.add_argument('--analyze', type=str, metavar='PROBLEM', help='ØªØ­Ù„ÙŠÙ„ Ù…Ø´ÙƒÙ„Ø© Ù…Ø¹Ù‚Ø¯Ø©')
        agent_group.add_argument('--solve', type=str, metavar='CHALLENGE', help='Ø­Ù„ ØªØ­Ø¯ÙŠ Ø°ÙƒÙŠ')
        agent_group.add_argument('--status', action='store_true', help='Ø­Ø§Ù„Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØµØ¯ÙŠØ± ÙˆØ§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
        export_parser = subparsers.add_parser('export', help='ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬')
        export_parser.add_argument('--output', type=str, required=True, metavar='FILE', help='Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬')
        export_parser.add_argument('--format', choices=['json', 'txt', 'csv'], default='json', help='ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬')

        import_parser = subparsers.add_parser('import', help='Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')
        import_parser.add_argument('--input', type=str, required=True, metavar='FILE', help='Ù…Ù„Ù Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„')

        # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªÙØ§Ø¹Ù„
        interactive_parser = subparsers.add_parser('interactive', help='ÙˆØ¶Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±')

        return parser

    def run_status(self, args):
        """Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…."""

        if not self.system_ready:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ø¬Ø§Ù‡Ø²")
            return

        print("ğŸŒŸ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Baserah")
        print("=" * 50)

        # Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…
        summary = self.mother_system.get_system_summary()
        print(f"ğŸ“Š Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…:")
        print(f"   Ù…Ø¹Ø±Ù Ø§Ù„Ù†Ø¸Ø§Ù…: {summary['system_id']}")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙˆØ±Ø§Ø«Ø§Øª: {summary['total_inheritances']}")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙƒÙŠÙØ§Øª: {summary['total_adaptations']}")
        print(f"   Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ·ÙˆÙŠØ±: {summary['system_evolution_count']}")
        print(f"   Ù†Ù‚Ø§Ø¡ Baserah: {summary['baserah_purity'] * 100:.1f}%")

        # Ø­Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±
        health_status = self.self_evolving.analyze_system_health()
        metrics = self.self_evolving.current_metrics
        print(f"\nğŸ§¬ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ·ÙˆÙŠØ±:")
        print(f"   Ø­Ø§Ù„Ø© Ø§Ù„ØµØ­Ø©: {health_status.value}")
        print(f"   Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡: {metrics.performance_score:.3f}")
        print(f"   ÙƒÙØ§Ø¡Ø© Ø§Ù„ØªÙƒÙŠÙ: {metrics.adaptation_efficiency:.3f}")
        print(f"   Ø§Ù„Ø¥Ù…ÙƒØ§Ù†Ø§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©: {metrics.revolutionary_potential:.3f}")

        # Ø­Ø§Ù„Ø© Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ©
        semantic_summary = self.semantic_system.get_semantic_summary()
        print(f"\nğŸ§  Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ©:")
        print(f"   Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø¯Ù„Ø§Ù„ÙŠØ©: {semantic_summary['total_semantic_equations']}")
        print(f"   ØªÙØ³ÙŠØ±Ø§Øª: {semantic_summary['total_interpretations']}")
        print(f"   Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª: {list(semantic_summary['type_distribution'].keys())}")

        # Ø­Ø§Ù„Ø© Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ
        cognitive_summary = self.consciousness.get_cognitive_summary()
        print(f"\nğŸ§ âœ¨ Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ:")
        print(f"   Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙˆØ¹ÙŠ: {cognitive_summary['consciousness_level']:.3f}")
        print(f"   Ù…Ø¤Ø´Ø± Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹: {cognitive_summary['creativity_index']:.3f}")
        print(f"   ÙƒÙØ§Ø¡Ø© Ø§Ù„ØªØ¹Ù„Ù…: {cognitive_summary['learning_efficiency']:.3f}")

        if args.detailed:
            print(f"\nğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©:")
            print(f"   Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø±Ø«Ø©: {', '.join(summary['inherited_unit_types'])}")
            print(f"   ØªÙˆØ²ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª: {semantic_summary['type_distribution']}")
            print(f"   Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©: {semantic_summary['dimension_usage']}")

    def run_evolution(self, args):
        """ØªØ´ØºÙŠÙ„ Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ·ÙˆÙŠØ±."""

        if not self.system_ready:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ø¬Ø§Ù‡Ø²")
            return

        if args.analyze:
            print("ğŸ” ØªØ­Ù„ÙŠÙ„ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…...")

            health_status = self.self_evolving.analyze_system_health()
            decision = self.self_evolving.make_evolution_decision(health_status)

            print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
            print(f"   Ø­Ø§Ù„Ø© Ø§Ù„ØµØ­Ø©: {health_status.value}")
            print(f"   Ù‡Ù„ ÙŠØ¬Ø¨ Ø§Ù„ØªØ·ÙˆÙŠØ±: {'Ù†Ø¹Ù…' if decision['should_evolve'] else 'Ù„Ø§'}")
            print(f"   Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØ·ÙˆÙŠØ±: {decision.get('evolution_direction', {}).value if decision.get('evolution_direction') else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}")
            print(f"   ÙØ­Øµ Ø§Ù„Ø£Ù…Ø§Ù†: {'Ù†Ø¬Ø­' if decision['safety_checks_passed'] else 'ÙØ´Ù„'}")

            print(f"\nğŸ’¡ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨:")
            for reason in decision['reasoning']:
                print(f"   â€¢ {reason}")

        elif args.execute:
            print("âš¡ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ...")

            health_status = self.self_evolving.analyze_system_health()
            decision = self.self_evolving.make_evolution_decision(health_status)

            if decision['should_evolve'] and decision['safety_checks_passed']:
                evolution_result = self.self_evolving.execute_evolution(decision['evolution_direction'])

                print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ·ÙˆÙŠØ±:")
                print(f"   Ù†Ø¬Ø­ Ø§Ù„ØªØ·ÙˆÙŠØ±: {'Ù†Ø¹Ù…' if evolution_result['success'] else 'Ù„Ø§'}")
                print(f"   Ø¹Ø¯Ø¯ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª: {len(evolution_result['changes_made'])}")
                print(f"   Ù‚Ø¯Ø±Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©: {len(evolution_result['new_capabilities'])}")
                print(f"   ØªØ­Ø³Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡: {evolution_result['performance_improvement']:.3f}")

                if evolution_result['changes_made']:
                    print(f"\nğŸ”§ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©:")
                    for change in evolution_result['changes_made'][:5]:  # Ø£ÙˆÙ„ 5 ØªØºÙŠÙŠØ±Ø§Øª
                        print(f"   â€¢ {change}")

                if evolution_result['new_capabilities']:
                    print(f"\nğŸŒŸ Ù‚Ø¯Ø±Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©:")
                    for capability in evolution_result['new_capabilities'][:3]:  # Ø£ÙˆÙ„ 3 Ù‚Ø¯Ø±Ø§Øª
                        print(f"   â€¢ {capability}")
            else:
                print("â¸ï¸ ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„ØªØ·ÙˆÙŠØ± - Ù„Ù… ØªØªØ­Ù‚Ù‚ Ø§Ù„Ø´Ø±ÙˆØ·")

        elif args.continuous:
            cycles = args.continuous
            print(f"ğŸ”„ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù„Ù€ {cycles} Ø¯ÙˆØ±Ø©...")

            continuous_result = self.self_evolving.run_continuous_evolution(max_cycles=cycles)

            print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø³ØªÙ…Ø±:")
            print(f"   Ø¯ÙˆØ±Ø§Øª ÙƒÙ„ÙŠØ©: {continuous_result['total_cycles']}")
            print(f"   ØªØ·ÙˆÙŠØ±Ø§Øª Ù†Ø§Ø¬Ø­Ø©: {continuous_result['successful_evolutions']}")
            print(f"   Ø§Ø®ØªØ±Ø§Ù‚Ø§Øª Ø«ÙˆØ±ÙŠØ©: {continuous_result['revolutionary_breakthroughs']}")
            print(f"   Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {(continuous_result['successful_evolutions'] / continuous_result['total_cycles'] * 100):.1f}%")
            print(f"   Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {continuous_result['final_metrics'].performance_score:.3f}")

    def run_semantic(self, args):
        """ØªØ´ØºÙŠÙ„ Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ©."""

        if not self.system_ready:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ø¬Ø§Ù‡Ø²")
            return

        if args.interpret:
            sentence = args.interpret
            print(f"ğŸ§  ØªÙØ³ÙŠØ± Ø§Ù„Ø¬Ù…Ù„Ø©: '{sentence}'")

            interpretation = self.semantic_system.interpret_semantic_sentence(sentence)

            print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØ³ÙŠØ±:")
            print(f"   Ø§Ù„Ø«Ù‚Ø©: {interpretation['confidence']:.2f}")
            print(f"   ÙƒÙ„Ù…Ø§Øª Ù…Ø¹Ø±ÙˆÙØ©: {len(interpretation['recognized_words'])}/{len(sentence.split())}")

            if interpretation['recognized_words']:
                print(f"\nğŸ” Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©:")
                for word_info in interpretation['recognized_words']:
                    print(f"   {word_info['symbol']} {word_info['word']} ({word_info['type']})")

            if interpretation['confidence'] > 0.5:
                print(f"\nğŸ“‹ Ø®Ø·Ø© Ø§Ù„ØªÙ†ÙÙŠØ° ({len(interpretation['execution_plan'])} Ø®Ø·ÙˆØ©):")
                for i, step in enumerate(interpretation['execution_plan'], 1):
                    print(f"   {i}. {step['action']}")

        elif args.execute:
            command = args.execute
            print(f"âš¡ ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±: '{command}'")

            execution_result = self.semantic_system.execute_semantic_command(command)

            print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†ÙÙŠØ°:")
            print(f"   Ù†Ø¬Ø­ Ø§Ù„ØªÙ†ÙÙŠØ°: {'Ù†Ø¹Ù…' if execution_result['execution_success'] else 'Ù„Ø§'}")
            print(f"   Ø«Ù‚Ø© Ø§Ù„ØªÙØ³ÙŠØ±: {execution_result['interpretation']['confidence']:.2f}")

            if execution_result['execution_success']:
                if execution_result.get('visual_output'):
                    print(f"   ÙƒØ§Ø¦Ù†Ø§Øª Ø¨ØµØ±ÙŠØ©: {len(execution_result['visual_output'])}")

                if execution_result.get('mathematical_result'):
                    print(f"   ØªØ­ÙˆÙŠÙ„Ø§Øª Ø±ÙŠØ§Ø¶ÙŠØ©: {len(execution_result['mathematical_result'])}")

                if execution_result.get('semantic_analysis'):
                    fusion_score = execution_result['semantic_analysis'].get('fusion_score', 0)
                    print(f"   Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {fusion_score:.3f}")

        elif args.transform:
            source, target = args.transform
            print(f"ğŸ”„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {source} â†’ {target}")

            transformation = self.semantic_system.create_semantic_transformation(source, target)

            if 'error' in transformation:
                print(f"âŒ Ø®Ø·Ø£: {transformation['error']}")
                return

            print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­ÙˆÙŠÙ„:")
            print(f"   Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ­ÙˆÙŠÙ„: {transformation['transformation_score']:.3f}")
            print(f"   Ø®Ø·ÙˆØ§Øª Ø±ÙŠØ§Ø¶ÙŠØ©: {len(transformation['mathematical_steps'])}")
            print(f"   ØªØºÙŠÙŠØ±Ø§Øª Ø¯Ù„Ø§Ù„ÙŠØ©: {len(transformation['semantic_changes'])}")

        elif args.database:
            print("ğŸ“š Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©:")

            summary = self.semantic_system.get_semantic_summary()

            print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª: {summary['total_semantic_equations']}")
            print(f"   ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹: {summary['type_distribution']}")
            print(f"   Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {summary['dimension_usage']}")

            print(f"\nğŸ”¤ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:")
            for word in self.semantic_system.semantic_database.keys():
                equation = self.semantic_system.semantic_database[word]
                symbol = self.semantic_system.symbol_registry.get(f'{equation.semantic_type.value}_symbol', 'ğŸ”¸')
                print(f"   {symbol} {word} ({equation.semantic_type.value})")

    def run(self):
        """ØªØ´ØºÙŠÙ„ ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±."""

        parser = self.create_parser()
        args = parser.parse_args()

        if not args.command:
            parser.print_help()
            return

        print(f"ğŸŒŸ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Baserah - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)

        try:
            if args.command == 'status':
                self.run_status(args)
            elif args.command == 'evolution':
                self.run_evolution(args)
            elif args.command == 'semantic':
                self.run_semantic(args)
            elif args.command == 'cognitive':
                self.run_cognitive(args)
            elif args.command == 'artistic':
                self.run_artistic(args)
            elif args.command == 'quran':
                self.run_quran(args)
            elif args.command == 'lexicon':
                self.run_lexicon(args)
            elif args.command == 'agent':
                self.run_agent(args)
            elif args.command == 'export':
                self.run_export(args)
            elif args.command == 'import':
                self.run_import(args)
            elif args.command == 'interactive':
                self.run_interactive()
            else:
                print(f"âŒ Ø£Ù…Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {args.command}")

        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        except Exception as e:
            print(f"\nâŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±: {e}")
            import traceback
            traceback.print_exc()

    def run_cognitive(self, args):
        """ØªØ´ØºÙŠÙ„ Ø£ÙˆØ§Ù…Ø± Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©."""

        if not self.system_ready:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ø¬Ø§Ù‡Ø²")
            return

        if args.reflect:
            print("ğŸª Ø§Ù„ØªØ£Ù…Ù„ Ø§Ù„Ø°Ø§ØªÙŠ Ù„Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ...")

            reflection = self.consciousness.reflect_on_self()

            if 'error' in reflection:
                print(f"âŒ Ø®Ø·Ø£: {reflection['error']}")
                return

            print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ£Ù…Ù„ Ø§Ù„Ø°Ø§ØªÙŠ:")
            print(f"   Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙˆØ¹ÙŠ: {reflection['self_assessment']['consciousness_level']:.3f}")
            print(f"   Ù†Ù‚Ø§Ø· Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø°Ø§ØªÙŠ: {reflection['self_assessment']['self_awareness_score']:.3f}")
            print(f"   Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {reflection['self_assessment']['current_value']:.3f}")

            if reflection['insights']:
                print(f"\nğŸ’¡ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª ({len(reflection['insights'])}):")
                for insight in reflection['insights']:
                    print(f"   â€¢ {insight}")

            if reflection['improvement_areas']:
                print(f"\nğŸ¯ Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† ({len(reflection['improvement_areas'])}):")
                for area in reflection['improvement_areas']:
                    print(f"   â€¢ {area}")

            if reflection['consciousness_observations']:
                print(f"\nğŸŒŸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„ÙˆØ¹ÙŠ ({len(reflection['consciousness_observations'])}):")
                for observation in reflection['consciousness_observations']:
                    print(f"   â€¢ {observation}")

        elif args.learn:
            data_text = args.learn
            print(f"ğŸ“š Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ù„ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: '{data_text}'")

            try:
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª
                if ',' in data_text:
                    learning_data = [float(x.strip()) for x in data_text.split(',')]
                else:
                    learning_data = data_text

                learning_result = self.consciousness.autonomous_learn(learning_data)

                if 'error' in learning_result:
                    print(f"âŒ Ø®Ø·Ø£: {learning_result['error']}")
                    return

                print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ù„Ù…:")
                print(f"   Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {learning_result['data_processed']}")
                print(f"   Ù…Ø¹Ø±ÙØ© Ù…ÙƒØªØ³Ø¨Ø©: {len(learning_result['knowledge_gained'])}")
                print(f"   Ø£Ù†Ù…Ø§Ø· Ø¬Ø¯ÙŠØ¯Ø©: {len(learning_result['new_patterns'])}")
                print(f"   ØªØ­Ø³Ù† Ø§Ù„ÙƒÙØ§Ø¡Ø©: {learning_result['learning_efficiency_change']:.4f}")

                if learning_result['knowledge_gained']:
                    print(f"\nğŸ§  Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙƒØªØ³Ø¨Ø©:")
                    for knowledge in learning_result['knowledge_gained']:
                        print(f"   â€¢ {knowledge}")

                if learning_result['new_patterns']:
                    print(f"\nğŸ” Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
                    for pattern in learning_result['new_patterns']:
                        print(f"   â€¢ {pattern['type']}: {pattern['description']}")

            except ValueError:
                print("âŒ Ø®Ø·Ø£: ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­")

        elif args.create:
            print("ğŸ¨ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ...")

            # Ø¥Ù„Ù‡Ø§Ù… Ø¹Ø´ÙˆØ§Ø¦ÙŠ
            inspiration = np.random.uniform(0, 10)

            creative_output = self.consciousness.generate_creative_output(inspiration=inspiration)

            if 'error' in creative_output:
                print(f"âŒ Ø®Ø·Ø£: {creative_output['error']}")
                return

            print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ:")
            print(f"   Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹: {creative_output['creative_type']}")
            print(f"   Ù…ØµØ¯Ø± Ø§Ù„Ø¥Ù„Ù‡Ø§Ù…: {creative_output['inspiration_source']}")
            print(f"   Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹: {creative_output['creativity_score']:.3f}")
            print(f"   Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯Ø©: {creative_output['novelty_level']:.3f}")

            print(f"\nğŸ¯ Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ:")
            if creative_output['creative_type'] == 'equation':
                equation = creative_output['output']
                print(f"   Ø§Ø³Ù… Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©: {equation['equation_name']}")
                print(f"   Ù…ÙƒÙˆÙ†Ø§Øª: {len(equation['components'])}")
                print(f"   Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬Ù…Ø§Ù„ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ: {equation['mathematical_beauty_score']:.2f}")
            elif creative_output['creative_type'] == 'pattern':
                pattern = creative_output['output']
                print(f"   Ø§Ø³Ù… Ø§Ù„Ù†Ù…Ø·: {pattern['pattern_name']}")
                print(f"   Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…Ø·: {pattern['pattern_type']}")
                print(f"   Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯: {pattern['complexity_level']:.2f}")

        elif args.consciousness:
            print("ğŸŒŸ ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆØ¹ÙŠ...")

            consciousness_event = self.consciousness.emerge_consciousness()

            if 'error' in consciousness_event:
                print(f"âŒ Ø®Ø·Ø£: {consciousness_event['error']}")
                return

            print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ ØªØ·ÙˆÙŠØ± Ø§Ù„ÙˆØ¹ÙŠ:")
            print(f"   Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³Ø§Ø¨Ù‚: {consciousness_event['previous_level']:.3f}")
            print(f"   Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯: {consciousness_event['new_level']:.3f}")
            print(f"   Ø§Ù„ØªØ­Ø³Ù†: +{(consciousness_event['new_level'] - consciousness_event['previous_level']):.3f}")

            if consciousness_event['awareness_insights']:
                print(f"\nğŸ’¡ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø§Ù„ÙˆØ¹ÙŠ ({len(consciousness_event['awareness_insights'])}):")
                for insight in consciousness_event['awareness_insights']:
                    print(f"   â€¢ {insight}")

            if consciousness_event['existential_questions']:
                print(f"\nâ“ Ø£Ø³Ø¦Ù„Ø© ÙˆØ¬ÙˆØ¯ÙŠØ© ({len(consciousness_event['existential_questions'])}):")
                for question in consciousness_event['existential_questions']:
                    print(f"   â€¢ {question}")

            if consciousness_event['self_model_updates']:
                print(f"\nğŸ”„ ØªØ­Ø¯ÙŠØ«Ø§Øª Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°Ø§Øª ({len(consciousness_event['self_model_updates'])}):")
                for update in consciousness_event['self_model_updates']:
                    print(f"   â€¢ {update}")

        elif args.summary:
            print("ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ:")

            summary = self.consciousness.get_cognitive_summary()

            print(f"   Ù…Ø¹Ø±Ù Ø§Ù„ÙƒØ§Ø¦Ù†: {summary['object_id']}")
            print(f"   Ø§Ù„Ù†ÙˆØ¹: {summary['cognitive_type']}")
            print(f"   Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙˆØ¹ÙŠ: {summary['consciousness_level']:.3f}")
            print(f"   Ù…Ø¤Ø´Ø± Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹: {summary['creativity_index']:.3f}")
            print(f"   ÙƒÙØ§Ø¡Ø© Ø§Ù„ØªØ¹Ù„Ù…: {summary['learning_efficiency']:.3f}")
            print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø©: {summary['total_activities']}")
            print(f"   Ø¢Ø®Ø± Ù†Ø´Ø§Ø·: {summary['last_activity_time']}")

    def run_artistic(self, args):
        """ØªØ´ØºÙŠÙ„ Ø£ÙˆØ§Ù…Ø± Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©."""

        if not self.system_ready:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ø¬Ø§Ù‡Ø²")
            return

        if args.plot:
            params = args.plot

            if len(params) < 4:
                print("âŒ Ø®Ø·Ø£: ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ (Ù†ÙˆØ¹ n k alpha)")
                print("   Ù…Ø«Ø§Ù„: sigmoid 1 1.0 1.0")
                return

            try:
                equation_type = params[0]
                n = int(params[1])
                k = float(params[2])
                alpha = float(params[3])

                print(f"ğŸ“Š Ø±Ø³Ù… Ù…Ø¹Ø§Ø¯Ù„Ø© {equation_type} Ù…Ø¹ n={n}, k={k}, Î±={alpha}")

                # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù‚Ø§Ø· Ù„Ù„Ø±Ø³Ù…
                x = np.linspace(-5, 5, 1000)

                if equation_type == 'sigmoid':
                    y = self.artistic_unit.gse_renderer.calculate_sigmoid(x, n, k, 0.0, alpha)
                elif equation_type == 'linear':
                    y = k * x + alpha
                else:
                    print(f"âŒ Ù†ÙˆØ¹ Ù…Ø¹Ø§Ø¯Ù„Ø© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: {equation_type}")
                    return

                # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù
                output_file = f"plot_{equation_type}_{n}_{k}_{alpha}.txt"
                with open(output_file, 'w') as f:
                    f.write(f"# Ø±Ø³Ù… Ù…Ø¹Ø§Ø¯Ù„Ø© {equation_type}\n")
                    f.write(f"# Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª: n={n}, k={k}, Î±={alpha}\n")
                    f.write("# x\ty\n")
                    for xi, yi in zip(x, y):
                        f.write(f"{xi:.6f}\t{yi:.6f}\n")

                print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ: {output_file}")
                print(f"   Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {len(x)}")
                print(f"   Ø§Ù„Ù…Ø¯Ù‰: x âˆˆ [{x.min():.1f}, {x.max():.1f}]")
                print(f"   Ø§Ù„Ù‚ÙŠÙ…: y âˆˆ [{y.min():.3f}, {y.max():.3f}]")

            except ValueError as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {e}")

        elif args.adapt:
            source, target = args.adapt
            print(f"ğŸ”„ Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ø¨ØµØ±ÙŠ: {source} â†’ {target}")

            try:
                if not self.artistic_unit.visual_adaptation_enabled:
                    print("âš ï¸ ØªØ­Ø°ÙŠØ±: Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ø¨ØµØ±ÙŠ ØºÙŠØ± Ù…ÙØ¹Ù„")
                    return

                adaptation_frames = self.artistic_unit.create_visual_adaptation(source, target, steps=10)

                if adaptation_frames:
                    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(adaptation_frames)} Ø¥Ø·Ø§Ø± ØªÙƒÙŠÙ")
                    print(f"   Ø§Ù„Ù…ØµØ¯Ø±: {source}")
                    print(f"   Ø§Ù„Ù‡Ø¯Ù: {target}")
                    print(f"   Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙƒÙŠÙ: {len(adaptation_frames)}")
                else:
                    print("âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ø¨ØµØ±ÙŠ")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„Ø¨ØµØ±ÙŠ: {e}")

        elif args.animate:
            shape = args.animate
            print(f"ğŸ¬ Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³ÙˆÙ… Ù…ØªØ­Ø±ÙƒØ© Ù„Ù„Ø´ÙƒÙ„: {shape}")

            try:
                # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³ÙˆÙ… Ù…ØªØ­Ø±ÙƒØ© Ø¨Ø³ÙŠØ·Ø©
                frames = []
                for i in range(20):
                    frame_data = {
                        'frame': i,
                        'shape': shape,
                        'timestamp': datetime.now().isoformat(),
                        'parameters': {
                            'rotation': i * 18,  # Ø¯ÙˆØ±Ø§Ù† 18 Ø¯Ø±Ø¬Ø© Ù„ÙƒÙ„ Ø¥Ø·Ø§Ø±
                            'scale': 1.0 + 0.1 * np.sin(i * 0.3),
                            'alpha': 0.5 + 0.5 * np.cos(i * 0.2)
                        }
                    }
                    frames.append(frame_data)

                # Ø­ÙØ¸ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©
                animation_file = f"animation_{shape}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(animation_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'animation_name': f"Ø±Ø³ÙˆÙ… Ù…ØªØ­Ø±ÙƒØ© - {shape}",
                        'total_frames': len(frames),
                        'duration': len(frames) * 0.1,  # 0.1 Ø«Ø§Ù†ÙŠØ© Ù„ÙƒÙ„ Ø¥Ø·Ø§Ø±
                        'frames': frames
                    }, f, ensure_ascii=False, indent=2)

                print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©:")
                print(f"   Ø§Ù„Ù…Ù„Ù: {animation_file}")
                print(f"   Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª: {len(frames)}")
                print(f"   Ø§Ù„Ù…Ø¯Ø©: {len(frames) * 0.1:.1f} Ø«Ø§Ù†ÙŠØ©")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©: {e}")

    def run_export(self, args):
        """ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬."""

        if not self.system_ready:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ø¬Ø§Ù‡Ø²")
            return

        output_file = args.output
        output_format = args.format

        print(f"ğŸ’¾ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰: {output_file} (ØªÙ†Ø³ÙŠÙ‚: {output_format})")

        try:
            # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            export_data = {
                'export_info': {
                    'timestamp': datetime.now().isoformat(),
                    'format': output_format,
                    'system_version': 'Baserah Revolutionary System v1.0'
                },
                'mother_system': self.mother_system.get_system_summary(),
                'evolution_system': {
                    'health_status': self.self_evolving.analyze_system_health().value,
                    'current_metrics': {
                        'performance_score': self.self_evolving.current_metrics.performance_score,
                        'adaptation_efficiency': self.self_evolving.current_metrics.adaptation_efficiency,
                        'revolutionary_potential': self.self_evolving.current_metrics.revolutionary_potential,
                        'system_complexity': self.self_evolving.current_metrics.system_complexity
                    }
                },
                'semantic_system': self.semantic_system.get_semantic_summary(),
                'cognitive_system': self.consciousness.get_cognitive_summary()
            }

            # ØªØµØ¯ÙŠØ± Ø­Ø³Ø¨ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
            if output_format == 'json':
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)

            elif output_format == 'txt':
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write("ğŸŒŸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Baserah\n")
                    f.write("=" * 50 + "\n\n")

                    f.write(f"ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØµØ¯ÙŠØ±: {export_data['export_info']['timestamp']}\n\n")

                    f.write("ğŸ“Š Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…:\n")
                    mother = export_data['mother_system']
                    f.write(f"   Ø§Ù„ÙˆØ±Ø§Ø«Ø§Øª: {mother['total_inheritances']}\n")
                    f.write(f"   Ø§Ù„ØªÙƒÙŠÙØ§Øª: {mother['total_adaptations']}\n")
                    f.write(f"   Ù†Ù‚Ø§Ø¡ Baserah: {mother['baserah_purity'] * 100:.1f}%\n\n")

                    f.write("ğŸ§¬ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ·ÙˆÙŠØ±:\n")
                    evolution = export_data['evolution_system']
                    f.write(f"   Ø§Ù„Ø­Ø§Ù„Ø©: {evolution['health_status']}\n")
                    f.write(f"   Ø§Ù„Ø£Ø¯Ø§Ø¡: {evolution['current_metrics']['performance_score']:.3f}\n\n")

                    f.write("ğŸ§  Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©:\n")
                    semantic = export_data['semantic_system']
                    f.write(f"   Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª: {semantic['total_semantic_equations']}\n")
                    f.write(f"   Ø§Ù„ØªÙØ³ÙŠØ±Ø§Øª: {semantic['total_interpretations']}\n\n")

                    f.write("ğŸ§ âœ¨ Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ:\n")
                    cognitive = export_data['cognitive_system']
                    f.write(f"   Ø§Ù„ÙˆØ¹ÙŠ: {cognitive['consciousness_level']:.3f}\n")
                    f.write(f"   Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹: {cognitive['creativity_index']:.3f}\n")

            elif output_format == 'csv':
                import csv
                with open(output_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)

                    # Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    writer.writerow(['Ø§Ù„Ù†Ø¸Ø§Ù…', 'Ø§Ù„Ù…Ù‚ÙŠØ§Ø³', 'Ø§Ù„Ù‚ÙŠÙ…Ø©'])

                    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…
                    mother = export_data['mother_system']
                    writer.writerow(['Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…', 'Ø§Ù„ÙˆØ±Ø§Ø«Ø§Øª', mother['total_inheritances']])
                    writer.writerow(['Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…', 'Ø§Ù„ØªÙƒÙŠÙØ§Øª', mother['total_adaptations']])
                    writer.writerow(['Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…', 'Ù†Ù‚Ø§Ø¡ Baserah', f"{mother['baserah_purity'] * 100:.1f}%"])

                    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ·ÙˆÙŠØ±
                    evolution = export_data['evolution_system']
                    writer.writerow(['Ø§Ù„ØªØ·ÙˆÙŠØ±', 'Ø§Ù„Ø­Ø§Ù„Ø©', evolution['health_status']])
                    writer.writerow(['Ø§Ù„ØªØ·ÙˆÙŠØ±', 'Ø§Ù„Ø£Ø¯Ø§Ø¡', f"{evolution['current_metrics']['performance_score']:.3f}"])

                    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„Ø©
                    semantic = export_data['semantic_system']
                    writer.writerow(['Ø§Ù„Ø¯Ù„Ø§Ù„Ø©', 'Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª', semantic['total_semantic_equations']])
                    writer.writerow(['Ø§Ù„Ø¯Ù„Ø§Ù„Ø©', 'Ø§Ù„ØªÙØ³ÙŠØ±Ø§Øª', semantic['total_interpretations']])

                    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ
                    cognitive = export_data['cognitive_system']
                    writer.writerow(['Ø§Ù„Ù…Ø¹Ø±ÙÙŠ', 'Ø§Ù„ÙˆØ¹ÙŠ', f"{cognitive['consciousness_level']:.3f}"])
                    writer.writerow(['Ø§Ù„Ù…Ø¹Ø±ÙÙŠ', 'Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹', f"{cognitive['creativity_index']:.3f}"])

            print(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            print(f"   Ø§Ù„Ù…Ù„Ù: {output_file}")
            print(f"   Ø§Ù„ØªÙ†Ø³ÙŠÙ‚: {output_format}")
            print(f"   Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {len(str(export_data))} Ø­Ø±Ù")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØµØ¯ÙŠØ±: {e}")

    def run_import(self, args):
        """Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""

        input_file = args.input

        print(f"ğŸ“¥ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†: {input_file}")

        try:
            if not os.path.exists(input_file):
                print(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {input_file}")
                return

            with open(input_file, 'r', encoding='utf-8') as f:
                if input_file.endswith('.json'):
                    imported_data = json.load(f)
                else:
                    print("âŒ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… (JSON ÙÙ‚Ø· Ø­Ø§Ù„ÙŠØ§Ù‹)")
                    return

            print(f"âœ… ØªÙ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            print(f"   ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØµØ¯ÙŠØ±: {imported_data.get('export_info', {}).get('timestamp', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
            print(f"   Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù…: {imported_data.get('export_info', {}).get('system_version', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")

            # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªÙˆØ±Ø¯Ø©
            if 'mother_system' in imported_data:
                mother = imported_data['mother_system']
                print(f"   Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…: {mother.get('total_inheritances', 0)} ÙˆØ±Ø§Ø«Ø©")

            if 'semantic_system' in imported_data:
                semantic = imported_data['semantic_system']
                print(f"   Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©: {semantic.get('total_semantic_equations', 0)} Ù…Ø¹Ø§Ø¯Ù„Ø©")

            if 'cognitive_system' in imported_data:
                cognitive = imported_data['cognitive_system']
                print(f"   Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ: ÙˆØ¹ÙŠ {cognitive.get('consciousness_level', 0):.3f}")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯: {e}")

    def run_interactive(self):
        """ÙˆØ¶Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±."""

        print("ğŸ® ÙˆØ¶Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±")
        print("=" * 50)
        print("Ø£ÙˆØ§Ù…Ø± Ù…ØªØ§Ø­Ø©:")
        print("  status    - Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…")
        print("  evolve    - ØªØ·ÙˆÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠ")
        print("  semantic  - Ø¯Ù„Ø§Ù„Ø© Ù…Ø¹Ù†ÙˆÙŠØ©")
        print("  cognitive - ÙƒØ§Ø¦Ù† Ù…Ø¹Ø±ÙÙŠ")
        print("  help      - Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©")
        print("  exit      - Ø®Ø±ÙˆØ¬")
        print("=" * 50)

        while True:
            try:
                command = input("\nğŸŒŸ Baserah> ").strip().lower()

                if command == 'exit' or command == 'quit':
                    print("ğŸ‘‹ ÙˆØ¯Ø§Ø¹Ø§Ù‹!")
                    break

                elif command == 'status':
                    # Ù…Ø­Ø§ÙƒØ§Ø© args Ù„Ù„Ø­Ø§Ù„Ø©
                    class MockArgs:
                        detailed = False
                    self.run_status(MockArgs())

                elif command == 'evolve':
                    print("ğŸ§¬ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ...")
                    class MockArgs:
                        analyze = False
                        execute = True
                        continuous = None
                    self.run_evolution(MockArgs())

                elif command.startswith('semantic '):
                    sentence = command[9:].strip()
                    if sentence:
                        class MockArgs:
                            interpret = sentence
                            execute = None
                            transform = None
                            database = False
                        self.run_semantic(MockArgs())
                    else:
                        print("âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø¬Ù…Ù„Ø© Ø¨Ø¹Ø¯ 'semantic'")

                elif command == 'cognitive':
                    print("ğŸ§  ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ£Ù…Ù„ Ø§Ù„Ø°Ø§ØªÙŠ...")
                    class MockArgs:
                        reflect = True
                        learn = None
                        create = False
                        consciousness = False
                        summary = False
                    self.run_cognitive(MockArgs())

                elif command == 'help':
                    print("ğŸ“š Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©:")
                    print("  status                    - Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…")
                    print("  evolve                    - ØªØ·ÙˆÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠ")
                    print("  semantic <Ø¬Ù…Ù„Ø©>           - ØªÙØ³ÙŠØ± Ø¬Ù…Ù„Ø© Ø¯Ù„Ø§Ù„ÙŠØ©")
                    print("  cognitive                 - ØªØ£Ù…Ù„ Ø°Ø§ØªÙŠ")
                    print("  exit                      - Ø®Ø±ÙˆØ¬")

                elif command == '':
                    continue

                else:
                    print(f"âŒ Ø£Ù…Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {command}")
                    print("Ø§ÙƒØªØ¨ 'help' Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©")

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ÙˆØ¯Ø§Ø¹Ø§Ù‹!")
                break
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£: {e}")

    def run_quran(self, args):
        """ØªØ´ØºÙŠÙ„ Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ."""

        if not self.system_ready:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ø¬Ø§Ù‡Ø²")
            return

        if args.analyze:
            surah_number, verse_number = args.analyze
            print(f"ğŸ•Œ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¢ÙŠØ©: {surah_number}:{verse_number}")

            try:
                analysis = self.quranic_engine.analyze_verse_revolutionary(
                    surah_number, verse_number, deep_analysis=True
                )

                print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
                print(f"   Ø§Ù„Ù†Øµ: {analysis.text}")
                print(f"   Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {analysis.semantic_weight:.3f}")
                print(f"   Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {len(analysis.word_analysis)}")
                print(f"   Ø±Ø¤Ù‰ Ø«ÙˆØ±ÙŠØ©: {len(analysis.revolutionary_insights)}")
                print(f"   Ø£Ù†Ù…Ø§Ø· Ø¥Ù„Ù‡ÙŠØ©: {len(analysis.divine_patterns)}")
                print(f"   Ø¥Ø¹Ø¬Ø§Ø² Ø±Ù‚Ù…ÙŠ: {len(analysis.numerical_miracle)}")

                if analysis.revolutionary_insights:
                    print(f"\nğŸ’¡ Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø«ÙˆØ±ÙŠØ©:")
                    for insight in analysis.revolutionary_insights[:3]:
                        print(f"   â€¢ {insight}")

                if analysis.divine_patterns:
                    print(f"\nğŸŒŸ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù„Ù‡ÙŠØ©:")
                    for pattern in analysis.divine_patterns[:3]:
                        print(f"   â€¢ {pattern}")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")

        elif args.search:
            search_term = args.search
            print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø¹Ù†: '{search_term}'")

            try:
                search_result = self.quranic_engine.search_quranic_text(search_term, "word")

                print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«:")
                print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {search_result['total_matches']}")
                print(f"   Ø³ÙˆØ± Ù…Ø·Ø§Ø¨Ù‚Ø©: {len(search_result['surahs_found'])}")

                if search_result['matches']:
                    print(f"\nğŸ“‹ Ø£ÙˆÙ„ 5 Ù†ØªØ§Ø¦Ø¬:")
                    for i, match in enumerate(search_result['matches'][:5], 1):
                        print(f"   {i}. {match['surah_name']} ({match['surah_number']}:{match['verse_number']})")
                        print(f"      {match['verse_text'][:100]}...")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")

        elif args.surah:
            surah_number = args.surah
            print(f"ğŸ“š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆØ±Ø©: {surah_number}")

            try:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ø³ÙˆØ±Ø©
                if str(surah_number) not in self.quranic_engine.quran_text_data.get('surahs', {}):
                    print(f"âš ï¸ Ø§Ù„Ø³ÙˆØ±Ø© Ø±Ù‚Ù… {surah_number} ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
                    print("ğŸ“‹ Ø§Ù„Ø³ÙˆØ± Ø§Ù„Ù…ØªÙˆÙØ±Ø©: 1 (Ø§Ù„ÙØ§ØªØ­Ø©), 112 (Ø§Ù„Ø¥Ø®Ù„Ø§Øµ), 113 (Ø§Ù„ÙÙ„Ù‚), 114 (Ø§Ù„Ù†Ø§Ø³)")
                    return

                surah_analysis = self.quranic_engine.analyze_surah_revolutionary(surah_number, deep_analysis=True)

                print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆØ±Ø©:")
                stats = surah_analysis['surah_statistics']
                print(f"   Ø§Ø³Ù… Ø§Ù„Ø³ÙˆØ±Ø©: {stats['surah_name']}")
                print(f"   Ù†ÙˆØ¹ Ø§Ù„Ø³ÙˆØ±Ø©: {stats['surah_type']}")
                print(f"   Ø¹Ø¯Ø¯ Ø§Ù„Ø¢ÙŠØ§Øª: {stats['total_verses']}")
                print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {stats['total_words']}")
                print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {stats['average_semantic_weight']:.3f}")
                print(f"   Ø¥Ø¹Ø¬Ø§Ø² Ø±Ù‚Ù…ÙŠ: {stats['numerical_miracles_count']}")
                print(f"   Ø£Ù†Ù…Ø§Ø· Ø¥Ù„Ù‡ÙŠØ©: {stats['divine_patterns_count']}")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙˆØ±Ø©: {e}")

        elif args.status:
            print("ğŸ“Š Ø­Ø§Ù„Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ:")

            try:
                status = self.quranic_engine.get_engine_status()
                stats = status['statistics']

                print(f"   Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ: {status['engine_info']['name']}")
                print(f"   Ø§Ù„Ø¥ØµØ¯Ø§Ø±: {status['engine_info']['version']}")
                print(f"   Ø¢ÙŠØ§Øª Ù…Ø­Ù„Ù„Ø©: {stats['verses_analyzed']}")
                print(f"   ÙƒÙ„Ù…Ø§Øª Ù…Ø­Ù„Ù„Ø©: {stats['words_analyzed']}")
                print(f"   Ø¥Ø¹Ø¬Ø§Ø² Ø±Ù‚Ù…ÙŠ Ù…ÙƒØªØ´Ù: {stats['numerical_miracles_discovered']}")
                print(f"   Ø£Ù†Ù…Ø§Ø· Ø¥Ù„Ù‡ÙŠØ©: {stats['divine_patterns_found']}")
                print(f"   Ø±Ø¤Ù‰ Ø«ÙˆØ±ÙŠØ©: {stats['total_revolutionary_insights']}")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø©: {e}")

    def run_lexicon(self, args):
        """ØªØ´ØºÙŠÙ„ Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ."""

        if not self.system_ready:
            print("âŒ Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ø¬Ø§Ù‡Ø²")
            return

        if args.analyze:
            word = args.analyze
            print(f"ğŸ“š ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø©: '{word}'")

            try:
                analysis = self.lexicon_engine.analyze_word_revolutionary(word, deep_analysis=True)

                print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
                print(f"   Ø§Ù„ÙƒÙ„Ù…Ø©: {analysis.word}")
                print(f"   Ø§Ù„Ø¬Ø°Ø±: {analysis.root}")
                print(f"   Ø§Ù„Ù…Ø¹Ù†Ù‰: {analysis.meaning}")
                print(f"   Ø§Ù„ÙˆØ²Ù† Ø§Ù„ØµØ±ÙÙŠ: {analysis.morphological_weight:.3f}")
                print(f"   Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {analysis.semantic_weight:.3f}")
                print(f"   Ø±Ø¤Ù‰ Ø«ÙˆØ±ÙŠØ©: {len(analysis.revolutionary_insights)}")

                if analysis.revolutionary_insights:
                    print(f"\nğŸ’¡ Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø«ÙˆØ±ÙŠØ©:")
                    for insight in analysis.revolutionary_insights[:3]:
                        print(f"   â€¢ {insight}")

                if analysis.morphological_analysis:
                    morph = analysis.morphological_analysis
                    print(f"\nğŸ” Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ:")
                    print(f"   Ø§Ù„Ù†ÙˆØ¹: {morph.get('word_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
                    print(f"   Ø§Ù„ÙˆØ²Ù†: {morph.get('pattern', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
                    print(f"   Ø§Ù„Ø²ÙˆØ§Ø¦Ø¯: {morph.get('affixes', [])}")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")

        elif args.root:
            root = args.root
            print(f"ğŸŒ± Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø¬Ø°Ø±: '{root}'")

            try:
                search_result = self.lexicon_engine.search_by_root(root)

                print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«:")
                print(f"   Ø§Ù„Ø¬Ø°Ø±: {root}")
                print(f"   ÙƒÙ„Ù…Ø§Øª Ù…Ø´ØªÙ‚Ø©: {len(search_result['words'])}")

                if search_result.get('root_meaning'):
                    print(f"   Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø¬Ø°Ø±: {search_result['root_meaning']}")

                if search_result['words']:
                    print(f"\nğŸ“‹ Ø£ÙˆÙ„ 10 ÙƒÙ„Ù…Ø§Øª Ù…Ø´ØªÙ‚Ø©:")
                    for i, word_info in enumerate(search_result['words'][:10], 1):
                        if isinstance(word_info, dict):
                            print(f"   {i}. {word_info.get('word', word_info)} - {word_info.get('meaning', '')}")
                        else:
                            print(f"   {i}. {word_info}")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")

        elif args.morphology:
            word = args.morphology
            print(f"ğŸ” Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ: '{word}'")

            try:
                analysis = self.lexicon_engine.analyze_word_revolutionary(word, deep_analysis=True)

                if analysis.morphological_analysis:
                    morph = analysis.morphological_analysis
                    print(f"ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ:")
                    print(f"   Ø§Ù„ÙƒÙ„Ù…Ø©: {analysis.word}")
                    print(f"   Ø§Ù„Ø¬Ø°Ø±: {analysis.root}")
                    print(f"   Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø©: {morph.get('word_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
                    print(f"   Ø§Ù„ÙˆØ²Ù† Ø§Ù„ØµØ±ÙÙŠ: {morph.get('pattern', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
                    print(f"   Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø§Øª: {morph.get('prefixes', [])}")
                    print(f"   Ø§Ù„Ù„ÙˆØ§Ø­Ù‚: {morph.get('suffixes', [])}")
                    print(f"   Ø§Ù„ÙˆØ²Ù† Ø§Ù„ØµØ±ÙÙŠ: {analysis.morphological_weight:.3f}")

                    if morph.get('grammatical_info'):
                        print(f"   Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†Ø­ÙˆÙŠØ©: {morph['grammatical_info']}")
                else:
                    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ ØµØ±ÙÙŠ Ù„Ù„ÙƒÙ„Ù…Ø©")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ: {e}")

        elif args.status:
            print("ğŸ“Š Ø­Ø§Ù„Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø¬Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ:")

            try:
                status = self.lexicon_engine.get_engine_status()
                stats = status['statistics']

                print(f"   Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ: {status['engine_info']['name']}")
                print(f"   Ø§Ù„Ø¥ØµØ¯Ø§Ø±: {status['engine_info']['version']}")
                print(f"   ÙƒÙ„Ù…Ø§Øª Ù…Ø­Ù„Ù„Ø©: {stats['words_analyzed']}")
                print(f"   Ø¬Ø°ÙˆØ± Ù…ÙƒØªØ´ÙØ©: {stats['roots_discovered']}")
                print(f"   Ø£ÙˆØ²Ø§Ù† ØµØ±ÙÙŠØ©: {stats['morphological_patterns_found']}")
                print(f"   Ø±Ø¤Ù‰ Ø«ÙˆØ±ÙŠØ©: {stats['total_revolutionary_insights']}")

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø©: {e}")

def main():
    """ØªØ´ØºÙŠÙ„ ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±."""

    try:
        cli = BaserahCLI()
        cli.run()
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ ÙˆØ§Ø¬Ù‡Ø© Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()